<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>ptLasso Vignette and Manual • ptLasso</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="ptLasso Vignette and Manual">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-primary" data-bs-theme="dark" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">ptLasso</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item"><a class="nav-link" href="../articles/ptLasso.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/InputGroupedData.html">Input grouped data</a></li>
    <li><a class="dropdown-item" href="../articles/LearningTheInputGroups.html">Learning the input groups</a></li>
    <li><a class="dropdown-item" href="../articles/DifferentGroupsTrainAndTest.html">Different groups in train and test data</a></li>
    <li><a class="dropdown-item" href="../articles/TargetGroupedData.html">Target grouped (multinomial response) data</a></li>
    <li><a class="dropdown-item" href="../articles/MultiResponseGaussian.html">Multi-response data with Gaussian responses</a></li>
    <li><a class="dropdown-item" href="../articles/TimeSeriesData.html">Time series data</a></li>
    <li><a class="dropdown-item" href="../articles/MultiResponseMixed.html">Multi-response data with mixed response types</a></li>
    <li><a class="dropdown-item" href="../articles/ConditionalAverageTreatmentEffect.html">Conditional average treatment effects</a></li>
    <li><a class="dropdown-item" href="../articles/UsingNonlinearBases.html">Pretraining with nonlinear bases</a></li>
    <li><a class="dropdown-item" href="../articles/UnsupervisedPretraining.html">Unsupervised pretraining</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>ptLasso Vignette and Manual</h1>
            
      

      <div class="d-none name"><code>ptLasso.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction-to-pretraining">Introduction to pretraining<a class="anchor" aria-label="anchor" href="#introduction-to-pretraining"></a>
</h2>
<p>Suppose we have a dataset spanning ten cancers and we want to fit a
lasso penalized Cox model to predict survival time. Some of the cancer
classes in our dataset are large (e.g. breast, lung) and some are small
(e.g. head and neck). There are two obvious approaches: (1) fit a
“pancancer model” to the entire training set and use it to make
predictions for all cancer classes and (2) fit a separate (class
specific) model for each cancer and use it to make predictions for that
class only.</p>
<p>Pretraining (<span class="citation">Craig et al. (2024)</span>) is a
method that bridges these two options; it has a parameter that allows
you to fit the pancancer model, the class specific models, and
everything in between. <code>ptLasso</code> is a package that fits
pretrained models using the <code>glmnet</code> package (<span class="citation">Friedman, Tibshirani, and Hastie (2010)</span>),
including lasso, elasticnet and ridge models.</p>
<p>Our example dataset consisting of ten different cancers is called
<strong>input grouped</strong>. There is a grouping on the rows of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
and each row belongs to one of the cancer classes. We want to fit a
specific model for each of the ten cancers, but we also want to share
information across all cancers. Importantly, pretraining is a general
method to pass information from one model to another – it has many uses
beyond what has already been discussed here, including time series data,
multi-response data and conditional average treatment effect estimation.
Some of these modeling tasks are not supported by the
<code>ptLasso</code> package, and the final section in this vignette
shows how to do pretraining for them using the <code>glmnet</code>
package. The remainder of this introduction describes the input grouped
setting.</p>
<!--Alternatively, data can be __target grouped__, where there is no grouping on the rows of $X$, but we have (for example) a multinomial outcome. We could fit one multinomial model, or we could fit a set of one-vs-rest models. Pretraining again bridges the two approaches, and this is described in detail in the section "Target grouped data". The remainder of this introduction describes the input grouped setting. -->
<p>Before we describe pretraining in more detail, we will first give a
quick review of the lasso.</p>
<div class="section level3">
<h3 id="review-of-the-lasso">Review of the lasso<a class="anchor" aria-label="anchor" href="#review-of-the-lasso"></a>
</h3>
<p>For the Gaussian family with data
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mi>…</mi><mi>n</mi></mrow><annotation encoding="application/x-tex">(x_i,y_i), i=1,2,\ldots n</annotation></semantics></math>,
the lasso has the form <span class="math display">$$\begin{equation}
{\rm argmin}_{\beta_0, \beta} \frac{1}{2} \sum_{i=1}^n(y_i- \beta_0
-\sum_{j=1}^p x_{ij}\beta_j)^2 + \lambda \sum_{j=1}^p |\beta_j |.
\end{equation}$$</span> Varying the regularization parameter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi><mo>≥</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\lambda \ge 0</annotation></semantics></math>
yields a path of solutions: an optimal value
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>λ</mi><mo accent="true">̂</mo></mover><annotation encoding="application/x-tex">\hat\lambda</annotation></semantics></math>
is usually chosen by cross-validation, using for example the
<code>cv.glmnet</code> function from the package
<code>glmnet</code>.</p>
<p>In GLMs and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mo>ℓ</mo><mn>1</mn></msub><annotation encoding="application/x-tex">\ell_1</annotation></semantics></math>-regularized
GLMs, one can include an <em>offset</em>: a pre-specified
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>-vector
that is included as an additional column to the feature matrix, but
whose weight
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>β</mi><mi>j</mi></msub><annotation encoding="application/x-tex">\beta_j</annotation></semantics></math>
is fixed at 1. Secondly, one can generalize the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mo>ℓ</mo><mn>1</mn></msub><annotation encoding="application/x-tex">\ell_1</annotation></semantics></math>
norm to a weighted norm, taking the form <span class="math display">$$\begin{equation}
\sum_j {\rm pf}_j |\beta_j |
\end{equation}$$</span> where each <span class="math inline">${\rm pf}_j
\ge 0$</span> is a <strong>penalty factor</strong> for feature
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>.
At the extremes, a penalty factor of zero implies no penalty and means
that the feature will always be included in the model; a penalty factor
of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo><mi>∞</mi></mrow><annotation encoding="application/x-tex">+\infty</annotation></semantics></math>
leads to that feature being discarded (i.e., never entered into the
model).</p>
</div>
<div class="section level3">
<h3 id="details-of-pretraining">Details of pretraining<a class="anchor" aria-label="anchor" href="#details-of-pretraining"></a>
</h3>
<p>For the input grouped setting, pretraining model fitting happens in
two steps. First, train a model using the full data:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>μ</mi><mo accent="true">̂</mo></mover><mn>0</mn></msub><mo>,</mo><msub><mover><mi>θ</mi><mo accent="true">̂</mo></mover><mn>1</mn></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mover><mi>θ</mi><mo accent="true">̂</mo></mover><mi>k</mi></msub><mo>,</mo><msub><mover><mi>β</mi><mo accent="true">̂</mo></mover><mn>0</mn></msub><mo>=</mo><mo>arg</mo><munder><mo>min</mo><mrow><msub><mi>μ</mi><mn>0</mn></msub><mo>,</mo><msub><mi>θ</mi><mn>1</mn></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mi>θ</mi><mi>k</mi></msub><mo>,</mo><msub><mi>β</mi><mn>0</mn></msub></mrow></munder><mfrac><mn>1</mn><mn>2</mn></mfrac><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mo stretchy="false" form="postfix">∥</mo><msub><mi>y</mi><mi>k</mi></msub><mo>−</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>μ</mi><mn>0</mn></msub><mn>𝟏</mn><mo>+</mo><msub><mi>θ</mi><mi>k</mi></msub><mn>𝟏</mn><mo>+</mo><msub><mi>X</mi><mi>k</mi></msub><msub><mi>β</mi><mn>0</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow><msubsup><mo stretchy="false" form="postfix">∥</mo><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><mrow><mo stretchy="true" form="prefix">|</mo><mo stretchy="true" form="postfix">|</mo></mrow><mi>β</mi><msub><mrow><mo stretchy="true" form="prefix">|</mo><mo stretchy="true" form="postfix">|</mo></mrow><mn>1</mn></msub><mo>,</mo></mrow><annotation encoding="application/x-tex">\begin{equation}
    \hat{\mu}_0, \hat{\theta}_1, \dots, \hat{\theta}_k, \hat{\beta}_0 = \arg \min_{\mu_0, \theta_1, \dots, \theta_k, \beta_0} \frac{1}{2} \sum_{k=1}^K \| y_k - \left(\mu_0 \mathbf{1} + \theta_k \mathbf{1} + X_k \beta_0\right) \|_2^2 + \lambda ||\beta||_1,
\end{equation}</annotation></semantics></math> where:</p>
<ul>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>X</mi><mi>k</mi></msub><mo>,</mo><msub><mi>y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">X_k, y_k</annotation></semantics></math>
are the observations in group
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>,</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>θ</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\theta_k</annotation></semantics></math>
is the group specific intercept for group
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
(by convention,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>θ</mi><mo accent="true">̂</mo></mover><mn>1</mn></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\hat{\theta}_1 = 0</annotation></semantics></math>),</li>
<li>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi><mo>,</mo><mi>β</mi></mrow><annotation encoding="application/x-tex">\mu, \beta</annotation></semantics></math>
are the overall intercept and coefficients,</li>
<li>and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>
is a parameter that has been chosen (perhaps the value minimizing the CV
error).</li>
</ul>
<p>Define
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>β</mi><mo accent="true">̂</mo></mover><mn>0</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">S(\hat\beta_0)</annotation></semantics></math>
to be the support set (the nonzero coefficients) of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>β</mi><mo accent="true">̂</mo></mover><mn>0</mn></msub><annotation encoding="application/x-tex">\hat{\beta}_0</annotation></semantics></math>.</p>
<p>Then, for each group
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>,
fit an <em>individual</em> model: find
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>β</mi><mo accent="true">̂</mo></mover><mi>k</mi></msub><annotation encoding="application/x-tex">\hat{\beta}_k</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mover><mi>μ</mi><mo accent="true">̂</mo></mover><mi>k</mi></msub><annotation encoding="application/x-tex">\hat{\mu}_k</annotation></semantics></math>
such that <span class="math display">$$\begin{eqnarray}
&amp;&amp; \hat{\mu}_k, \hat{\beta}_k = \arg \min_{\mu_k, \beta_k}
\frac{1}{2}  \| y_k - (1-\alpha) \left(\hat{\mu}_0 \mathbf{1} +
\hat{\theta}_k \mathbf{1} + X_k \hat{\beta}_0\right) - (\mu_k \mathbf{1}
+ X_k \beta_k) \|_2^2 +
\cr &amp;&amp; \phantom{\hat{\mu}_k, \hat{\beta}_k} \lambda_2
\sum_{j=1}^p \Bigl[ I(j \in S(\hat{\beta}_0))+ \frac{1}{\alpha} I(j
\notin S(\hat{\beta}_0))  \Bigr] |\beta_{kj}|,
\label{eq:model}
\end{eqnarray}$$</span> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>λ</mi><mn>2</mn></msub><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\lambda_2 &gt; 0</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>∈</mo><mrow><mo stretchy="true" form="prefix">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">\alpha\in [0,1]</annotation></semantics></math>
are hyperparameters that may be chosen through cross validation.</p>
<p>This is a lasso linear regression model with two additional
components: <em>offset</em>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>−</mo><mi>α</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>μ</mi><mo accent="true">̂</mo></mover><mn>0</mn></msub><mn>𝟏</mn><mo>+</mo><msub><mover><mi>θ</mi><mo accent="true">̂</mo></mover><mi>k</mi></msub><mn>𝟏</mn><mo>+</mo><msub><mi>X</mi><mi>k</mi></msub><msub><mover><mi>β</mi><mo accent="true">̂</mo></mover><mn>0</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">(1-\alpha) \left(\hat{\mu}_0 \mathbf{1} + \hat{\theta}_k \mathbf{1} + X_k \hat{\beta}_0\right)</annotation></semantics></math>,
and <em>penalty factor</em> for coefficient
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>
which is 1 if
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi><mo>∈</mo><mi>S</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>β</mi><mo accent="true">̂</mo></mover><mn>0</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">j \in S(\hat{\beta}_0)</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mfrac><mn>1</mn><mi>α</mi></mfrac><annotation encoding="application/x-tex">\frac{1}{\alpha}</annotation></semantics></math>
otherwise.</p>
<p>Notice that when
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\alpha=0</annotation></semantics></math>,
this returns the overall model fine tuned for each group: this second
stage model is only allowed to fit the residual
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>k</mi></msub><mo>−</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>μ</mi><mo accent="true">̂</mo></mover><mn>0</mn></msub><mn>𝟏</mn><mo>+</mo><msub><mover><mi>θ</mi><mo accent="true">̂</mo></mover><mi>k</mi></msub><mn>𝟏</mn><mo>+</mo><msub><mi>X</mi><mi>k</mi></msub><msub><mover><mi>β</mi><mo accent="true">̂</mo></mover><mn>0</mn></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">y_k - \left(\hat{\mu}_0 \mathbf{1} + \hat{\theta}_k \mathbf{1} + X_k \hat{\beta}_0\right)</annotation></semantics></math>,
and the penalty factor only allows the use of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>β</mi><mi>j</mi></msub><annotation encoding="application/x-tex">\beta_j</annotation></semantics></math>
if it was already selected by the overall model.</p>
<p>At the other extreme, when
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\alpha=1</annotation></semantics></math>,
this is equivalent to fitting a separate model for each class. There is
no offset, and the lasso penalty is 1 for all features (the usual lasso
penalty).</p>
</div>
<div class="section level3">
<h3 id="ptlasso-under-the-hood">
<code>ptLasso</code> under the hood<a class="anchor" aria-label="anchor" href="#ptlasso-under-the-hood"></a>
</h3>
<p>All model fitting in <code>ptLasso</code> is done with
<code>cv.glmnet</code>. The first step of pretraining is a
straightforward call to <code>cv.glmnet</code>; the second step is done
by calling <code>cv.glmnet</code> with:</p>
<ol style="list-style-type: decimal">
<li>
<code>offset</code>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>−</mo><mi>α</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mover><msub><mi>μ</mi><mn>0</mn></msub><mo accent="true">̂</mo></mover><mn>𝟏</mn><mo>+</mo><msub><mover><mi>θ</mi><mo accent="true">̂</mo></mover><mi>k</mi></msub><mn>𝟏</mn><mo>+</mo><msub><mi>X</mi><mi>k</mi></msub><mover><msub><mi>β</mi><mn>0</mn></msub><mo accent="true">̂</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">(1-\alpha) \left(\hat{\mu_0} \mathbf{1} + \hat{\theta}_k \mathbf{1} + X_k \hat{\beta_0}\right)</annotation></semantics></math>
and</li>
<li>
<code>penalty.factor</code>, the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>j</mi><mtext mathvariant="normal">th</mtext></msup><annotation encoding="application/x-tex">j^\text{th}</annotation></semantics></math>
entry of which is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>1</mn><annotation encoding="application/x-tex">1</annotation></semantics></math>
if
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi><mo>∈</mo><mi>S</mi><mrow><mo stretchy="true" form="prefix">(</mo><mover><msub><mi>β</mi><mn>0</mn></msub><mo accent="true">̂</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">j \in S(\hat{\beta_0})</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mfrac><mn>1</mn><mi>α</mi></mfrac><annotation encoding="application/x-tex">\frac{1}{\alpha}</annotation></semantics></math>
otherwise.</li>
</ol>
<p>Because <code>ptLasso</code> uses <code>cv.glmnet</code>, it inherits
most of the virtues of the <code>glmnet</code> package: for example, it
handles sparse input-matrix formats, as well as range constraints on
coefficients.</p>
<p>Additionally, one call to <code>ptLasso</code> fits an overall model,
pretrained class specific models, and class specific models for each
group (without pretraining). The <code>ptLasso</code> package also
includes methods for prediction and plotting, and a function that
performs K-fold cross-validation.</p>
</div>
</div>
<div class="section level2">
<h2 id="quick-start">Quick start<a class="anchor" aria-label="anchor" href="#quick-start"></a>
</h2>
<div class="section level3">
<h3 id="ptlasso-uses-the-same-syntax-as-glmnet">ptLasso uses the same syntax as glmnet<a class="anchor" aria-label="anchor" href="#ptlasso-uses-the-same-syntax-as-glmnet"></a>
</h3>
<p>For those familiar with <code>glmnet</code>, <code>ptLasso</code> has
a similar structure: <code>ptLasso</code> has functions to train, plot
and predict, and it follows the syntax of <code>glmnet</code>.</p>
<p>Additionally, <code>ptLasso</code> has a parameter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
that is analogous to the elasticnet parameter also called
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>.
To avoid confusion, we will refer to the elasticnet parameter as
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>α</mi><mtext mathvariant="normal">en</mtext></msub><annotation encoding="application/x-tex">\alpha_{\text{en}}</annotation></semantics></math>.
As with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>α</mi><mtext mathvariant="normal">en</mtext></msub><annotation encoding="application/x-tex">\alpha_{\text{en}}</annotation></semantics></math>
in <code>glmnet</code>, you must specify the value of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
that you want to use when calling <code>ptLasso</code>; the default is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">\alpha = 0.5</annotation></semantics></math>.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># The typical glmnet pipeline: train, plot and predict,</span></span>
<span><span class="co"># using elasticnet parameter 0.2.</span></span>
<span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/glmnet.html" class="external-link">glmnet</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span>, alpha <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span>
<span><span class="va">test.preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">Xtest</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># The typical ptLasso pipeline: train, plot and predict,</span></span>
<span><span class="co"># using pretraining parameter 0.5.</span></span>
<span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span>, <span class="va">groups</span>, alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span>
<span><span class="va">test.preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">Xtest</span>, <span class="va">groupstest</span><span class="op">)</span></span></code></pre></div>
<p>There are a few big differences between <code>ptLasso</code> and
<code>glmnet</code>:</p>
<ul>
<li>
<code>ptLasso</code> calls <code>cv.glmnet</code> under the hood:
cross validation over
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>
is done automatically, and</li>
<li>the <code>ptLasso</code> package includes <code>cv.ptLasso</code>: a
function to do cross validation over
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>.</li>
</ul>
<p>With cross validation, the typical <code>ptLasso</code> pipeline
looks like:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/cv.ptLasso.html">cv.ptLasso</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span>, <span class="va">groups</span>, alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span>
<span><span class="va">test.preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">Xtest</span>, <span class="va">groupstest</span><span class="op">)</span></span></code></pre></div>
<p>The <code>predict</code> function uses the value of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
that achieved the best average CV performance across groups. But it is
possible to instead use a different
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
for each group (specifically the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
that achieved the best CV performance <em>for each group</em>). An
example is at the end of this section.</p>
</div>
<div class="section level3">
<h3 id="an-example">An example<a class="anchor" aria-label="anchor" href="#an-example"></a>
</h3>
<p>First, we load the <code>ptLasso</code> package:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va"><a href="https://erincr.github.io/ptLasso/">ptLasso</a></span><span class="op">)</span></span>
<span><span class="co">#&gt; Loading required package: ptLasso</span></span>
<span><span class="co">#&gt; Loading required package: ggplot2</span></span>
<span><span class="co">#&gt; Loading required package: glmnet</span></span>
<span><span class="co">#&gt; Loading required package: Matrix</span></span>
<span><span class="co">#&gt; Loaded glmnet 4.1-8</span></span>
<span><span class="co">#&gt; Loading required package: gridExtra</span></span></code></pre></div>
<p>To show how to use <code>ptLasso</code>, we’ll simulate data with 5
groups and a continuous response using the helper function
<code>gaussian.example.data</code>. There are
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>200</mn></mrow><annotation encoding="application/x-tex">n = 200</annotation></semantics></math>
observations in each group and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>=</mo><mn>120</mn></mrow><annotation encoding="application/x-tex">p = 120</annotation></semantics></math>
features. All groups share 10 informative features; though the features
are shared, they have different coefficient values. Each group has 10
additional features that are specific to that group, and all other
features are uninformative.
<!--The coefficients for the 5 groups are in Table \@ref(tab:coefs).--></p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="va">out</span> <span class="op">=</span> <span class="fu"><a href="../reference/gaussian.example.data.html">gaussian.example.data</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="va">out</span><span class="op">$</span><span class="va">x</span>; <span class="va">y</span> <span class="op">=</span> <span class="va">out</span><span class="op">$</span><span class="va">y</span>; <span class="va">groups</span> <span class="op">=</span> <span class="va">out</span><span class="op">$</span><span class="va">groups</span></span>
<span></span>
<span><span class="va">outtest</span> <span class="op">=</span> <span class="fu"><a href="../reference/gaussian.example.data.html">gaussian.example.data</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">xtest</span> <span class="op">=</span> <span class="va">outtest</span><span class="op">$</span><span class="va">x</span>; <span class="va">ytest</span> <span class="op">=</span> <span class="va">outtest</span><span class="op">$</span><span class="va">y</span>; <span class="va">groupstest</span> <span class="op">=</span> <span class="va">outtest</span><span class="op">$</span><span class="va">groups</span></span></code></pre></div>
<p>Now we are ready to fit a model using <code>ptLasso</code>. We’ll use
the pretraining parameter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">\alpha = 0.5</annotation></semantics></math>
(randomly chosen).</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span></code></pre></div>
<!--In practice we recommend choosing $\alpha$ more thoughtfully by using (1) a validation set to measure performance for a few different choices of $\alpha$ (e.g. $0, 0.25, 0.5, 0.75, 1.0$), or (2) `cv.ptLasso`, which will recommend a choice of $\alpha$ based on CV performance.-->
<p>The function <code>ptLasso</code> used <code>cv.glmnet</code> to fit
11 models:</p>
<ul>
<li>the <em>overall</em> model (using all 5 groups),</li>
<li>the 5 <em>pretrained</em> models (one for each group) and</li>
<li>the 5 <em>individual</em> models (one for each group).</li>
</ul>
<p>A call to <code>plot</code> displays the cross validation curves for
each model. The top row shows the overall model, the middle row the
pretrained models, and the bottom row the individual models.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span></code></pre></div>
<p><img src="ptLasso_files/figure-html/unnamed-chunk-6-1.png" width="700"></p>
<p><code>predict</code> makes predictions from all
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>11</mn><annotation encoding="application/x-tex">11</annotation></semantics></math>
models. It returns a list containing:</p>
<ol style="list-style-type: decimal">
<li>
<code>yhatoverall</code> (predictions from the overall model),</li>
<li>
<code>yhatpre</code> (predictions from the pretrained models)
and</li>
<li>
<code>yhatind</code> (predictions from the individual models).</li>
</ol>
<p>By default, <code>predict</code> uses <code>lambda.min</code> for all
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>11</mn><annotation encoding="application/x-tex">11</annotation></semantics></math><code>cv.glmnet</code> models; you could instead specify
<code>s = lambda.1se</code> or use a numeric value. Whatever value of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>
you choose will be used for all models (overall, pretrained and
individual).</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">xtest</span>, groupstest<span class="op">=</span><span class="va">groupstest</span><span class="op">)</span></span></code></pre></div>
<p>If you also provide <code>ytest</code> (for model validation),
<code>predict</code> will additionally compute performance measures.
<!---For continuous outcomes, `predict` computes the mean squared prediction error by default; the argument `type.measure = "mae"` would compute the mean absolute prediction error instead.---></p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">xtest</span>, groupstest<span class="op">=</span><span class="va">groupstest</span>, ytest<span class="op">=</span><span class="va">ytest</span><span class="op">)</span></span>
<span><span class="va">preds</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.ptLasso(object = fit, xtest = xtest, groupstest = groupstest,  </span></span>
<span><span class="co">#&gt;     ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0.5 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (Mean squared error):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            allGroups  mean group_1 group_2 group_3 group_4 group_5    r^2</span></span>
<span><span class="co">#&gt; Overall        755.7 755.7   836.0   554.9   565.4   777.9  1044.0 0.5371</span></span>
<span><span class="co">#&gt; Pretrain       503.2 503.2   550.6   443.3   553.5   505.6   462.9 0.6918</span></span>
<span><span class="co">#&gt; Individual     532.8 532.8   584.1   443.2   567.2   550.5   518.9 0.6736</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                          </span></span>
<span><span class="co">#&gt; Overall    64                            </span></span>
<span><span class="co">#&gt; Pretrain   94 (21 common + 73 individual)</span></span>
<span><span class="co">#&gt; Individual 109</span></span></code></pre></div>
<p>To access the coefficients of the fitted models, use
<code>coef</code> as usual. This returns a list with the coefficients of
the individual models, pretrained models and overall models, as returned
by <code>glmnet</code>.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">all.coefs</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">fit</span>, s<span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">all.coefs</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "individual" "pretrain"   "overall"</span></span></code></pre></div>
<p>The entries for the individual and pretrained models are lists with
one entry for each group. Because we have 5 groups, we’ll have 5 sets of
coefficients.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">all.coefs</span><span class="op">$</span><span class="va">pretrain</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 5</span></span></code></pre></div>
<p>The first few coefficients for group 1 from the pretrained model
are:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">all.coefs</span><span class="op">$</span><span class="va">pretrain</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">#&gt; 6 x 1 sparse Matrix of class "dgCMatrix"</span></span>
<span><span class="co">#&gt;                     s1</span></span>
<span><span class="co">#&gt; (Intercept)  0.5088629</span></span>
<span><span class="co">#&gt; V1          -4.0203684</span></span>
<span><span class="co">#&gt; V2           .        </span></span>
<span><span class="co">#&gt; V3           .        </span></span>
<span><span class="co">#&gt; V4          -0.1923623</span></span>
<span><span class="co">#&gt; V5          -0.6581933</span></span></code></pre></div>
<p>When we used <code>ptLasso</code> to fit a model, we chose
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">\alpha = 0.5</annotation></semantics></math>.
In practice we recommend choosing
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
more thoughtfully by using (1) a validation set to measure performance
for a few different choices of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
(e.g. <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>,</mo><mn>0.25</mn><mo>,</mo><mn>0.5</mn><mo>,</mo><mn>0.75</mn><mo>,</mo><mn>1.0</mn></mrow><annotation encoding="application/x-tex">0, 0.25, 0.5, 0.75, 1.0</annotation></semantics></math>)
or (2) the function <code>cv.ptLasso</code>.</p>
<p>The call to <code>cv.ptLasso</code> is nearly identical to that for
<code>ptLasso</code>. By default, <code>cv.ptLasso</code> will try
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0</mn><mo>,</mo><mn>0.1</mn><mo>,</mo><mn>0.2</mn><mo>,</mo><mi>…</mi><mo>,</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\alpha = 0, 0.1, 0.2, \dots, 1</annotation></semantics></math>,
but this can be changed with the argument <code>alphalist</code>. After
fitting, printing the <code>cv.ptLasso</code> object shows the cross
validated mean squared error for all models.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cvfit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cv.ptLasso.html">cv.ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span><span class="op">)</span></span>
<span><span class="va">cvfit</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; cv.ptLasso(x = x, y = y, groups = groups, family = "gaussian",  </span></span>
<span><span class="co">#&gt;     type.measure = "mse", use.case = "inputGroups", group.intercepts = TRUE) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; type.measure:  mse </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            alpha overall  mean wtdMean group_1 group_2 group_3 group_4 group_5</span></span>
<span><span class="co">#&gt; Overall            696.4 696.4   696.4   739.5   500.8   566.4   669.4  1005.9</span></span>
<span><span class="co">#&gt; Pretrain     0.0   523.2 523.2   523.2   511.2   475.1   513.8   521.5   594.3</span></span>
<span><span class="co">#&gt; Pretrain     0.1   512.9 512.9   512.9   417.7   471.3   554.8   537.5   583.4</span></span>
<span><span class="co">#&gt; Pretrain     0.2   501.0 501.0   501.0   415.3   449.9   539.1   496.4   604.2</span></span>
<span><span class="co">#&gt; Pretrain     0.3   494.5 494.5   494.5   409.4   432.8   536.9   512.2   581.3</span></span>
<span><span class="co">#&gt; Pretrain     0.4   486.9 486.9   486.9   390.7   420.2   536.0   522.4   565.1</span></span>
<span><span class="co">#&gt; Pretrain     0.5   507.2 507.2   507.2   411.3   451.4   577.4   532.5   563.7</span></span>
<span><span class="co">#&gt; Pretrain     0.6   506.9 506.9   506.9   382.7   448.0   573.1   497.0   633.6</span></span>
<span><span class="co">#&gt; Pretrain     0.7   504.9 504.9   504.9   377.7   485.2   582.1   507.0   572.7</span></span>
<span><span class="co">#&gt; Pretrain     0.8   496.4 496.4   496.4   395.9   471.5   573.7   488.8   552.1</span></span>
<span><span class="co">#&gt; Pretrain     0.9   526.0 526.0   526.0   384.4   482.8   605.6   522.9   634.2</span></span>
<span><span class="co">#&gt; Pretrain     1.0   538.8 538.8   538.8   422.4   506.6   604.4   533.8   626.8</span></span>
<span><span class="co">#&gt; Individual         538.8 538.8   538.8   422.4   506.6   604.4   533.8   626.8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alphahat (fixed) = 0.4</span></span>
<span><span class="co">#&gt; alphahat (varying):</span></span>
<span><span class="co">#&gt; group_1 group_2 group_3 group_4 group_5 </span></span>
<span><span class="co">#&gt;     0.7     0.4     0.0     0.8     0.8</span></span></code></pre></div>
<p>Plotting the <code>cv.ptLasso</code> object visualizes performance as
a function of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">cvfit</span><span class="op">)</span></span></code></pre></div>
<p><img src="ptLasso_files/figure-html/unnamed-chunk-13-1.png" width="500"></p>
<p>And, as with <code>ptLasso</code>, we can <code>predict</code>. By
default, <code>predict</code> uses the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
that minimized the cross validated MSE.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">cvfit</span>, <span class="va">xtest</span>, groupstest<span class="op">=</span><span class="va">groupstest</span>, ytest<span class="op">=</span><span class="va">ytest</span><span class="op">)</span></span>
<span><span class="va">preds</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.cv.ptLasso(object = cvfit, xtest = xtest, groupstest = groupstest,  </span></span>
<span><span class="co">#&gt;     ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0.4 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (Mean squared error):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            allGroups  mean group_1 group_2 group_3 group_4 group_5    r^2</span></span>
<span><span class="co">#&gt; Overall        757.1 757.1   815.7   542.6   567.1   792.7  1067.5 0.5362</span></span>
<span><span class="co">#&gt; Pretrain       511.1 511.1   579.7   460.1   547.5   502.9   465.6 0.6869</span></span>
<span><span class="co">#&gt; Individual     527.9 527.9   563.5   441.8   567.2   548.0   518.9 0.6766</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                          </span></span>
<span><span class="co">#&gt; Overall    50                            </span></span>
<span><span class="co">#&gt; Pretrain   86 (29 common + 57 individual)</span></span>
<span><span class="co">#&gt; Individual 109</span></span></code></pre></div>
<p>We could instead use the argument <code>alphatype = "varying"</code>
to use a different
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
for each group – we choose the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
that minimizes the CV MSE for each group:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">cvfit</span>, <span class="va">xtest</span>, groupstest<span class="op">=</span><span class="va">groupstest</span>, ytest<span class="op">=</span><span class="va">ytest</span>, </span>
<span>                alphatype<span class="op">=</span><span class="st">"varying"</span><span class="op">)</span></span>
<span><span class="va">preds</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.cv.ptLasso(object = cvfit, xtest = xtest, groupstest = groupstest,  </span></span>
<span><span class="co">#&gt;     ytest = ytest, alphatype = "varying") </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha:</span></span>
<span><span class="co">#&gt; [1] 0.7 0.4 0.0 0.8 0.8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (Mean squared error):</span></span>
<span><span class="co">#&gt;            overall  mean wtdMean group_1 group_2 group_3 group_4 group_5</span></span>
<span><span class="co">#&gt; Overall      757.1 757.1   757.1   815.7   542.6   567.1   792.7  1067.5</span></span>
<span><span class="co">#&gt; Pretrain     505.0 505.0   505.0   502.6   460.1   542.4   537.9   481.8</span></span>
<span><span class="co">#&gt; Individual   527.9 527.9   527.9   563.5   441.8   567.2   548.0   518.9</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                           </span></span>
<span><span class="co">#&gt; Overall    50                             </span></span>
<span><span class="co">#&gt; Pretrain   103 (29 common + 74 individual)</span></span>
<span><span class="co">#&gt; Individual 109</span></span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="other-details">Other details<a class="anchor" aria-label="anchor" href="#other-details"></a>
</h2>
<div class="section level3">
<h3 id="choosing-alpha-the-pretraining-parameter">Choosing
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>,
the pretraining parameter<a class="anchor" aria-label="anchor" href="#choosing-alpha-the-pretraining-parameter"></a>
</h3>
<p>Selecting the parameter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
is an important part of pretraining. The simplest way to do this is to
use <code>cv.ptLasso</code> – this will automatically perform
pretraining for a range of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
values and return the CV performance for each. The default values for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
are
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>,</mo><mn>0.1</mn><mo>,</mo><mn>0.2</mn><mo>,</mo><mi>…</mi><mo>,</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">0, 0.1, 0.2, \dots, 1</annotation></semantics></math>.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cvfit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cv.ptLasso.html">cv.ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span><span class="op">)</span></span>
<span><span class="va">cvfit</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; cv.ptLasso(x = x, y = y, groups = groups, family = "gaussian",  </span></span>
<span><span class="co">#&gt;     type.measure = "mse", use.case = "inputGroups", group.intercepts = TRUE) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; type.measure:  mse </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            alpha overall  mean wtdMean group_1 group_2 group_3 group_4 group_5</span></span>
<span><span class="co">#&gt; Overall            699.7 699.7   699.7   748.4   501.9   575.6   663.0  1009.9</span></span>
<span><span class="co">#&gt; Pretrain     0.0   518.6 518.6   518.6   470.1   471.5   547.0   540.7   563.7</span></span>
<span><span class="co">#&gt; Pretrain     0.1   506.0 506.0   506.0   429.7   452.1   538.7   551.1   558.3</span></span>
<span><span class="co">#&gt; Pretrain     0.2   495.3 495.3   495.3   393.6   460.6   565.5   530.9   526.1</span></span>
<span><span class="co">#&gt; Pretrain     0.3   490.4 490.4   490.4   390.4   436.5   546.3   511.6   567.4</span></span>
<span><span class="co">#&gt; Pretrain     0.4   487.5 487.5   487.5   383.7   438.8   545.6   509.4   560.3</span></span>
<span><span class="co">#&gt; Pretrain     0.5   481.2 481.2   481.2   364.9   429.7   548.5   513.4   549.7</span></span>
<span><span class="co">#&gt; Pretrain     0.6   504.1 504.1   504.1   393.1   460.0   586.4   531.9   549.0</span></span>
<span><span class="co">#&gt; Pretrain     0.7   511.5 511.5   511.5   393.2   462.7   584.3   492.9   624.3</span></span>
<span><span class="co">#&gt; Pretrain     0.8   509.1 509.1   509.1   382.4   496.2   597.9   503.4   565.6</span></span>
<span><span class="co">#&gt; Pretrain     0.9   501.5 501.5   501.5   404.0   481.6   581.9   488.3   552.0</span></span>
<span><span class="co">#&gt; Pretrain     1.0   517.1 517.1   517.1   409.1   488.9   612.7   484.7   590.1</span></span>
<span><span class="co">#&gt; Individual         517.1 517.1   517.1   409.1   488.9   612.7   484.7   590.1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alphahat (fixed) = 0.5</span></span>
<span><span class="co">#&gt; alphahat (varying):</span></span>
<span><span class="co">#&gt; group_1 group_2 group_3 group_4 group_5 </span></span>
<span><span class="co">#&gt;     0.5     0.5     0.1     1.0     0.2</span></span></code></pre></div>
<p>Of course, you can specify the values of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
to consider:</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cvfit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cv.ptLasso.html">cv.ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, alphalist <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.5</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">cvfit</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; cv.ptLasso(x = x, y = y, groups = groups, alphalist = c(0, 0.5,  </span></span>
<span><span class="co">#&gt;     1), family = "gaussian", type.measure = "mse", use.case = "inputGroups",  </span></span>
<span><span class="co">#&gt;     group.intercepts = TRUE) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; type.measure:  mse </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            alpha overall  mean wtdMean group_1 group_2 group_3 group_4 group_5</span></span>
<span><span class="co">#&gt; Overall            708.8 708.8   708.8   739.0   514.4   575.4   665.0  1050.1</span></span>
<span><span class="co">#&gt; Pretrain     0.0   524.4 524.4   524.4   481.7   485.7   529.4   526.8   598.4</span></span>
<span><span class="co">#&gt; Pretrain     0.5   496.3 496.3   496.3   365.0   448.5   569.3   507.5   591.1</span></span>
<span><span class="co">#&gt; Pretrain     1.0   526.4 526.4   526.4   399.4   513.5   611.8   492.9   614.6</span></span>
<span><span class="co">#&gt; Individual         526.4 526.4   526.4   399.4   513.5   611.8   492.9   614.6</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alphahat (fixed) = 0.5</span></span>
<span><span class="co">#&gt; alphahat (varying):</span></span>
<span><span class="co">#&gt; group_1 group_2 group_3 group_4 group_5 </span></span>
<span><span class="co">#&gt;     0.5     0.5     0.0     1.0     0.5</span></span></code></pre></div>
<p>At prediction time, <code>cv.ptLasso</code> uses the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
that had the best CV performance on average across all groups. We could
instead choose to use a different
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
for each group, as <code>cv.ptLasso</code> already figured out which
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
optimizes the CV performance for each group. To use group-specific
values of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>,
specify <code>alphatype = "varying"</code> at prediction time. In this
example, the best group-specific
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
values all happen to be
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>0.5</mn><annotation encoding="application/x-tex">0.5</annotation></semantics></math>
– the same as the overall
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">###############################################</span></span>
<span><span class="co"># Common alpha for all groups:</span></span>
<span><span class="co">###############################################</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">cvfit</span>, <span class="va">xtest</span>, <span class="va">groupstest</span>, ytest<span class="op">=</span><span class="va">ytest</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.cv.ptLasso(object = cvfit, xtest = xtest, groupstest = groupstest,  </span></span>
<span><span class="co">#&gt;     ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0.5 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (Mean squared error):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            allGroups  mean group_1 group_2 group_3 group_4 group_5    r^2</span></span>
<span><span class="co">#&gt; Overall        757.1 757.1   815.7   542.6   567.1   792.7  1067.5 0.5362</span></span>
<span><span class="co">#&gt; Pretrain       507.0 507.0   556.6   446.3   556.6   504.1   471.4 0.6894</span></span>
<span><span class="co">#&gt; Individual     527.9 527.9   572.6   443.2   562.4   550.5   510.7 0.6766</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                          </span></span>
<span><span class="co">#&gt; Overall    50                            </span></span>
<span><span class="co">#&gt; Pretrain   95 (25 common + 70 individual)</span></span>
<span><span class="co">#&gt; Individual 110</span></span>
<span></span>
<span><span class="co">###############################################</span></span>
<span><span class="co"># Different alpha for each group:</span></span>
<span><span class="co">###############################################</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">cvfit</span>, <span class="va">xtest</span>, <span class="va">groupstest</span>, ytest<span class="op">=</span><span class="va">ytest</span>, alphatype <span class="op">=</span> <span class="st">"varying"</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.cv.ptLasso(object = cvfit, xtest = xtest, groupstest = groupstest,  </span></span>
<span><span class="co">#&gt;     ytest = ytest, alphatype = "varying") </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha:</span></span>
<span><span class="co">#&gt; [1] 0.5 0.5 0.0 1.0 0.5</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (Mean squared error):</span></span>
<span><span class="co">#&gt;            overall  mean wtdMean group_1 group_2 group_3 group_4 group_5</span></span>
<span><span class="co">#&gt; Overall      757.1 757.1   757.1   815.7   542.6   567.1   792.7  1067.5</span></span>
<span><span class="co">#&gt; Pretrain     517.3 517.3   517.3   556.6   446.3   561.5   550.5   471.4</span></span>
<span><span class="co">#&gt; Individual   527.9 527.9   527.9   572.6   443.2   562.4   550.5   510.7</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                          </span></span>
<span><span class="co">#&gt; Overall    50                            </span></span>
<span><span class="co">#&gt; Pretrain   99 (25 common + 74 individual)</span></span>
<span><span class="co">#&gt; Individual 110</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="choosing-lambda-the-lasso-path-parameter-for-the-first-stage-of-pretraining">Choosing
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>,
the lasso path parameter, for the first stage of pretraining<a class="anchor" aria-label="anchor" href="#choosing-lambda-the-lasso-path-parameter-for-the-first-stage-of-pretraining"></a>
</h3>
<p>The first step of pretraining fits the overall model with
<code>cv.glmnet</code> and selects a model along the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>
path. The second stage uses the overall model’s support and predictions
to train the group-specific models.</p>
<p>At train time, we need to know choose a value of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>
to use for the first stage. This can be specified in
<code>ptLasso</code> with the argument <code>overall.lambda</code>. The
default value is “lambda.1se”, but <code>overall.lambda</code> can
accept “lambda.1se” or “lambda.min”.</p>
<p>Whatever choice is made at train time will be automatically used at
test time, and this cannot be changed. The fitted model from the second
stage of pretraining expects the offset to have been computed using a
particular model – it does not make sense to compute the offset using a
model with a different
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>.</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Default:</span></span>
<span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>, overall.lambda <span class="op">=</span> <span class="st">"lambda.1se"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Alternative:</span></span>
<span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>, overall.lambda <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="fitting-elasticnet-or-ridge-models">Fitting elasticnet or ridge models<a class="anchor" aria-label="anchor" href="#fitting-elasticnet-or-ridge-models"></a>
</h3>
<p>By default, <code>ptLasso</code> fits lasso penalized models; in
<code>glmnet</code>, this corresponds to the elasticnet parameter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mtext mathvariant="normal">en</mtext></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\alpha_\text{en} = 1</annotation></semantics></math>
(where the subscript <code>en</code> stands for “elasticnet”). Fitting
pretrained elasticnet or ridge models is also possible with
<code>ptLasso</code>: use argument <code>en.alpha</code> between
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>0</mn><annotation encoding="application/x-tex">0</annotation></semantics></math>
(ridge) and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>1</mn><annotation encoding="application/x-tex">1</annotation></semantics></math>
(lasso). Here is an example using the pretraining parameter
<code>alpha = 0.5</code> and the elasticnet parameter
<code>en.alpha = 0.2</code>.</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, </span>
<span>               alpha <span class="op">=</span> <span class="fl">0.5</span>,    <span class="co"># pretraining parameter</span></span>
<span>               en.alpha <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span> <span class="co"># elasticnet parameter</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="printing-progress-during-model-training">Printing progress during model training<a class="anchor" aria-label="anchor" href="#printing-progress-during-model-training"></a>
</h3>
<p>When models take a long time to train, it can be useful to print out
progress during training. <code>ptLasso</code> has two ways to do this
(and they can be combined). First, we can simply print out which model
is being fitted using <code>verbose = TRUE</code>:</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>, verbose <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; Fitting overall model</span></span>
<span><span class="co">#&gt; Fitting individual models</span></span>
<span><span class="co">#&gt;  Fitting individual model 1 / 5</span></span>
<span><span class="co">#&gt;  Fitting individual model 2 / 5</span></span>
<span><span class="co">#&gt;  Fitting individual model 3 / 5</span></span>
<span><span class="co">#&gt;  Fitting individual model 4 / 5</span></span>
<span><span class="co">#&gt;  Fitting individual model 5 / 5</span></span>
<span><span class="co">#&gt; Fitting pretrained lasso models</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 1 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 2 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 3 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 4 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 5 / 5</span></span></code></pre></div>
<p>We can also print out a progress bar for <em>each model</em> that is
being fit – this functionality comes directly from
<code>cv.glmnet</code>, and follows its notation. (To avoid cluttering
this document, we do not run the following example.)</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>, trace.it <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<p>And of course, we can combine these to print out (1) which model is
being trained and (2) the corresponding progress bar.</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>, verbose <span class="op">=</span> <span class="cn">TRUE</span>, trace.it <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="using-individual-and-overall-models-that-were-previously-trained">Using individual and overall models that were previously
trained<a class="anchor" aria-label="anchor" href="#using-individual-and-overall-models-that-were-previously-trained"></a>
</h3>
<p><code>ptLasso</code> will fit the overall and individual models.
However, if you have already trained the overall or individual models,
you can save compute time by passing them directly to
<code>ptLasso</code> – they will not be refitted.
<strong><code>ptLasso</code> expects that these models were fitted using
the same training data that you pass to <code>ptLasso</code>, and that
they were fitted with the argument <code>keep = TRUE</code>.</strong>
Here is an example. We will fit an overall model and individual models,
and then we will show how to pass them to <code>ptLasso</code>. Using
<code>verbose = TRUE</code> in the call to <code>ptLasso</code> shows us
what models are being trained (and confirms that we are not refitting
the overall and individual models).</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">overall.model</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, keep <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">individual.models</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">lapply</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span>, </span>
<span>                           <span class="kw">function</span><span class="op">(</span><span class="va">kk</span><span class="op">)</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="va">kk</span>, <span class="op">]</span>, </span>
<span>                                                  <span class="va">y</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="va">kk</span><span class="op">]</span>, </span>
<span>                                                  keep <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, </span>
<span>               fitoverall <span class="op">=</span> <span class="va">overall.model</span>,</span>
<span>               fitind <span class="op">=</span> <span class="va">individual.models</span>,</span>
<span>               verbose <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; Fitting pretrained lasso models</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 1 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 2 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 3 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 4 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 5 / 5</span></span></code></pre></div>
<p>Of course we could pass just the overall <em>or</em> individual
models to `ptLasso:</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, fitoverall <span class="op">=</span> <span class="va">overall.model</span>, verbose <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; Fitting individual models</span></span>
<span><span class="co">#&gt;  Fitting individual model 1 / 5</span></span>
<span><span class="co">#&gt;  Fitting individual model 2 / 5</span></span>
<span><span class="co">#&gt;  Fitting individual model 3 / 5</span></span>
<span><span class="co">#&gt;  Fitting individual model 4 / 5</span></span>
<span><span class="co">#&gt;  Fitting individual model 5 / 5</span></span>
<span><span class="co">#&gt; Fitting pretrained lasso models</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 1 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 2 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 3 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 4 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 5 / 5</span></span></code></pre></div>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, fitind <span class="op">=</span> <span class="va">individual.models</span>, verbose <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; Fitting overall model</span></span>
<span><span class="co">#&gt; Fitting pretrained lasso models</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 1 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 2 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 3 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 4 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 5 / 5</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="fitting-the-overall-model-without-group-specific-intercepts">Fitting the overall model without group-specific intercepts<a class="anchor" aria-label="anchor" href="#fitting-the-overall-model-without-group-specific-intercepts"></a>
</h3>
<p>When we fit the overall model with input grouped data, we solve the
following:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><msub><mi>μ</mi><mn>0</mn></msub><mo accent="true">̂</mo></mover><mo>,</mo><mover><msub><mi>θ</mi><mn>2</mn></msub><mo accent="true">̂</mo></mover><mo>,</mo><mi>…</mi><mo>,</mo><mover><msub><mi>θ</mi><mi>K</mi></msub><mo accent="true">̂</mo></mover><mo>,</mo><mover><msub><mi>β</mi><mn>0</mn></msub><mo accent="true">̂</mo></mover><mo>=</mo><mo>arg</mo><munder><mo>min</mo><mrow><mi>μ</mi><mo>,</mo><msub><mi>θ</mi><mn>2</mn></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mi>θ</mi><mi>k</mi></msub><mo>,</mo><mi>β</mi></mrow></munder><mfrac><mn>1</mn><mn>2</mn></mfrac><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mo stretchy="false" form="postfix">∥</mo><msub><mi>y</mi><mi>k</mi></msub><mo>−</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>μ</mi><mn>𝟏</mn><mo>+</mo><msub><mi>θ</mi><mi>k</mi></msub><mn>𝟏</mn><mo>+</mo><msub><mi>X</mi><mi>k</mi></msub><mi>β</mi><mo stretchy="true" form="postfix">)</mo></mrow><msubsup><mo stretchy="false" form="postfix">∥</mo><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><mrow><mo stretchy="true" form="prefix">|</mo><mo stretchy="true" form="postfix">|</mo></mrow><mi>β</mi><msub><mrow><mo stretchy="true" form="prefix">|</mo><mo stretchy="true" form="postfix">|</mo></mrow><mn>1</mn></msub><mo>,</mo></mrow><annotation encoding="application/x-tex">\begin{equation}
    \hat{\mu_0}, \hat{\theta_2}, \dots, \hat{\theta_K}, \hat{\beta_0} = \arg \min_{\mu, \theta_2, \dots, \theta_k, \beta} \frac{1}{2} \sum_{k=1}^K \| y_k - \left(\mu \mathbf{1} + \theta_k \mathbf{1} + X_k \beta\right) \|_2^2 + \lambda ||\beta||_1,
\end{equation}</annotation></semantics></math> where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><msub><mi>θ</mi><mn>1</mn></msub><mo accent="true">̂</mo></mover><annotation encoding="application/x-tex">\hat{\theta_1}</annotation></semantics></math>
is defined to be
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>0</mn><annotation encoding="application/x-tex">0</annotation></semantics></math>.
We can instead omit
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>θ</mi><mn>1</mn></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mi>θ</mi><mi>K</mi></msub></mrow><annotation encoding="application/x-tex">\theta_1, \dots, \theta_K</annotation></semantics></math>
and instead fit the following:
<math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><msub><mi>μ</mi><mn>0</mn></msub><mo accent="true">̂</mo></mover><mo>,</mo><mover><msub><mi>β</mi><mn>0</mn></msub><mo accent="true">̂</mo></mover><mo>=</mo><mo>arg</mo><munder><mo>min</mo><mrow><mi>μ</mi><mo>,</mo><mi>β</mi></mrow></munder><mfrac><mn>1</mn><mn>2</mn></mfrac><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><mo stretchy="false" form="postfix">∥</mo><msub><mi>y</mi><mi>k</mi></msub><mo>−</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>μ</mi><mn>𝟏</mn><mo>+</mo><msub><mi>X</mi><mi>k</mi></msub><mi>β</mi><mo stretchy="true" form="postfix">)</mo></mrow><msubsup><mo stretchy="false" form="postfix">∥</mo><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mi>λ</mi><mrow><mo stretchy="true" form="prefix">|</mo><mo stretchy="true" form="postfix">|</mo></mrow><mi>β</mi><msub><mrow><mo stretchy="true" form="prefix">|</mo><mo stretchy="true" form="postfix">|</mo></mrow><mn>1</mn></msub><mi>.</mi></mrow><annotation encoding="application/x-tex">\begin{equation}
    \hat{\mu_0}, \hat{\beta_0} = \arg \min_{\mu, \beta} \frac{1}{2} \sum_{k=1}^K \| y_k - \left(\mu \mathbf{1} + X_k \beta\right) \|_2^2 + \lambda ||\beta||_1.
\end{equation}</annotation></semantics></math> This may be useful in
settings where the groups are different between train and test sets (see
“Different groups in train and test data” under “Input grouped data”).
To do this, use the argument <code>group.intercepts = FALSE</code>.</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cvfit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cv.ptLasso.html">cv.ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, group.intercepts <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="va">cvfit</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; cv.ptLasso(x = x, y = y, groups = groups, group.intercepts = FALSE,  </span></span>
<span><span class="co">#&gt;     family = "gaussian", type.measure = "mse", use.case = "inputGroups") </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; type.measure:  mse </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            alpha overall  mean wtdMean group_1 group_2 group_3 group_4 group_5</span></span>
<span><span class="co">#&gt; Overall            696.2 696.2   696.2   694.7   489.2   580.5   670.0  1046.4</span></span>
<span><span class="co">#&gt; Pretrain     0.0   508.9 508.9   508.9   463.3   457.0   525.2   536.0   562.8</span></span>
<span><span class="co">#&gt; Pretrain     0.1   491.0 491.0   491.0   431.3   456.8   526.8   497.9   542.1</span></span>
<span><span class="co">#&gt; Pretrain     0.2   487.7 487.7   487.7   395.9   457.7   522.4   510.4   552.3</span></span>
<span><span class="co">#&gt; Pretrain     0.3   486.6 486.6   486.6   398.3   451.9   522.6   511.7   548.6</span></span>
<span><span class="co">#&gt; Pretrain     0.4   494.9 494.9   494.9   384.1   475.8   529.1   516.0   569.6</span></span>
<span><span class="co">#&gt; Pretrain     0.5   494.7 494.7   494.7   382.9   444.1   553.7   488.4   604.5</span></span>
<span><span class="co">#&gt; Pretrain     0.6   480.4 480.4   480.4   352.8   455.2   545.6   489.1   559.4</span></span>
<span><span class="co">#&gt; Pretrain     0.7   512.8 512.8   512.8   381.0   517.0   573.2   501.6   591.4</span></span>
<span><span class="co">#&gt; Pretrain     0.8   509.6 509.6   509.6   389.9   470.0   602.6   510.4   574.9</span></span>
<span><span class="co">#&gt; Pretrain     0.9   512.4 512.4   512.4   393.5   477.9   600.7   497.6   592.1</span></span>
<span><span class="co">#&gt; Pretrain     1.0   526.8 526.8   526.8   409.5   502.1   622.5   492.3   607.6</span></span>
<span><span class="co">#&gt; Individual         526.8 526.8   526.8   409.5   502.1   622.5   492.3   607.6</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alphahat (fixed) = 0.6</span></span>
<span><span class="co">#&gt; alphahat (varying):</span></span>
<span><span class="co">#&gt; group_1 group_2 group_3 group_4 group_5 </span></span>
<span><span class="co">#&gt;     0.6     0.5     0.2     0.5     0.1</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="arguments-for-use-in-cv-glmnet">Arguments for use in <code>cv.glmnet</code><a class="anchor" aria-label="anchor" href="#arguments-for-use-in-cv-glmnet"></a>
</h3>
<p>Because model fitting is done with <code>cv.glmnet</code>,
<code>ptLasso</code> can take and pass arguments to
<code>cv.glmnet</code>. Notable choices include
<code>penalty.factor</code>, <code>weights</code>,
<code>upper.limits</code>, <code>lower.limits</code> and
<code>en.alpha</code> (known as <code>alpha</code> in
<code>glmnet</code>). Please refer to the <code>glmnet</code>
documentation for more information on their use.</p>
<p><code>ptLasso</code> does not support the arguments
<code>intercept</code>, <code>offset</code>, <code>fit</code> and
<code>check.args</code>.</p>
</div>
<div class="section level3">
<h3 id="parallelizing-model-fitting">Parallelizing model fitting<a class="anchor" aria-label="anchor" href="#parallelizing-model-fitting"></a>
</h3>
<p>For large datasets, we can parallelize model fitting within the calls
to <code>cv.glmnet</code>. As in <code>cv.glmnet</code>, pass the
argument <code>parallel = TRUE</code>, and register parallel
beforehand:</p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va">doMC</span><span class="op">)</span></span>
<span><span class="fu">registerDoMC</span><span class="op">(</span>cores <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span>
<span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, groups <span class="op">=</span> <span class="va">groups</span>, family <span class="op">=</span> <span class="st">"gaussian"</span>, type.measure <span class="op">=</span> <span class="st">"mse"</span>, </span>
<span>              parallel<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="input-grouped-data">Input grouped data<a class="anchor" aria-label="anchor" href="#input-grouped-data"></a>
</h2>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va"><a href="https://erincr.github.io/ptLasso/">ptLasso</a></span><span class="op">)</span></span></code></pre></div>
<div class="section level3">
<h3 id="base-case-input-grouped-data-with-a-binomial-outcome">Base case: input grouped data with a binomial outcome<a class="anchor" aria-label="anchor" href="#base-case-input-grouped-data-with-a-binomial-outcome"></a>
</h3>
<p>In the Quick Start, we applied <code>ptLasso</code> to data with a
continuous response. Here, we’ll use data with a binary outcome. This
creates a dataset with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">k = 3</annotation></semantics></math>
groups (each with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>100</mn><annotation encoding="application/x-tex">100</annotation></semantics></math>
observations), 5 shared coefficients, and 5 coefficients specific to
each group.</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="va">out</span> <span class="op">=</span> <span class="fu"><a href="../reference/binomial.example.data.html">binomial.example.data</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="va">out</span><span class="op">$</span><span class="va">x</span>; <span class="va">y</span> <span class="op">=</span> <span class="va">out</span><span class="op">$</span><span class="va">y</span>; <span class="va">groups</span> <span class="op">=</span> <span class="va">out</span><span class="op">$</span><span class="va">groups</span></span>
<span></span>
<span><span class="va">outtest</span> <span class="op">=</span> <span class="fu"><a href="../reference/binomial.example.data.html">binomial.example.data</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">xtest</span> <span class="op">=</span> <span class="va">outtest</span><span class="op">$</span><span class="va">x</span>; <span class="va">ytest</span> <span class="op">=</span> <span class="va">outtest</span><span class="op">$</span><span class="va">y</span>; <span class="va">groupstest</span> <span class="op">=</span> <span class="va">outtest</span><span class="op">$</span><span class="va">groups</span></span></code></pre></div>
<p>We can fit and predict as before. By default,
<code>predict.ptLasso</code> will compute and return the
<em>deviance</em> on the test set.</p>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>, family <span class="op">=</span> <span class="st">"binomial"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">xtest</span>, <span class="va">groupstest</span>, ytest <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.ptLasso(object = fit, xtest = xtest, groupstest = groupstest,  </span></span>
<span><span class="co">#&gt;     ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0.5 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (Deviance):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            allGroups  mean wtdMean group_1 group_2 group_3</span></span>
<span><span class="co">#&gt; Overall        1.359 1.359   1.359   1.334   1.321   1.421</span></span>
<span><span class="co">#&gt; Pretrain       1.279 1.279   1.279   1.272   1.169   1.397</span></span>
<span><span class="co">#&gt; Individual     1.283 1.283   1.283   1.265   1.186   1.399</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                        </span></span>
<span><span class="co">#&gt; Overall    7                           </span></span>
<span><span class="co">#&gt; Pretrain   12 (3 common + 9 individual)</span></span>
<span><span class="co">#&gt; Individual 20</span></span></code></pre></div>
<p>We could instead compute the AUC by specifying the
<code>type.measure</code> in the call to <code>ptLasso</code>. Note:
<code>type.measure</code> is specified during model fitting and not
prediction because it is used in each call to
<code>cv.glmnet</code>.</p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>, family <span class="op">=</span> <span class="st">"binomial"</span>, </span>
<span>              type.measure <span class="op">=</span> <span class="st">"auc"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">xtest</span>, <span class="va">groupstest</span>, ytest <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.ptLasso(object = fit, xtest = xtest, groupstest = groupstest,  </span></span>
<span><span class="co">#&gt;     ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0.5 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (AUC):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            allGroups   mean wtdMean group_1 group_2 group_3</span></span>
<span><span class="co">#&gt; Overall       0.6026 0.6039  0.6039  0.6161  0.6877  0.5080</span></span>
<span><span class="co">#&gt; Pretrain      0.6407 0.6524  0.6524  0.6936  0.7447  0.5190</span></span>
<span><span class="co">#&gt; Individual    0.6442 0.6618  0.6618  0.6936  0.7732  0.5186</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                         </span></span>
<span><span class="co">#&gt; Overall    15                           </span></span>
<span><span class="co">#&gt; Pretrain   39 (3 common + 36 individual)</span></span>
<span><span class="co">#&gt; Individual 40</span></span></code></pre></div>
<p>To fit the overall and individual models, we can use elasticnet
instead of lasso by defining the parameter <code>en.alpha</code> (as in
<code>glmnet</code> and described in the section “Fitting elasticnet or
ridge models”).</p>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>, family <span class="op">=</span> <span class="st">"binomial"</span>, </span>
<span>              type.measure <span class="op">=</span> <span class="st">"auc"</span>, </span>
<span>              en.alpha <span class="op">=</span> <span class="fl">.5</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">xtest</span>, <span class="va">groupstest</span>, ytest <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.ptLasso(object = fit, xtest = xtest, groupstest = groupstest,  </span></span>
<span><span class="co">#&gt;     ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0.5 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (AUC):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            allGroups   mean wtdMean group_1 group_2 group_3</span></span>
<span><span class="co">#&gt; Overall       0.6041 0.6018  0.6018  0.5928  0.6704  0.5422</span></span>
<span><span class="co">#&gt; Pretrain      0.6270 0.6547  0.6547  0.6781  0.7720  0.5141</span></span>
<span><span class="co">#&gt; Individual    0.6387 0.6598  0.6598  0.6756  0.7820  0.5218</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                         </span></span>
<span><span class="co">#&gt; Overall    3                            </span></span>
<span><span class="co">#&gt; Pretrain   39 (3 common + 36 individual)</span></span>
<span><span class="co">#&gt; Individual 36</span></span></code></pre></div>
<p>Using cross validation is the same as in the Gaussian case:</p>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##################################################</span></span>
<span><span class="co"># Fit:</span></span>
<span><span class="co">##################################################</span></span>
<span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/cv.ptLasso.html">cv.ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, family <span class="op">=</span> <span class="st">"binomial"</span>, type.measure <span class="op">=</span> <span class="st">"auc"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Warning: from glmnet C++ code (error code -100); Convergence for 100th lambda</span></span>
<span><span class="co">#&gt; value not reached after maxit=100000 iterations; solutions for larger lambdas</span></span>
<span><span class="co">#&gt; returned</span></span>
<span><span class="co">#&gt; Warning: from glmnet C++ code (error code -100); Convergence for 100th lambda</span></span>
<span><span class="co">#&gt; value not reached after maxit=100000 iterations; solutions for larger lambdas</span></span>
<span><span class="co">#&gt; returned</span></span>
<span><span class="co">#&gt; Warning: from glmnet C++ code (error code -92); Convergence for 92th lambda</span></span>
<span><span class="co">#&gt; value not reached after maxit=100000 iterations; solutions for larger lambdas</span></span>
<span><span class="co">#&gt; returned</span></span>
<span><span class="co">#&gt; Warning: from glmnet C++ code (error code -90); Convergence for 90th lambda</span></span>
<span><span class="co">#&gt; value not reached after maxit=100000 iterations; solutions for larger lambdas</span></span>
<span><span class="co">#&gt; returned</span></span>
<span></span>
<span><span class="co">##################################################</span></span>
<span><span class="co"># Predict with a common alpha for all groups:</span></span>
<span><span class="co">##################################################</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">xtest</span>, <span class="va">groupstest</span>, ytest <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.cv.ptLasso(object = fit, xtest = xtest, groupstest = groupstest,  </span></span>
<span><span class="co">#&gt;     ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0.7 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (AUC):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            allGroups   mean wtdMean group_1 group_2 group_3</span></span>
<span><span class="co">#&gt; Overall       0.5990 0.5960  0.5960  0.6030  0.6644  0.5206</span></span>
<span><span class="co">#&gt; Pretrain      0.6401 0.6640  0.6640  0.6965  0.7732  0.5222</span></span>
<span><span class="co">#&gt; Individual    0.6559 0.6707  0.6707  0.6936  0.7808  0.5377</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                         </span></span>
<span><span class="co">#&gt; Overall    7                            </span></span>
<span><span class="co">#&gt; Pretrain   40 (3 common + 37 individual)</span></span>
<span><span class="co">#&gt; Individual 37</span></span>
<span></span>
<span><span class="co">##################################################</span></span>
<span><span class="co"># Predict with a different alpha for each group:</span></span>
<span><span class="co">##################################################</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">xtest</span>, <span class="va">groupstest</span>, ytest <span class="op">=</span> <span class="va">ytest</span>, alphatype <span class="op">=</span> <span class="st">"varying"</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.cv.ptLasso(object = fit, xtest = xtest, groupstest = groupstest,  </span></span>
<span><span class="co">#&gt;     ytest = ytest, alphatype = "varying") </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha:</span></span>
<span><span class="co">#&gt; [1] 0.2 0.5 0.2</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (AUC):</span></span>
<span><span class="co">#&gt;            overall   mean wtdMean group_1 group_2 group_3</span></span>
<span><span class="co">#&gt; Overall     0.5990 0.5960  0.5960  0.6030  0.6644  0.5206</span></span>
<span><span class="co">#&gt; Pretrain    0.6359 0.6573  0.6573  0.6838  0.7736  0.5145</span></span>
<span><span class="co">#&gt; Individual  0.6559 0.6707  0.6707  0.6936  0.7808  0.5377</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                         </span></span>
<span><span class="co">#&gt; Overall    7                            </span></span>
<span><span class="co">#&gt; Pretrain   40 (3 common + 37 individual)</span></span>
<span><span class="co">#&gt; Individual 37</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="base-case-input-grouped-survival-data">Base case: input grouped survival data<a class="anchor" aria-label="anchor" href="#base-case-input-grouped-survival-data"></a>
</h3>
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va"><a href="https://github.com/therneau/survival" class="external-link">survival</a></span><span class="op">)</span></span>
<span><span class="co">#&gt; Loading required package: survival</span></span></code></pre></div>
<p>Now, we will simulate survival times with 3 groups; the three groups
have overlapping support, with 5 shared features and each has 5
individual features. To compute survival time, we start by computing
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="normal">survival</mtext><mo>=</mo><mi>X</mi><mi>β</mi><mo>+</mo><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\text{survival} = X \beta + \epsilon</annotation></semantics></math>,
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>β</mi><annotation encoding="application/x-tex">\beta</annotation></semantics></math>
is specific to each group and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ϵ</mi><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math>
is noise. Because survival times must be positive, we modify this to be
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="normal">survival</mtext><mo>=</mo><mtext mathvariant="normal">survival</mtext><mo>+</mo><mn>1.1</mn><mo>*</mo><mtext mathvariant="normal">abs</mtext><mrow><mo stretchy="true" form="prefix">(</mo><mtext mathvariant="normal">min</mtext><mrow><mo stretchy="true" form="prefix">(</mo><mtext mathvariant="normal">survival</mtext><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\text{survival} = \text{survival} + 1.1 * \text{abs}(\text{min}(\text{survival}))</annotation></semantics></math>.</p>
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">600</span>; <span class="va">ntrain</span> <span class="op">=</span> <span class="fl">300</span></span>
<span><span class="va">p</span> <span class="op">=</span> <span class="fl">50</span></span>
<span>     </span>
<span><span class="va">x</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">*</span><span class="va">p</span><span class="op">)</span>, <span class="va">n</span>, <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">beta1</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">5</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">5</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">beta2</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">p</span><span class="op">)</span> <span class="op">*</span> <span class="va">beta1</span> <span class="co"># Shared support</span></span>
<span><span class="va">beta2</span> <span class="op">=</span> <span class="va">beta2</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">5</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">5</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">10</span><span class="op">)</span><span class="op">)</span> <span class="co"># Individual features</span></span>
<span></span>
<span><span class="va">beta3</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">p</span><span class="op">)</span> <span class="op">*</span> <span class="va">beta1</span> <span class="co"># Shared support</span></span>
<span><span class="va">beta3</span> <span class="op">=</span> <span class="va">beta3</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">5</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">15</span><span class="op">)</span><span class="op">)</span> <span class="co"># Individual features</span></span>
<span></span>
<span><span class="co"># Randomly split into groups</span></span>
<span><span class="va">groups</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, <span class="va">n</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compute survival times:</span></span>
<span><span class="va">survival</span> <span class="op">=</span> <span class="va">x</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta1</span></span>
<span><span class="va">survival</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">2</span><span class="op">]</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">2</span>, <span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta2</span></span>
<span><span class="va">survival</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">3</span><span class="op">]</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">3</span>, <span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta3</span></span>
<span><span class="va">survival</span> <span class="op">=</span> <span class="va">survival</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span><span class="va">survival</span> <span class="op">=</span> <span class="va">survival</span> <span class="op">+</span> <span class="fl">1.1</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">abs</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">min</a></span><span class="op">(</span><span class="va">survival</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Censoring times from a random uniform distribution:</span></span>
<span><span class="va">censoring</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">n</span>, min <span class="op">=</span> <span class="fl">1</span>, max <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Did we observe surivival or censoring?</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/survival/man/Surv.html" class="external-link">Surv</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">pmin</a></span><span class="op">(</span><span class="va">survival</span>, <span class="va">censoring</span><span class="op">)</span>, <span class="va">survival</span> <span class="op">&lt;=</span> <span class="va">censoring</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Split into train and test:</span></span>
<span><span class="va">xtest</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">300</span><span class="op">)</span>, <span class="op">]</span></span>
<span><span class="va">ytest</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">300</span><span class="op">)</span>, <span class="op">]</span></span>
<span><span class="va">groupstest</span> <span class="op">=</span> <span class="va">groups</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">300</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">300</span>, <span class="op">]</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">300</span>, <span class="op">]</span></span>
<span><span class="va">groups</span> <span class="op">=</span> <span class="va">groups</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">300</span><span class="op">]</span></span></code></pre></div>
<p>Training with <code>ptLasso</code> is much the same as it was for the
continuous and binomial cases; the only difference is that we specify
<code>family = "cox"</code>. By default, <code>ptLasso</code> uses the
partial likelihood for model selection. We could instead use the C
index.</p>
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">############################################################</span></span>
<span><span class="co"># Default -- use partial likelihood as the type.measure:</span></span>
<span><span class="co">############################################################</span></span>
<span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>, family <span class="op">=</span> <span class="st">"cox"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">xtest</span>, <span class="va">groupstest</span>, ytest <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.ptLasso(object = fit, xtest = xtest, groupstest = groupstest,  </span></span>
<span><span class="co">#&gt;     ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0.5 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (Deviance):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            allGroups  mean wtdMean group_1 group_2 group_3</span></span>
<span><span class="co">#&gt; Overall        381.2 87.60   89.36   99.49  106.53   56.79</span></span>
<span><span class="co">#&gt; Pretrain       396.3 87.86   88.66   93.31   96.54   73.72</span></span>
<span><span class="co">#&gt; Individual     425.2 99.07   99.54  111.68  101.85   83.67</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                         </span></span>
<span><span class="co">#&gt; Overall    10                           </span></span>
<span><span class="co">#&gt; Pretrain   20 (4 common + 16 individual)</span></span>
<span><span class="co">#&gt; Individual 24</span></span>
<span></span>
<span><span class="co">############################################################</span></span>
<span><span class="co"># Alternatively -- use the C index:</span></span>
<span><span class="co">############################################################</span></span>
<span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>, family <span class="op">=</span> <span class="st">"cox"</span>, type.measure <span class="op">=</span> <span class="st">"C"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Warning: from glmnet C++ code (error code -30075); Numerical error at 75th</span></span>
<span><span class="co">#&gt; lambda value; solutions for larger values of lambda returned</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">xtest</span>, <span class="va">groupstest</span>, ytest <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.ptLasso(object = fit, xtest = xtest, groupstest = groupstest,  </span></span>
<span><span class="co">#&gt;     ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0.5 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (C-index):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            allGroups   mean wtdMean group_1 group_2 group_3</span></span>
<span><span class="co">#&gt; Overall       0.8545 0.8673  0.8608  0.9139  0.7746  0.9133</span></span>
<span><span class="co">#&gt; Pretrain      0.8359 0.8396  0.8393  0.9152  0.8173  0.7864</span></span>
<span><span class="co">#&gt; Individual    0.7925 0.7985  0.8008  0.9075  0.8007  0.6873</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                         </span></span>
<span><span class="co">#&gt; Overall    6                            </span></span>
<span><span class="co">#&gt; Pretrain   35 (4 common + 31 individual)</span></span>
<span><span class="co">#&gt; Individual 37</span></span></code></pre></div>
<p>The call to <code>cv.ptLasso</code> is again much the same; we only
need to specify <code>family</code> (“cox”) and
<code>type.measure</code> (if we want to use the C index instead of the
partial likelihood).</p>
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##################################################</span></span>
<span><span class="co"># Fit:</span></span>
<span><span class="co">##################################################</span></span>
<span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/cv.ptLasso.html">cv.ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, family <span class="op">=</span> <span class="st">"cox"</span>, type.measure <span class="op">=</span> <span class="st">"C"</span><span class="op">)</span></span>
<span></span>
<span><span class="co">##################################################</span></span>
<span><span class="co"># Predict with a common alpha for all groups:</span></span>
<span><span class="co">##################################################</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">xtest</span>, <span class="va">groupstest</span>, ytest <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.cv.ptLasso(object = fit, xtest = xtest, groupstest = groupstest,  </span></span>
<span><span class="co">#&gt;     ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0.2 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (C-index):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            allGroups   mean wtdMean group_1 group_2 group_3</span></span>
<span><span class="co">#&gt; Overall       0.8527 0.8652  0.8586  0.9113  0.7711  0.9133</span></span>
<span><span class="co">#&gt; Pretrain      0.8501 0.8795  0.8742  0.9177  0.8043  0.9164</span></span>
<span><span class="co">#&gt; Individual    0.7865 0.8005  0.8033  0.9126  0.8078  0.6811</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                        </span></span>
<span><span class="co">#&gt; Overall    8                           </span></span>
<span><span class="co">#&gt; Pretrain   13 (4 common + 9 individual)</span></span>
<span><span class="co">#&gt; Individual 31</span></span>
<span></span>
<span><span class="co">##################################################</span></span>
<span><span class="co"># Predict with a different alpha for each group:</span></span>
<span><span class="co">##################################################</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">xtest</span>, <span class="va">groupstest</span>, ytest <span class="op">=</span> <span class="va">ytest</span>, alphatype <span class="op">=</span> <span class="st">"varying"</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.cv.ptLasso(object = fit, xtest = xtest, groupstest = groupstest,  </span></span>
<span><span class="co">#&gt;     ytest = ytest, alphatype = "varying") </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha:</span></span>
<span><span class="co">#&gt; [1] 0.3 0.4 0.4</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (C-index):</span></span>
<span><span class="co">#&gt;            overall   mean wtdMean group_1 group_2 group_3</span></span>
<span><span class="co">#&gt; Overall     0.8527 0.8652  0.8586  0.9113  0.7711  0.9133</span></span>
<span><span class="co">#&gt; Pretrain    0.8081 0.8493  0.8475  0.9229  0.8078  0.8173</span></span>
<span><span class="co">#&gt; Individual  0.7865 0.8005  0.8033  0.9126  0.8078  0.6811</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                         </span></span>
<span><span class="co">#&gt; Overall    8                            </span></span>
<span><span class="co">#&gt; Pretrain   28 (4 common + 24 individual)</span></span>
<span><span class="co">#&gt; Individual 31</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="different-groups-in-train-and-test-data">Different groups in train and test data<a class="anchor" aria-label="anchor" href="#different-groups-in-train-and-test-data"></a>
</h3>
<p>Suppose we observe groups at test time that were unobserved at train
time. For example, our training set may consist of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math><em>people</em> – each with many observations – and at test time, we
wish to make predictions for observations from new people. We can still
use pretraining in this setting: train a model using all data, and use
this to guide the training for person-specific models.</p>
<p>Now however, we also fit an extra model to predict the similarity of
test observations to the observations from each of the <em>training
people</em>. To train this model, we use the (training) observation
matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
and the response
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mtext mathvariant="normal">sim</mtext></msub><annotation encoding="application/x-tex">y_{\text{sim}}</annotation></semantics></math>,
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mtext mathvariant="normal">sim</mtext></msub><mo>=</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">y_{\text{sim}} = k</annotation></semantics></math>
for all observations from the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>k</mi><mtext mathvariant="normal">th</mtext></msup><annotation encoding="application/x-tex">k^\text{th}</annotation></semantics></math>
person. When used for prediction, this model gives us a similarity (or
probability) vector of length
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>K</mi><annotation encoding="application/x-tex">K</annotation></semantics></math>
that sums to 1, describing how similar an observation is to each
training person.</p>
<p>At test time, we make predictions from (1) each pretrained
person-specific model and (2) the person-similarity model, and we
compute the weighted average of the pretrained predictions with respect
to the similarity vector. Here is an example using simulated data.</p>
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va"><a href="https://glmnet.stanford.edu" class="external-link">glmnet</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va"><a href="https://erincr.github.io/ptLasso/">ptLasso</a></span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Start with 5 people, each with 300 observations and 200 features.</span></span>
<span><span class="co"># 3 people will be used for training, and 2 for testing.</span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">300</span><span class="op">*</span><span class="fl">5</span>; <span class="va">p</span> <span class="op">=</span> <span class="fl">200</span>;</span>
<span><span class="va">groups</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sort.html" class="external-link">sort</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span>, <span class="va">n</span><span class="op">/</span><span class="fl">5</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># We will have different coefficients for each of the 3 training people, </span></span>
<span><span class="co"># and the first 3 features are shared support.</span></span>
<span><span class="va">beta.group1</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>, <span class="fl">1</span>, <span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="fl">3</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">6</span><span class="op">)</span><span class="op">)</span>; </span>
<span><span class="va">beta.group2</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>, <span class="fl">1</span>, <span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">3</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="fl">3</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">9</span><span class="op">)</span><span class="op">)</span>; </span>
<span><span class="va">beta.group3</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>, <span class="fl">1</span>, <span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">6</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="fl">3</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">12</span><span class="op">)</span><span class="op">)</span>; </span>
<span></span>
<span><span class="co"># The two test people are each a combination of of the training people.</span></span>
<span><span class="co"># Person 4 will have observations drawn from classes 1 and 2, and</span></span>
<span><span class="co"># Person 5 will have observations drawn from classes 1 and 3.</span></span>
<span><span class="co"># The vector "hidden groups" is a latent variable - used to simulate data</span></span>
<span><span class="co"># but unobserved in real data.</span></span>
<span><span class="va">hidden.gps</span> <span class="op">=</span> <span class="va">groups</span></span>
<span><span class="va">hidden.gps</span><span class="op">[</span><span class="va">hidden.gps</span> <span class="op">==</span> <span class="fl">4</span><span class="op">]</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">4</span><span class="op">)</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">hidden.gps</span><span class="op">[</span><span class="va">hidden.gps</span> <span class="op">==</span> <span class="fl">5</span><span class="op">]</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">5</span><span class="op">)</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># We modify X according to group membership;</span></span>
<span><span class="co"># we want X to cluster into groups 1, 2 and 3.</span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="va">n</span>, ncol <span class="op">=</span> <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">x</span><span class="op">[</span><span class="va">hidden.gps</span> <span class="op">==</span> <span class="fl">1</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">hidden.gps</span> <span class="op">==</span> <span class="fl">1</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span> <span class="op">+</span> <span class="fl">1</span></span>
<span><span class="va">x</span><span class="op">[</span><span class="va">hidden.gps</span> <span class="op">==</span> <span class="fl">2</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">hidden.gps</span> <span class="op">==</span> <span class="fl">2</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span> <span class="op">+</span> <span class="fl">2</span></span>
<span><span class="va">x</span><span class="op">[</span><span class="va">hidden.gps</span> <span class="op">==</span> <span class="fl">3</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">hidden.gps</span> <span class="op">==</span> <span class="fl">3</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span> <span class="op">+</span> <span class="fl">3</span></span>
<span></span>
<span><span class="co"># And now, we compute y using betas 1, 2 and 3: </span></span>
<span><span class="va">x.beta</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">n</span><span class="op">)</span></span>
<span><span class="va">x.beta</span><span class="op">[</span><span class="va">hidden.gps</span> <span class="op">==</span> <span class="fl">1</span><span class="op">]</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">hidden.gps</span> <span class="op">==</span> <span class="fl">1</span>, <span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta.group1</span> </span>
<span><span class="va">x.beta</span><span class="op">[</span><span class="va">hidden.gps</span> <span class="op">==</span> <span class="fl">2</span><span class="op">]</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">hidden.gps</span> <span class="op">==</span> <span class="fl">2</span>, <span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta.group2</span> </span>
<span><span class="va">x.beta</span><span class="op">[</span><span class="va">hidden.gps</span> <span class="op">==</span> <span class="fl">3</span><span class="op">]</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">hidden.gps</span> <span class="op">==</span> <span class="fl">3</span>, <span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta.group3</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">x.beta</span> <span class="op">+</span> <span class="fl">5</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span></code></pre></div>
<p>We’re ready to split into train, validation and test sets. We will
use people 1, 2 and 3 for training and validation (two-thirds train,
one-third validation), and people 4 and 5 for testing.</p>
<div class="sourceCode" id="cb41"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">trn.index</span> <span class="op">=</span> <span class="va">groups</span> <span class="op">&lt;</span> <span class="fl">4</span></span>
<span><span class="va">val.sample</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">trn.index</span><span class="op">)</span>, <span class="fl">1</span><span class="op">/</span><span class="fl">3</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">trn.index</span><span class="op">)</span>, replace <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span></span>
<span><span class="va">xtrain</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">trn.index</span>, <span class="op">]</span><span class="op">[</span><span class="op">-</span><span class="va">val.sample</span>, <span class="op">]</span></span>
<span><span class="va">ytrain</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="va">trn.index</span><span class="op">]</span><span class="op">[</span><span class="op">-</span><span class="va">val.sample</span><span class="op">]</span></span>
<span><span class="va">gpstrain</span> <span class="op">=</span> <span class="va">groups</span><span class="op">[</span><span class="va">trn.index</span><span class="op">]</span><span class="op">[</span><span class="op">-</span><span class="va">val.sample</span><span class="op">]</span></span>
<span></span>
<span><span class="va">xval</span>   <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">trn.index</span>, <span class="op">]</span><span class="op">[</span><span class="va">val.sample</span>, <span class="op">]</span> </span>
<span><span class="va">yval</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="va">trn.index</span><span class="op">]</span><span class="op">[</span><span class="va">val.sample</span><span class="op">]</span></span>
<span><span class="va">gpsval</span> <span class="op">=</span> <span class="va">groups</span><span class="op">[</span><span class="va">trn.index</span><span class="op">]</span><span class="op">[</span><span class="va">val.sample</span><span class="op">]</span></span>
<span></span>
<span><span class="va">xtest</span>  <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="op">!</span><span class="va">trn.index</span>, <span class="op">]</span></span>
<span><span class="va">ytest</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="op">!</span><span class="va">trn.index</span><span class="op">]</span></span>
<span><span class="va">gpstest</span> <span class="op">=</span> <span class="va">groups</span><span class="op">[</span><span class="op">!</span><span class="va">trn.index</span><span class="op">]</span></span></code></pre></div>
<p>We start with pretraining, where the person ID is the grouping
variable.</p>
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cvfit</span> <span class="op">=</span> <span class="fu"><a href="../reference/cv.ptLasso.html">cv.ptLasso</a></span><span class="op">(</span><span class="va">xtrain</span>, <span class="va">ytrain</span>, <span class="va">gpstrain</span>, </span>
<span>                   type.measure <span class="op">=</span> <span class="st">"mse"</span>, </span>
<span>                   group.intercepts <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>                   overall.lambda <span class="op">=</span> <span class="st">"lambda.1se"</span><span class="op">)</span></span></code></pre></div>
<p>Now, we train a model to predict the person ID from the covariates.
Because this example is simulated, we can measure the performance of our
model on test data (via the confusion matrix comparing predicted group
labels to true labels). In real settings, this would be impossible.</p>
<div class="sourceCode" id="cb43"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">simmod</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">xtrain</span>, <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">gpstrain</span><span class="op">)</span>, family <span class="op">=</span> <span class="st">"multinomial"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Peek at performance on test data.</span></span>
<span><span class="co"># Not possible with real data.</span></span>
<span><span class="va">class.preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">simmod</span>, <span class="va">xtest</span>, type<span class="op">=</span><span class="st">"response"</span><span class="op">)</span><span class="op">[</span>, , <span class="fl">1</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/table.html" class="external-link">table</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">class.preds</span>, <span class="fl">1</span>, <span class="va">which.max</span><span class="op">)</span>, </span>
<span>      <span class="va">hidden.gps</span><span class="op">[</span><span class="va">groups</span> <span class="op">&gt;=</span> <span class="fl">4</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">#&gt;    </span></span>
<span><span class="co">#&gt;       1   2   3</span></span>
<span><span class="co">#&gt;   1 260  37   3</span></span>
<span><span class="co">#&gt;   2  39  82  29</span></span>
<span><span class="co">#&gt;   3   0  36 114</span></span></code></pre></div>
<p>Finally we can make predictions: we have everything we need. For each
test observation, we will get the pretrained prediction for all 3
training classes. Our final predictions are the weighted combination of
the predictions from <code>ptLasso</code> and the class predictions from
<code>glmnet</code>.</p>
<div class="sourceCode" id="cb44"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">alphahat</span>  <span class="op">=</span> <span class="va">cvfit</span><span class="op">$</span><span class="va">alphahat</span></span>
<span><span class="va">bestmodel</span> <span class="op">=</span> <span class="va">cvfit</span><span class="op">$</span><span class="va">fit</span><span class="op">[[</span><span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="va">cvfit</span><span class="op">$</span><span class="va">alphalist</span> <span class="op">==</span> <span class="va">alphahat</span><span class="op">)</span><span class="op">]</span><span class="op">]</span></span>
<span></span>
<span><span class="va">offset</span> <span class="op">=</span> <span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">alphahat</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">bestmodel</span><span class="op">$</span><span class="va">fitoverall</span>, <span class="va">xtest</span>, s <span class="op">=</span> <span class="st">"lambda.1se"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Get the prediction for all three classes for each test observation. </span></span>
<span><span class="co"># This will be a matrix with three columns; one for each class.</span></span>
<span><span class="va">pretrained.preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/do.call.html" class="external-link">do.call</a></span><span class="op">(</span><span class="va">cbind</span>, </span>
<span>                        <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">lapply</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, </span>
<span>                               <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">bestmodel</span><span class="op">$</span><span class="va">fitpre</span><span class="op">[[</span><span class="va">i</span><span class="op">]</span><span class="op">]</span>, </span>
<span>                                                   <span class="va">xtest</span>,</span>
<span>                                                   newoffset <span class="op">=</span> <span class="va">offset</span><span class="op">)</span></span>
<span>                      <span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/colSums-methods.html" class="external-link">rowSums</a></span><span class="op">(</span><span class="va">pretrained.preds</span> <span class="op">*</span> <span class="va">class.preds</span><span class="op">)</span>, newy <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span><span class="op">$</span><span class="va">mse</span></span>
<span><span class="co">#&gt; [1] 28.17891</span></span>
<span><span class="co">#&gt; attr(,"measure")</span></span>
<span><span class="co">#&gt; [1] "Mean-Squared Error"</span></span></code></pre></div>
<p>There are two reasonable baselines. The first is the overall model
with no grouping at all, and the second is the set of individual models
(one for each group).</p>
<div class="sourceCode" id="cb45"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">########################################################</span></span>
<span><span class="co"># Baseline 1: overall model</span></span>
<span><span class="co">########################################################</span></span>
<span><span class="va">overall.predictions</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">cvfit</span><span class="op">$</span><span class="va">fitoverall</span>, <span class="va">xtest</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="va">overall.predictions</span>, newy <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span><span class="op">$</span><span class="va">mse</span></span>
<span><span class="co">#&gt; lambda.1se </span></span>
<span><span class="co">#&gt;   29.64747 </span></span>
<span><span class="co">#&gt; attr(,"measure")</span></span>
<span><span class="co">#&gt; [1] "Mean-Squared Error"</span></span>
<span></span>
<span><span class="co">########################################################</span></span>
<span><span class="co"># Baseline 2: individual models</span></span>
<span><span class="co">########################################################</span></span>
<span><span class="va">individual.preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/do.call.html" class="external-link">do.call</a></span><span class="op">(</span><span class="va">cbind</span>, </span>
<span>                           <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">lapply</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, </span>
<span>                                  <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">bestmodel</span><span class="op">$</span><span class="va">fitind</span><span class="op">[[</span><span class="va">i</span><span class="op">]</span><span class="op">]</span>, </span>
<span>                                                      <span class="va">xtest</span>,</span>
<span>                                                      type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span></span>
<span>                      <span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/colSums-methods.html" class="external-link">rowSums</a></span><span class="op">(</span><span class="va">individual.preds</span> <span class="op">*</span> <span class="va">class.preds</span><span class="op">)</span>, newy <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span><span class="op">$</span><span class="va">mse</span></span>
<span><span class="co">#&gt; [1] 29.17333</span></span>
<span><span class="co">#&gt; attr(,"measure")</span></span>
<span><span class="co">#&gt; [1] "Mean-Squared Error"</span></span></code></pre></div>
<p>What we have done – taking a weighted average of predictions with
respect to similarity to each person – makes sense mathematically.
However, we have found better empirical results if we instead train a
supervised learning algorithm to make the final prediction
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>y</mi><mo accent="true">̂</mo></mover><annotation encoding="application/x-tex">\hat{y}</annotation></semantics></math>
using the pretrained model predictions and the class similarity
predictions as features. So, let’s do that here, using our
so-far-untouched validation set.</p>
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">val.offset</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">bestmodel</span><span class="op">$</span><span class="va">fitoverall</span>, <span class="va">xval</span>, s <span class="op">=</span> <span class="st">"lambda.1se"</span><span class="op">)</span></span>
<span><span class="va">val.offset</span> <span class="op">=</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">alphahat</span><span class="op">)</span> <span class="op">*</span> <span class="va">val.offset</span></span>
<span><span class="va">val.preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/do.call.html" class="external-link">do.call</a></span><span class="op">(</span><span class="va">cbind</span>, </span>
<span>                    <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">lapply</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">bestmodel</span><span class="op">$</span><span class="va">fitpre</span><span class="op">[[</span><span class="va">i</span><span class="op">]</span><span class="op">]</span>, </span>
<span>                                                    <span class="va">xval</span>,</span>
<span>                                                    newoffset <span class="op">=</span> <span class="va">val.offset</span>,</span>
<span>                                                    type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span></span>
<span>                      <span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="va">val.class.preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">simmod</span>, <span class="va">xval</span><span class="op">)</span><span class="op">[</span>, , <span class="fl">1</span><span class="op">]</span></span>
<span></span>
<span><span class="va">pred.data</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">val.preds</span>, <span class="va">val.class.preds</span>, <span class="va">val.preds</span> <span class="op">*</span> <span class="va">val.class.preds</span><span class="op">)</span> </span>
<span><span class="va">final.model</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">pred.data</span>, <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/colSums-methods.html" class="external-link">rowSums</a></span><span class="op">(</span><span class="va">val.preds</span> <span class="op">*</span> <span class="va">val.class.preds</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">pred.data.test</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">pretrained.preds</span>, </span>
<span>                       <span class="va">class.preds</span>, </span>
<span>                       <span class="va">pretrained.preds</span> <span class="op">*</span> <span class="va">class.preds</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">final.model</span>, <span class="va">pred.data.test</span><span class="op">)</span>, newy <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span><span class="op">$</span><span class="va">mse</span></span>
<span><span class="co">#&gt; lambda.1se </span></span>
<span><span class="co">#&gt;   28.28504 </span></span>
<span><span class="co">#&gt; attr(,"measure")</span></span>
<span><span class="co">#&gt; [1] "Mean-Squared Error"</span></span></code></pre></div>
<p>Comparing performance of all models side-by-side shows that (1) using
input groups improved performance – including for the individual models
and (2) including the final model did not help performance dramatically
(but we still recommend trying this with real data).</p>
<div class="sourceCode" id="cb47"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">rd</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">x</span>, <span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Overall model PSE: "</span>, </span>
<span>    <span class="fu">rd</span><span class="op">(</span><span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="va">overall.predictions</span>, newy <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span><span class="op">$</span><span class="va">mse</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Overall model PSE:  29.65</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Individual model PSE: "</span>, </span>
<span>    <span class="fu">rd</span><span class="op">(</span><span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/colSums-methods.html" class="external-link">rowSums</a></span><span class="op">(</span><span class="va">individual.preds</span><span class="op">*</span><span class="va">class.preds</span><span class="op">)</span>, newy <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span><span class="op">$</span><span class="va">mse</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Individual model PSE:  29.17</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Pretraining model PSE: "</span>, </span>
<span>    <span class="fu">rd</span><span class="op">(</span><span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/colSums-methods.html" class="external-link">rowSums</a></span><span class="op">(</span><span class="va">pretrained.preds</span><span class="op">*</span><span class="va">class.preds</span><span class="op">)</span>, newy <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span><span class="op">$</span><span class="va">mse</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Pretraining model PSE:  28.18</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Pretraining model + final prediction model PSE: "</span>, </span>
<span>    <span class="fu">rd</span><span class="op">(</span><span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">final.model</span>, </span>
<span>                          <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">pretrained.preds</span>, </span>
<span>                                <span class="va">class.preds</span>, </span>
<span>                                <span class="va">pretrained.preds</span> <span class="op">*</span> <span class="va">class.preds</span><span class="op">)</span></span>
<span>                      <span class="op">)</span>, </span>
<span>              newy <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span><span class="op">$</span><span class="va">mse</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Pretraining model + final prediction model PSE:  28.29</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="learning-the-input-groups">Learning the input groups<a class="anchor" aria-label="anchor" href="#learning-the-input-groups"></a>
</h3>
<p>Suppose we have a dataset with features
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
and response
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>,
and no input grouping. Suppose we also have a small set of meaningful
features
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Z</mi><annotation encoding="application/x-tex">Z</annotation></semantics></math>
that we expect to stratify observations (e.g. in biomedicine,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Z</mi><annotation encoding="application/x-tex">Z</annotation></semantics></math>
may consist of age and sex). In this setting, we can <em>learn</em>
input groups using
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Z</mi><annotation encoding="application/x-tex">Z</annotation></semantics></math>.</p>
<p>The steps to do this are as follows.</p>
<ol style="list-style-type: decimal">
<li>Partition data into two sets: one to learn the grouping and one to
do pretraining.</li>
<li>With the first set, train a small CART tree using
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Z</mi><annotation encoding="application/x-tex">Z</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>.</li>
<li>Make predictions for the remaining data; assign observations to
groups according to their terminal nodes.</li>
<li>Apply pretraining using the learned group assignments.</li>
</ol>
<p>Here, we show an example using simulated data. We use
<code>rpart</code> to train a CART tree. The package <code>ODRF</code>
(<span class="citation">Liu and Xia (2022)</span>) is another good
choice – it fits a linear model in each terminal node, which is closer
to what pretraining does, and may therefore have better performance.</p>
<div class="sourceCode" id="cb48"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va"><a href="https://github.com/bethatkinson/rpart" class="external-link">rpart</a></span><span class="op">)</span></span>
<span><span class="co">#&gt; Loading required package: rpart</span></span></code></pre></div>
<p>Simulate data with a binary outcome:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
is drawn from a random normal (with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>=</mo><mn>50</mn></mrow><annotation encoding="application/x-tex">p = 50</annotation></semantics></math>
uncorrelated features), and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Z</mi><annotation encoding="application/x-tex">Z</annotation></semantics></math>
is simulated as age (uniform between 20 and 90) and sex (half 0, half
1). The <em>true</em> groups are (1) age under 50, (2) age over 50 and
sex = 0 and (3) age over 50 and sex = 1.</p>
<div class="sourceCode" id="cb49"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">1000</span>; <span class="va">p</span> <span class="op">=</span> <span class="fl">50</span></span>
<span><span class="va">groupvars</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span>age <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">n</span>, min <span class="op">=</span> <span class="fl">20</span>, max <span class="op">=</span> <span class="fl">90</span><span class="op">)</span><span class="op">)</span>, </span>
<span>                  sex <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>, <span class="va">n</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">groups</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">n</span><span class="op">)</span></span>
<span><span class="va">groups</span><span class="op">[</span><span class="va">groupvars</span><span class="op">[</span>, <span class="st">"age"</span><span class="op">]</span> <span class="op">&gt;</span> <span class="fl">50</span> <span class="op">&amp;</span> <span class="va">groupvars</span><span class="op">[</span>, <span class="st">"sex"</span><span class="op">]</span> <span class="op">==</span> <span class="fl">0</span><span class="op">]</span> <span class="op">=</span> <span class="fl">2</span></span>
<span><span class="va">groups</span><span class="op">[</span><span class="va">groupvars</span><span class="op">[</span>, <span class="st">"age"</span><span class="op">]</span> <span class="op">&gt;</span> <span class="fl">50</span> <span class="op">&amp;</span> <span class="va">groupvars</span><span class="op">[</span>, <span class="st">"sex"</span><span class="op">]</span> <span class="op">==</span> <span class="fl">1</span><span class="op">]</span> <span class="op">=</span> <span class="fl">3</span></span></code></pre></div>
<p>Now, we’ll define coefficients
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>β</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\beta_k</annotation></semantics></math>
such that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>=</mo><mn>1</mn><mo>∣</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><mo>exp</mo><mrow><mo stretchy="true" form="prefix">(</mo><mo>−</mo><msubsup><mi>x</mi><mi>i</mi><mi>T</mi></msubsup><msub><mi>β</mi><mi>k</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac></mrow><annotation encoding="application/x-tex">P(y_i = 1 \mid x_i) = \frac{1}{1 + \exp(-x_i^T \beta_k)}</annotation></semantics></math>
for each group. Across groups, three coefficients are shared, three are
group-specific and the rest are 0. Each group has a unique intercept to
adjust its baseline risk.</p>
<div class="sourceCode" id="cb50"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">beta.group1</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.1</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.2</span>, <span class="fl">0.3</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">6</span><span class="op">)</span><span class="op">)</span>; </span>
<span><span class="va">beta.group2</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.1</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">3</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.2</span>, <span class="fl">0.3</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">9</span><span class="op">)</span><span class="op">)</span>; </span>
<span><span class="va">beta.group3</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.1</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">6</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.2</span>, <span class="fl">0.3</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">12</span><span class="op">)</span><span class="op">)</span>; </span>
<span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="va">n</span>, ncol <span class="op">=</span> <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">x.beta</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">n</span><span class="op">)</span></span>
<span><span class="va">x.beta</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">1</span><span class="op">]</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">1</span>, <span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta.group1</span> <span class="op">-</span> <span class="fl">0.75</span></span>
<span><span class="va">x.beta</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">2</span><span class="op">]</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">2</span>, <span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta.group2</span> </span>
<span><span class="va">x.beta</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">3</span><span class="op">]</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">3</span>, <span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta.group3</span> <span class="op">+</span> <span class="fl">0.75</span></span>
<span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html" class="external-link">rbinom</a></span><span class="op">(</span><span class="va">n</span>, size <span class="op">=</span> <span class="fl">1</span>, prob <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="op">-</span><span class="va">x.beta</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Now that we have our data, we will partition it into 3 datasets: </span></span>
<span><span class="co"># one to cluster, one to train models and one to test performance.</span></span>
<span><span class="va">xcluster</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">250</span>, <span class="op">]</span>; <span class="va">xtrain</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="fl">251</span><span class="op">:</span><span class="fl">750</span>, <span class="op">]</span>; <span class="va">xtest</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="fl">751</span><span class="op">:</span><span class="fl">1000</span>, <span class="op">]</span>;</span>
<span><span class="va">ycluster</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">250</span><span class="op">]</span>;   <span class="va">ytrain</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="fl">251</span><span class="op">:</span><span class="fl">750</span><span class="op">]</span>;   <span class="va">ytest</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="fl">751</span><span class="op">:</span><span class="fl">1000</span><span class="op">]</span>;</span>
<span></span>
<span><span class="va">zcluster</span> <span class="op">=</span> <span class="va">groupvars</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">250</span>, <span class="op">]</span>; </span>
<span><span class="va">ztrain</span> <span class="op">=</span> <span class="va">groupvars</span><span class="op">[</span><span class="fl">251</span><span class="op">:</span><span class="fl">750</span>, <span class="op">]</span>; </span>
<span><span class="va">ztest</span> <span class="op">=</span> <span class="va">groupvars</span><span class="op">[</span><span class="fl">751</span><span class="op">:</span><span class="fl">1000</span>, <span class="op">]</span>;</span>
<span></span>
<span><span class="co"># We will use this just to see how our clustering performed.</span></span>
<span><span class="co"># Not possible with real data!</span></span>
<span><span class="va">groupstrain</span> <span class="op">=</span> <span class="va">groups</span><span class="op">[</span><span class="fl">251</span><span class="op">:</span><span class="fl">750</span><span class="op">]</span>; </span></code></pre></div>
<p>By design,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>y</mi><mo>=</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">P(y = 1)</annotation></semantics></math>
is different across groups:</p>
<div class="sourceCode" id="cb51"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_boxplot.html" class="external-link">geom_boxplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">groups</span>, y<span class="op">=</span><span class="fl">1</span><span class="op">/</span><span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="op">-</span><span class="va">x.beta</span><span class="op">)</span><span class="op">)</span>, group <span class="op">=</span> <span class="va">groups</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Group"</span>, y <span class="op">=</span> <span class="st">"P(y = 1)"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html" class="external-link">theme_minimal</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p><img src="ptLasso_files/figure-html/unnamed-chunk-121-1.png" width="384"></p>
<p>We cluster using <code>rpart</code>. Note that we use
<code>maxdepth = 2</code>: an obvious choice because we simulated the
data and we know that there is a second-level interaction (age + sex)
that determines outcome. In general, however, we recommend keeping this
tree small (<code>maxdepth</code> smaller than 4) so that it is easily
interpretable.</p>
<div class="sourceCode" id="cb52"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">treefit</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/rpart/man/rpart.html" class="external-link">rpart</a></span><span class="op">(</span><span class="va">ycluster</span><span class="op">~</span><span class="va">.</span>, </span>
<span>                data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span><span class="va">zcluster</span>, <span class="va">ycluster</span><span class="op">)</span>, </span>
<span>                control<span class="op">=</span><span class="fu"><a href="https://rdrr.io/pkg/rpart/man/rpart.control.html" class="external-link">rpart.control</a></span><span class="op">(</span>maxdepth<span class="op">=</span><span class="fl">2</span>, minbucket<span class="op">=</span><span class="fl">20</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">treefit</span></span>
<span><span class="co">#&gt; n= 250 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; node), split, n, deviance, yval</span></span>
<span><span class="co">#&gt;       * denotes terminal node</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; 1) root 250 61.82400 0.4480000  </span></span>
<span><span class="co">#&gt;   2) age&lt; 50.5 111 23.18919 0.2972973 *</span></span>
<span><span class="co">#&gt;   3) age&gt;=50.5 139 34.10072 0.5683453  </span></span>
<span><span class="co">#&gt;     6) sex&lt; 0.5 56 13.92857 0.4642857 *</span></span>
<span><span class="co">#&gt;     7) sex&gt;=0.5 83 19.15663 0.6385542 *</span></span></code></pre></div>
<p>We want our tree to return the ID of the terminal node for each
observation instead of class probabilities. The following is a trick
that causes <code>predict</code> to behave as desired.</p>
<div class="sourceCode" id="cb53"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">leaf</span><span class="op">=</span><span class="va">treefit</span><span class="op">$</span><span class="va">frame</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span><span class="op">==</span><span class="st">"&lt;leaf&gt;"</span>   </span>
<span><span class="va">treefit</span><span class="op">$</span><span class="va">frame</span><span class="op">[</span><span class="va">leaf</span>,<span class="st">"yval"</span><span class="op">]</span><span class="op">=</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">leaf</span><span class="op">)</span></span>
<span></span>
<span><span class="va">predgroupstrain</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">treefit</span>, <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span><span class="va">ztrain</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">predgroupstest</span>  <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">treefit</span>, <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span><span class="va">ztest</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>Finally, we are ready to apply pretraining using the predicted groups
as our grouping variable.</p>
<div class="sourceCode" id="cb54"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cvfit</span> <span class="op">=</span> <span class="fu"><a href="../reference/cv.ptLasso.html">cv.ptLasso</a></span><span class="op">(</span><span class="va">xtrain</span>, <span class="va">ytrain</span>, <span class="va">predgroupstrain</span>, family <span class="op">=</span> <span class="st">"binomial"</span>, </span>
<span>                   type.measure <span class="op">=</span> <span class="st">"auc"</span>, nfolds <span class="op">=</span> <span class="fl">10</span>, </span>
<span>                   overall.lambda <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">cvfit</span>, <span class="va">xtest</span>, <span class="va">predgroupstest</span>, ytest <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.cv.ptLasso(object = cvfit, xtest = xtest, groupstest = predgroupstest,  </span></span>
<span><span class="co">#&gt;     ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (AUC):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            allGroups   mean wtdMean group_1 group_2 group_3</span></span>
<span><span class="co">#&gt; Overall       0.7081 0.6448  0.6399  0.6085  0.6575  0.6684</span></span>
<span><span class="co">#&gt; Pretrain      0.7109 0.6590  0.6526  0.6147  0.6823  0.6800</span></span>
<span><span class="co">#&gt; Individual    0.7058 0.6525  0.6477  0.6085  0.6428  0.7063</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                       </span></span>
<span><span class="co">#&gt; Overall    8                          </span></span>
<span><span class="co">#&gt; Pretrain   8 (8 common + 0 individual)</span></span>
<span><span class="co">#&gt; Individual 19</span></span></code></pre></div>
<p>Note that the overall model trained by <code>cv.ptLasso</code> takes
advantage of the clustering: it fits a unique intercept for each group.
Performance would have been much worse if we hadn’t done any clustering
at all:</p>
<div class="sourceCode" id="cb55"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">baseline.model</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">xtrain</span>, <span class="va">ytrain</span>, family <span class="op">=</span> <span class="st">"binomial"</span>, type.measure <span class="op">=</span> <span class="st">"auc"</span>, nfolds <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="va">baseline.model</span>, newx<span class="op">=</span><span class="va">xtest</span>, newy<span class="op">=</span><span class="va">ytest</span><span class="op">)</span><span class="op">$</span><span class="va">auc</span></span>
<span><span class="co">#&gt; [1] 0.6050242</span></span>
<span><span class="co">#&gt; attr(,"measure")</span></span>
<span><span class="co">#&gt; [1] "AUC"</span></span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="target-grouped-data">Target grouped data<a class="anchor" aria-label="anchor" href="#target-grouped-data"></a>
</h2>
<div class="sourceCode" id="cb56"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va"><a href="https://erincr.github.io/ptLasso/">ptLasso</a></span><span class="op">)</span></span></code></pre></div>
<div class="section level3">
<h3 id="intuition">Intuition<a class="anchor" aria-label="anchor" href="#intuition"></a>
</h3>
<p>Now we turn to the <strong>target grouped</strong> setting, where we
have a dataset with a multinomial outcome and no other grouping on the
observations. For example, our data might look like the following:</p>
<div class="sourceCode" id="cb57"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">500</span>; <span class="va">p</span> <span class="op">=</span> <span class="fl">75</span>; <span class="va">k</span> <span class="op">=</span> <span class="fl">3</span></span>
<span><span class="va">X</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="va">n</span>, ncol <span class="op">=</span> <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">k</span>, <span class="va">n</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="va">Xtest</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="va">n</span>, ncol <span class="op">=</span> <span class="va">p</span><span class="op">)</span></span></code></pre></div>
<p>Each row in
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
belongs to class 1, 2 or 3, and we wish to predict class membership. We
could fit a single multinomial model to the data:</p>
<div class="sourceCode" id="cb58"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">multinomial</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span>, family <span class="op">=</span> <span class="st">"multinomial"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">multipreds</span>  <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">multinomial</span>, <span class="va">Xtest</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span></span>
<span><span class="va">multipreds.class</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">multipreds</span>, <span class="fl">1</span>, <span class="va">which.max</span><span class="op">)</span></span></code></pre></div>
<p>Or, we could fit 3 one-vs-rest models; at prediction time, we would
assign observations to the class with the highest probability.</p>
<div class="sourceCode" id="cb59"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">class1</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span> <span class="op">==</span> <span class="fl">1</span>, family <span class="op">=</span> <span class="st">"binomial"</span><span class="op">)</span></span>
<span><span class="va">class2</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span> <span class="op">==</span> <span class="fl">2</span>, family <span class="op">=</span> <span class="st">"binomial"</span><span class="op">)</span></span>
<span><span class="va">class3</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span> <span class="op">==</span> <span class="fl">3</span>, family <span class="op">=</span> <span class="st">"binomial"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">ovrpreds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">class1</span>, <span class="va">Xtest</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">class2</span>, <span class="va">Xtest</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">class3</span>, <span class="va">Xtest</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">ovrpreds.class</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">ovrpreds</span>, <span class="fl">1</span>, <span class="va">which.max</span><span class="op">)</span></span></code></pre></div>
<p>Another alternative is to do pretraining, which fits something <em>in
between</em> one model for all data and three separate models.
<code>ptLasso</code> will do this for you, using the arguments
<code>family = "multinomial"</code> and
<code>use.case = "targetGroups"</code>.</p>
<div class="sourceCode" id="cb60"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span>, groups <span class="op">=</span> <span class="va">y</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>,</span>
<span>              family <span class="op">=</span> <span class="st">"multinomial"</span>, </span>
<span>              use.case <span class="op">=</span> <span class="st">"targetGroups"</span><span class="op">)</span></span></code></pre></div>
<p>But what exactly is pretraining doing here? We’ll walk through an
example, doing pretraining “by hand”. The steps are:</p>
<ol style="list-style-type: decimal">
<li>Train an overall model: a multinomial model using a penalty on the
coefficients
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>β</mi><annotation encoding="application/x-tex">\beta</annotation></semantics></math>
so that each coefficient is either 0 or nonzero for all classes.</li>
<li>Train individual one-vs-rest models using the penalty factor and
offset defined by the overall model (as in the input grouped
setting).</li>
</ol>
<p>To train the overall model, we use <code>cv.glmnet</code> with
<code>type.multinomial = "grouped"</code>. This puts a penalty on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>β</mi><annotation encoding="application/x-tex">\beta</annotation></semantics></math>
to force coefficients to be <em>in</em> or <em>out</em> of the model for
all classes. This is analogous to the overall model in the input grouped
setting: we want to first learn <strong>shared</strong> information.</p>
<div class="sourceCode" id="cb61"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">multinomial</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span>, family <span class="op">=</span> <span class="st">"multinomial"</span>, </span>
<span>                        type.multinomial <span class="op">=</span> <span class="st">"grouped"</span>,</span>
<span>                        keep <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<p>Then, we fit 3 one-vs-rest models using the support and offset from
the multinomial model.</p>
<div class="sourceCode" id="cb62"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># The support of the overall model:</span></span>
<span><span class="va">nonzero.coefs</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">multinomial</span>, s <span class="op">=</span> <span class="st">"lambda.1se"</span><span class="op">)</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span> <span class="op">!=</span> <span class="fl">0</span><span class="op">)</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># The offsets - one for each class:</span></span>
<span><span class="va">offset</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">multinomial</span>, <span class="va">X</span>, s <span class="op">=</span> <span class="st">"lambda.1se"</span><span class="op">)</span></span>
<span><span class="va">offset.class1</span> <span class="op">=</span> <span class="va">offset</span><span class="op">[</span>, <span class="fl">1</span>, <span class="fl">1</span><span class="op">]</span></span>
<span><span class="va">offset.class2</span> <span class="op">=</span> <span class="va">offset</span><span class="op">[</span>, <span class="fl">2</span>, <span class="fl">1</span><span class="op">]</span></span>
<span><span class="va">offset.class3</span> <span class="op">=</span> <span class="va">offset</span><span class="op">[</span>, <span class="fl">3</span>, <span class="fl">1</span><span class="op">]</span></span></code></pre></div>
<p>Now we have everything we need to train the one-vs-rest models. As
always, we have the pretraining parameter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
- for this example, let’s use
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">\alpha = 0.5</annotation></semantics></math>:</p>
<div class="sourceCode" id="cb63"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">alpha</span> <span class="op">=</span> <span class="fl">0.5</span></span>
<span><span class="va">penalty.factor</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="va">alpha</span>, <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">penalty.factor</span><span class="op">[</span><span class="va">nonzero.coefs</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1</span></span>
<span></span>
<span><span class="va">class1</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span> <span class="op">==</span> <span class="fl">1</span>, family <span class="op">=</span> <span class="st">"binomial"</span>, </span>
<span>                   offset <span class="op">=</span> <span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">alpha</span><span class="op">)</span> <span class="op">*</span> <span class="va">offset.class1</span>,</span>
<span>                   penalty.factor <span class="op">=</span> <span class="va">penalty.factor</span><span class="op">)</span></span>
<span><span class="va">class2</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span> <span class="op">==</span> <span class="fl">2</span>, family <span class="op">=</span> <span class="st">"binomial"</span>, </span>
<span>                   offset <span class="op">=</span> <span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">alpha</span><span class="op">)</span> <span class="op">*</span> <span class="va">offset.class2</span>,</span>
<span>                   penalty.factor <span class="op">=</span> <span class="va">penalty.factor</span><span class="op">)</span></span>
<span><span class="va">class3</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span> <span class="op">==</span> <span class="fl">3</span>, family <span class="op">=</span> <span class="st">"binomial"</span>, </span>
<span>                   offset <span class="op">=</span> <span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">alpha</span><span class="op">)</span> <span class="op">*</span> <span class="va">offset.class3</span>,</span>
<span>                   penalty.factor <span class="op">=</span> <span class="va">penalty.factor</span><span class="op">)</span></span></code></pre></div>
<p>And we’re done with pretraining! To predict, we again assign each row
to the class with the highest prediction:</p>
<div class="sourceCode" id="cb64"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">newoffset</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">multinomial</span>, <span class="va">X</span>, s <span class="op">=</span> <span class="st">"lambda.1se"</span><span class="op">)</span></span>
<span><span class="va">ovrpreds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">class1</span>, <span class="va">Xtest</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span>, newoffset <span class="op">=</span> <span class="va">newoffset</span><span class="op">[</span>, <span class="fl">1</span>, <span class="fl">1</span><span class="op">]</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">class2</span>, <span class="va">Xtest</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span>, newoffset <span class="op">=</span> <span class="va">newoffset</span><span class="op">[</span>, <span class="fl">2</span>, <span class="fl">1</span><span class="op">]</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">class3</span>, <span class="va">Xtest</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span>, newoffset <span class="op">=</span> <span class="va">newoffset</span><span class="op">[</span>, <span class="fl">3</span>, <span class="fl">1</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="va">ovrpreds.class</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">ovrpreds</span>, <span class="fl">1</span>, <span class="va">which.max</span><span class="op">)</span></span></code></pre></div>
<p>This is all done automatically within <code>ptLasso</code>; we will
now show an example using the <code>ptLasso</code> functions. The
example above is intended only to show how pretraining works for
multinomial outcomes, and some technical details have been omitted. (For
example, <code>ptLasso</code> takes care of crossfitting between the
first and second steps.)</p>
</div>
<div class="section level3">
<h3 id="example">Example<a class="anchor" aria-label="anchor" href="#example"></a>
</h3>
<p>First, let’s simulate multinomial data with 5 classes. We start by
drawing
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
from a normal distribution (uncorrelated features), and then we shift
the columns differently for each group.</p>
<div class="sourceCode" id="cb65"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">500</span>; <span class="va">p</span> <span class="op">=</span> <span class="fl">50</span>; <span class="va">k</span> <span class="op">=</span> <span class="fl">5</span></span>
<span><span class="va">class.sizes</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="va">n</span><span class="op">/</span><span class="va">k</span>, <span class="va">k</span><span class="op">)</span></span>
<span><span class="va">ncommon</span> <span class="op">=</span> <span class="fl">10</span>; <span class="va">nindiv</span> <span class="op">=</span> <span class="fl">5</span>;</span>
<span><span class="va">shift.common</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">.2</span>, <span class="fl">.2</span>, length.out <span class="op">=</span> <span class="va">k</span><span class="op">)</span></span>
<span><span class="va">shift.indiv</span>  <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">.1</span>, <span class="fl">.1</span>, length.out <span class="op">=</span> <span class="va">k</span><span class="op">)</span></span>
<span></span>
<span><span class="va">x</span>     <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, <span class="va">n</span>, <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">xtest</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, <span class="va">n</span>, <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">ytest</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">sapply</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">class.sizes</span><span class="op">)</span>, <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="va">i</span>, <span class="va">class.sizes</span><span class="op">[</span><span class="va">i</span><span class="op">]</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">start</span> <span class="op">=</span> <span class="va">ncommon</span> <span class="op">+</span> <span class="fl">1</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">k</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">end</span> <span class="op">=</span> <span class="va">start</span> <span class="op">+</span> <span class="va">nindiv</span> <span class="op">-</span> <span class="fl">1</span></span>
<span>  <span class="va">x</span><span class="op">[</span><span class="va">y</span> <span class="op">==</span> <span class="va">i</span>, <span class="fl">1</span><span class="op">:</span><span class="va">ncommon</span><span class="op">]</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">y</span> <span class="op">==</span> <span class="va">i</span>, <span class="fl">1</span><span class="op">:</span><span class="va">ncommon</span><span class="op">]</span> <span class="op">+</span> <span class="va">shift.common</span><span class="op">[</span><span class="va">i</span><span class="op">]</span></span>
<span>  <span class="va">x</span><span class="op">[</span><span class="va">y</span> <span class="op">==</span> <span class="va">i</span>, <span class="va">start</span><span class="op">:</span><span class="va">end</span><span class="op">]</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">y</span> <span class="op">==</span> <span class="va">i</span>, <span class="va">start</span><span class="op">:</span><span class="va">end</span><span class="op">]</span> <span class="op">+</span> <span class="va">shift.indiv</span><span class="op">[</span><span class="va">i</span><span class="op">]</span></span>
<span>  </span>
<span>  <span class="va">xtest</span><span class="op">[</span><span class="va">ytest</span> <span class="op">==</span> <span class="va">i</span>, <span class="fl">1</span><span class="op">:</span><span class="va">ncommon</span><span class="op">]</span> <span class="op">=</span> <span class="va">xtest</span><span class="op">[</span><span class="va">ytest</span> <span class="op">==</span> <span class="va">i</span>, <span class="fl">1</span><span class="op">:</span><span class="va">ncommon</span><span class="op">]</span> <span class="op">+</span> <span class="va">shift.common</span><span class="op">[</span><span class="va">i</span><span class="op">]</span></span>
<span>  <span class="va">xtest</span><span class="op">[</span><span class="va">ytest</span> <span class="op">==</span> <span class="va">i</span>, <span class="va">start</span><span class="op">:</span><span class="va">end</span><span class="op">]</span> <span class="op">=</span> <span class="va">xtest</span><span class="op">[</span><span class="va">ytest</span> <span class="op">==</span> <span class="va">i</span>, <span class="va">start</span><span class="op">:</span><span class="va">end</span><span class="op">]</span> <span class="op">+</span> <span class="va">shift.indiv</span><span class="op">[</span><span class="va">i</span><span class="op">]</span></span>
<span>  <span class="va">start</span> <span class="op">=</span> <span class="va">end</span> <span class="op">+</span> <span class="fl">1</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>The calls to <code>ptLasso</code> and <code>cv.ptLasso</code> are
almost the same as in the input grouped setting, only now we specify
<code>use.case = "targetGroups"</code>. The call to <code>predict</code>
does not require a <code>groups</code> argument because the groups are
unknown at prediction time.</p>
<div class="sourceCode" id="cb66"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">################################################################################</span></span>
<span><span class="co"># Fit the pretrained model.</span></span>
<span><span class="co"># By default, ptLasso uses type.measure = "deviance", but for ease of</span></span>
<span><span class="co"># interpretability, we use type.measure = "class" (the misclassification rate).</span></span>
<span><span class="co">################################################################################</span></span>
<span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span>, </span>
<span>              use.case <span class="op">=</span> <span class="st">"targetGroups"</span>, type.measure <span class="op">=</span> <span class="st">"class"</span><span class="op">)</span></span>
<span></span>
<span><span class="co">################################################################################</span></span>
<span><span class="co"># Predict</span></span>
<span><span class="co">################################################################################</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">xtest</span>, ytest <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.ptLasso(object = fit, xtest = xtest, ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0.5 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (Misclassification error):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            overall   mean group_1 group_2 group_3 group_4 group_5</span></span>
<span><span class="co">#&gt; Overall      0.738                                               </span></span>
<span><span class="co">#&gt; Pretrain     0.728 0.2000   0.200     0.2     0.2     0.2   0.200</span></span>
<span><span class="co">#&gt; Individual   0.736 0.1984   0.196     0.2     0.2     0.2   0.196</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                         </span></span>
<span><span class="co">#&gt; Overall    29                           </span></span>
<span><span class="co">#&gt; Pretrain   23 (23 common + 0 individual)</span></span>
<span><span class="co">#&gt; Individual 32</span></span>
<span></span>
<span><span class="co">################################################################################</span></span>
<span><span class="co"># Fit with CV to choose the alpha parameter</span></span>
<span><span class="co">################################################################################</span></span>
<span><span class="va">cvfit</span> <span class="op">=</span> <span class="fu"><a href="../reference/cv.ptLasso.html">cv.ptLasso</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span>,</span>
<span>              use.case <span class="op">=</span> <span class="st">"targetGroups"</span>, type.measure <span class="op">=</span> <span class="st">"class"</span><span class="op">)</span></span>
<span></span>
<span><span class="co">################################################################################</span></span>
<span><span class="co"># Predict using one alpha for all classes</span></span>
<span><span class="co">################################################################################</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">cvfit</span>, <span class="va">xtest</span>, ytest <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.cv.ptLasso(object = cvfit, xtest = xtest, ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0.9 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (Misclassification error):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            overall   mean group_1 group_2 group_3 group_4 group_5</span></span>
<span><span class="co">#&gt; Overall      0.738                                               </span></span>
<span><span class="co">#&gt; Pretrain     0.722 0.1992     0.2     0.2     0.2     0.2   0.196</span></span>
<span><span class="co">#&gt; Individual   0.742 0.2000     0.2     0.2     0.2     0.2   0.200</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                         </span></span>
<span><span class="co">#&gt; Overall    39                           </span></span>
<span><span class="co">#&gt; Pretrain   32 (23 common + 9 individual)</span></span>
<span><span class="co">#&gt; Individual 36</span></span>
<span></span>
<span><span class="co">################################################################################</span></span>
<span><span class="co"># Predict using a separate alpha for each class</span></span>
<span><span class="co">################################################################################</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">cvfit</span>, <span class="va">xtest</span>, ytest <span class="op">=</span> <span class="va">ytest</span>, alphatype <span class="op">=</span> <span class="st">"varying"</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.cv.ptLasso(object = cvfit, xtest = xtest, ytest = ytest,  </span></span>
<span><span class="co">#&gt;     alphatype = "varying") </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0.1 0 0.7 0 0.1 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (Misclassification error):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            overall   mean group_1 group_2 group_3 group_4 group_5</span></span>
<span><span class="co">#&gt; Overall      0.738                                               </span></span>
<span><span class="co">#&gt; Pretrain     0.742 0.2016   0.208     0.2     0.2   0.202   0.198</span></span>
<span><span class="co">#&gt; Individual   0.742 0.2000   0.200     0.2     0.2   0.200   0.200</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                          </span></span>
<span><span class="co">#&gt; Overall    39                            </span></span>
<span><span class="co">#&gt; Pretrain   36 (23 common + 13 individual)</span></span>
<span><span class="co">#&gt; Individual 36</span></span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="multi-response-data-with-gaussian-responses">Multi-response data with Gaussian responses<a class="anchor" aria-label="anchor" href="#multi-response-data-with-gaussian-responses"></a>
</h2>
<div class="sourceCode" id="cb67"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va"><a href="https://erincr.github.io/ptLasso/">ptLasso</a></span><span class="op">)</span></span></code></pre></div>
<p>Multitask learning consists of data
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
with two or more responses
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mn>1</mn></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mi>y</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">y_1, \dots, y_j</annotation></semantics></math>.
We usually assume that there is shared signal across the responses, and
that performance can be improved by jointly fitting models for the
responses.</p>
<p>Here, we suppose that we wish to predict multiple <strong>Gaussian
responses</strong>. (If the goal is to predict multiple responses of a
different type, see the section “Multi-response data with mixed response
types”.)</p>
<p>Pretraining is a natural choice for multitask learning – it allows us
to pass information between models for the different responses. The
overview for our approach is to:</p>
<ol style="list-style-type: decimal">
<li>fit a multi-response Gaussian model using a group lasso penalty
(more below),</li>
<li>extract the support (shared across responses) and offsets (one for
each response), and</li>
<li>fit a model for each response, using the shared support and
appropriate offset.</li>
</ol>
<p>Importantly, the group lasso penalty behaves like the lasso, but on
the whole group of coefficients for each response: they are either all
zero, or else none are zero (see the <code>glmnet</code> documentation
about <code>family = "mgaussian"</code> for more detail). As a result,
the multi-response Gaussian model is forced to choose the same support
for all responses
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mn>1</mn></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mi>y</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">y_1, \dots, y_j</annotation></semantics></math>.
This encourages learning <em>across</em> all responses in the first
stage; in the second stage, we find features that are specific to each
individual response
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mi>k</mi></msub><annotation encoding="application/x-tex">y_k</annotation></semantics></math>.</p>
<p>This is all done with the function <code>ptLasso</code>, using the
argument <code>use.case = "multiresponse"</code>.</p>
<p>We will illustrate this with simulated data with two Gaussian
responses; the two responses share the first 5 features, and they each
have 5 features of their own. The two responses are quite related, with
Pearson correlation around 0.5.</p>
<div class="sourceCode" id="cb68"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Define constants</span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">1000</span>         <span class="co"># Total number of samples</span></span>
<span><span class="va">ntrain</span> <span class="op">=</span> <span class="fl">650</span>     <span class="co"># Number of training samples</span></span>
<span><span class="va">p</span> <span class="op">=</span> <span class="fl">500</span>          <span class="co"># Number of features</span></span>
<span><span class="va">sigma</span> <span class="op">=</span> <span class="fl">2</span>        <span class="co"># Standard deviation of noise</span></span>
<span>     </span>
<span></span>
<span><span class="co"># Generate covariate matrix</span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, <span class="va">n</span>, <span class="va">p</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Define coefficients for responses 1 and 2</span></span>
<span><span class="va">beta1</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">5</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="fl">5</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span> <span class="op">-</span> <span class="fl">10</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">beta2</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">5</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">5</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="fl">5</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span> <span class="op">-</span> <span class="fl">15</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">mu</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">x</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta1</span>, <span class="va">x</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta2</span><span class="op">)</span></span>
<span><span class="va">y</span>  <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">mu</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="va">sigma</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span>, </span>
<span>           <span class="va">mu</span><span class="op">[</span>, <span class="fl">2</span><span class="op">]</span> <span class="op">+</span> <span class="va">sigma</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"SNR for the two tasks:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/diag.html" class="external-link">diag</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html" class="external-link">var</a></span><span class="op">(</span><span class="va">mu</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html" class="external-link">var</a></span><span class="op">(</span><span class="va">y</span><span class="op">-</span><span class="va">mu</span><span class="op">)</span><span class="op">)</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; SNR for the two tasks: 1.6 1.44</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Correlation between two tasks:"</span>, <span class="fu"><a href="https://rdrr.io/r/stats/cor.html" class="external-link">cor</a></span><span class="op">(</span><span class="va">y</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span>, <span class="va">y</span><span class="op">[</span>, <span class="fl">2</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Correlation between two tasks: 0.5164748</span></span>
<span></span>
<span><span class="co"># Split into train and test</span></span>
<span><span class="va">xtest</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span>, <span class="op">]</span></span>
<span><span class="va">ytest</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span>, <span class="op">]</span></span>
<span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span>, <span class="op">]</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span>, <span class="op">]</span></span></code></pre></div>
<p>Now, we are ready to call <code>ptLasso</code> with our covariates
<code>x</code> and response matrix <code>y</code>, and we specify the
argument <code>use.case = "multiresponse"</code>. A call to
<code>plot</code> shows the CV curves over the lasso parameter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>
for each model.</p>
<div class="sourceCode" id="cb69"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, use.case <span class="op">=</span> <span class="st">"multiresponse"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span></code></pre></div>
<p><img src="ptLasso_files/figure-html/unnamed-chunk-165-1.png" width="700"></p>
<p>To choose the pretraining parameter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>,
we can use <code>cv.ptLasso</code>. Using <code>plot</code>, we can view
the CV curve for pretraining together with the overall model
(multi-response Gaussian model) and the individual model (a separate
Gaussian model for each response).</p>
<div class="sourceCode" id="cb70"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/cv.ptLasso.html">cv.ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, use.case <span class="op">=</span> <span class="st">"multiresponse"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span></code></pre></div>
<p><img src="ptLasso_files/figure-html/unnamed-chunk-166-1.png" width="700"></p>
<p>As in previous examples, we can predict using the
<code>predict</code>; if <code>ytest</code> is supplied, this will print
the mean squared error as well as the support size for the pretrained,
overall and individual models using the single
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
that minimizes the the average CV MSE across both responses.</p>
<div class="sourceCode" id="cb71"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">xtest</span>, ytest <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span></span>
<span><span class="va">preds</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.cv.ptLasso(object = fit, xtest = xtest, ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0.3 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (Mean squared error):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            allGroups  mean response_1 response_2</span></span>
<span><span class="co">#&gt; Overall        9.217 4.608      4.092      5.125</span></span>
<span><span class="co">#&gt; Pretrain       9.006 4.503      4.149      4.857</span></span>
<span><span class="co">#&gt; Individual     9.324 4.662      4.168      5.157</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                         </span></span>
<span><span class="co">#&gt; Overall    57                           </span></span>
<span><span class="co">#&gt; Pretrain   22 (20 common + 2 individual)</span></span>
<span><span class="co">#&gt; Individual 75</span></span></code></pre></div>
<p>Also as before, we can choose to use the value of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
that minimizes the CV MSE for <em>each</em> response.</p>
<div class="sourceCode" id="cb72"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">xtest</span>, ytest <span class="op">=</span> <span class="va">ytest</span>, alphatype <span class="op">=</span> <span class="st">"varying"</span><span class="op">)</span></span>
<span><span class="va">preds</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.cv.ptLasso(object = fit, xtest = xtest, ytest = ytest,  </span></span>
<span><span class="co">#&gt;     alphatype = "varying") </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha:</span></span>
<span><span class="co">#&gt; [1] 0.3 0.3</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (Mean squared error):</span></span>
<span><span class="co">#&gt;            allGroups  mean response_1 response_2</span></span>
<span><span class="co">#&gt; Overall        9.217 4.608      4.092      5.125</span></span>
<span><span class="co">#&gt; Pretrain       9.006 4.503      4.149      4.857</span></span>
<span><span class="co">#&gt; Individual     9.324 4.662      4.168      5.157</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                         </span></span>
<span><span class="co">#&gt; Overall    57                           </span></span>
<span><span class="co">#&gt; Pretrain   22 (20 common + 2 individual)</span></span>
<span><span class="co">#&gt; Individual 75</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="time-series-data">Time series data<a class="anchor" aria-label="anchor" href="#time-series-data"></a>
</h2>
<div class="sourceCode" id="cb73"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va"><a href="https://erincr.github.io/ptLasso/">ptLasso</a></span><span class="op">)</span></span></code></pre></div>
<p>We may have repeated measurements of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>
across time; for example, we may observe patients at two different
points in time. We expect that the relationship between
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>
will be different at time 1 and time 2, but not completely unrelated.
Therefore, pretraining can be useful: we can use the model fitted at
time 1 to inform the model for time 2.</p>
<p><code>ptLasso</code> supports this setting, and below is an example.
We first assume that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
is constant across time, and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>
changes. Later, we will show an example where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
changes across time.</p>
<p>To do pretraining with time series data, we:</p>
<ol style="list-style-type: decimal">
<li>fit a model for time 1 and extract its offset and support,</li>
<li>use the offset and support (the usual pretraining) to train a model
for time 2.</li>
</ol>
<p>We could continue this for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
time points: after fitting a model for time 2, we would extract the
offset and support. Now, the offset will include the offset from time 1
and the prediction from time 2; the support will be the <em>union</em>
of supports from the first two models.</p>
<div class="section level3">
<h3 id="example-1-covariates-are-constant-over-time">Example 1: covariates are constant over time<a class="anchor" aria-label="anchor" href="#example-1-covariates-are-constant-over-time"></a>
</h3>
<p>We’ll start by simulating data – more details in the comments.</p>
<div class="sourceCode" id="cb74"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Define constants</span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">600</span>          <span class="co"># Total number of samples</span></span>
<span><span class="va">ntrain</span> <span class="op">=</span> <span class="fl">300</span>     <span class="co"># Number of training samples</span></span>
<span><span class="va">p</span> <span class="op">=</span> <span class="fl">100</span>          <span class="co"># Number of features</span></span>
<span><span class="va">sigma</span> <span class="op">=</span> <span class="fl">3</span>        <span class="co"># Standard deviation of noise</span></span>
<span></span>
<span><span class="co"># Generate covariate matrix</span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, <span class="va">n</span>, <span class="va">p</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Define coefficients for time points 1 and 2</span></span>
<span><span class="va">beta1</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">10</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span> <span class="op">-</span> <span class="fl">10</span><span class="op">)</span><span class="op">)</span>  <span class="co"># Coefs at time 1</span></span>
<span><span class="va">beta2</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">p</span>, <span class="fl">0.5</span>, <span class="fl">2</span><span class="op">)</span> <span class="op">*</span> <span class="va">beta1</span>       <span class="co"># Coefs at time 2, shared support with time 1</span></span>
<span></span>
<span><span class="co"># Generate response variables for times 1 and 2</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span></span>
<span>  <span class="va">x</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta1</span> <span class="op">+</span> <span class="va">sigma</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span>,</span>
<span>  <span class="va">x</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta2</span> <span class="op">+</span> <span class="va">sigma</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Split data into training and testing sets</span></span>
<span><span class="va">xtest</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span>, <span class="op">]</span>  <span class="co"># Test covariates</span></span>
<span><span class="va">ytest</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span>, <span class="op">]</span>  <span class="co"># Test response</span></span>
<span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span>, <span class="op">]</span>  <span class="co"># Train covariates</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span>, <span class="op">]</span>  <span class="co"># Train response</span></span></code></pre></div>
<p>Having simulated data, we are ready to call <code>ptLasso</code>; the
call to <code>ptLasso</code> looks much the same as in all our other
examples, only now (1)
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>
is a matrix with one column for each time point and (2) we specify
<code>use.case = "timeSeries"</code>. After fitting, a call to
<code>plot</code> shows the models fitted for both of the time points
with and without using pretraining.</p>
<div class="sourceCode" id="cb75"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, use.case <span class="op">=</span> <span class="st">"timeSeries"</span>, alpha <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span></code></pre></div>
<p><img src="ptLasso_files/figure-html/unnamed-chunk-180-1.png" width="700"></p>
<p>And as before, we can <code>predict</code> with <code>xtest</code>.
In this example, pretraining helps performance: the two time points
share the same support, and pretraining discovers and leverages
this.</p>
<div class="sourceCode" id="cb76"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">xtest</span>, ytest <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span></span>
<span><span class="va">preds</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.ptLasso(object = fit, xtest = xtest, ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (Mean squared error):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;              mean response_1 response_2</span></span>
<span><span class="co">#&gt; Pretrain    9.604      10.78      8.428</span></span>
<span><span class="co">#&gt; Individual 10.428      10.78     10.076</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                          </span></span>
<span><span class="co">#&gt; Pretrain   26 (10 common + 16 individual)</span></span>
<span><span class="co">#&gt; Individual 39</span></span></code></pre></div>
<p>We specified <code>alpha = 0</code> in this example, but cross
validation would advise us to choose
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.2</mn></mrow><annotation encoding="application/x-tex">\alpha = 0.2</annotation></semantics></math>.
Plotting shows us the average performance across the two time points.
Importantly, at time 1, the individual model and the pretrained model
are the same; we do not see the advantage of pretraining until time 2
(when we use information from time 1).</p>
<div class="sourceCode" id="cb77"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cvfit</span> <span class="op">=</span> <span class="fu"><a href="../reference/cv.ptLasso.html">cv.ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, use.case <span class="op">=</span> <span class="st">"timeSeries"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">cvfit</span><span class="op">)</span></span></code></pre></div>
<p><img src="ptLasso_files/figure-html/unnamed-chunk-182-1.png" width="700"></p>
<div class="sourceCode" id="cb78"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">cvfit</span>, <span class="va">xtest</span>, ytest <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.cv.ptLasso(object = cvfit, xtest = xtest, ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0.2 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (Mean squared error):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;              mean response_1 response_2</span></span>
<span><span class="co">#&gt; Pretrain    9.875      10.87      8.884</span></span>
<span><span class="co">#&gt; Individual 10.447      10.87     10.027</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                          </span></span>
<span><span class="co">#&gt; Pretrain   28 (10 common + 18 individual)</span></span>
<span><span class="co">#&gt; Individual 40</span></span></code></pre></div>
<p>Note that we could also have treated this as a <em>multireponse</em>
problem, and ignored the time-ordering of the responses. See more in the
section called “Multi-response data with Gaussian responses”. (However,
time ordering can be informative, and the multi-response approach does
not make use of this.)</p>
<div class="sourceCode" id="cb79"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, use.case <span class="op">=</span> <span class="st">"multiresponse"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="example-2-covariates-change-over-time">Example 2: covariates change over time<a class="anchor" aria-label="anchor" href="#example-2-covariates-change-over-time"></a>
</h3>
<p>Now, we’ll repeat what we did above, but we’ll simulate data where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>
changes with time. In this setting, <code>ptLasso</code> expects
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>
to be a list with one covariate matrix for each time.</p>
<div class="sourceCode" id="cb80"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span>  <span class="co"># Set seed for reproducibility</span></span>
<span></span>
<span><span class="co"># Define constants</span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">600</span>          <span class="co"># Total number of samples</span></span>
<span><span class="va">ntrain</span> <span class="op">=</span> <span class="fl">300</span>     <span class="co"># Number of training samples</span></span>
<span><span class="va">p</span> <span class="op">=</span> <span class="fl">100</span>          <span class="co"># Number of features</span></span>
<span><span class="va">sigma</span> <span class="op">=</span> <span class="fl">3</span>        <span class="co"># Standard deviation of noise</span></span>
<span></span>
<span><span class="co"># Covariates for times 1 and 2</span></span>
<span><span class="va">x1</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, <span class="va">n</span>, <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">x2</span> <span class="op">=</span> <span class="va">x1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fl">0.2</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, <span class="va">n</span>, <span class="va">p</span><span class="op">)</span>  <span class="co"># Perturbed covariates for time 2</span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">x1</span>, <span class="va">x2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Define coefficients for time points 1 and 2</span></span>
<span><span class="va">beta1</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">10</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span> <span class="op">-</span> <span class="fl">10</span><span class="op">)</span><span class="op">)</span>  <span class="co"># Coefs at time 1</span></span>
<span><span class="va">beta2</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">p</span>, <span class="fl">0.5</span>, <span class="fl">2</span><span class="op">)</span> <span class="op">*</span> <span class="va">beta1</span>       <span class="co"># Coefs at time 2, shared support with time 1</span></span>
<span></span>
<span><span class="co"># Response variables for times 1 and 2:</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span></span>
<span>  <span class="va">x</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta1</span> <span class="op">+</span> <span class="va">sigma</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span>,</span>
<span>  <span class="va">x</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta2</span> <span class="op">+</span> <span class="va">sigma</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Split data into training and testing sets</span></span>
<span><span class="va">xtest</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">lapply</a></span><span class="op">(</span><span class="va">x</span>, <span class="kw">function</span><span class="op">(</span><span class="va">xx</span><span class="op">)</span> <span class="va">xx</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span>, <span class="op">]</span><span class="op">)</span>  <span class="co"># Test covariates</span></span>
<span><span class="va">ytest</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span>, <span class="op">]</span>  <span class="co"># Test response</span></span>
<span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">lapply</a></span><span class="op">(</span><span class="va">x</span>, <span class="kw">function</span><span class="op">(</span><span class="va">xx</span><span class="op">)</span> <span class="va">xx</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span>, <span class="op">]</span><span class="op">)</span>  <span class="co"># Train covariates</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span>, <span class="op">]</span>  <span class="co"># Train response</span></span></code></pre></div>
<p>Now,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>
is a list of length two:</p>
<div class="sourceCode" id="cb81"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="co">#&gt; List of 2</span></span>
<span><span class="co">#&gt;  $ : num [1:300, 1:100] -1.207 0.277 1.084 -2.346 0.429 ...</span></span>
<span><span class="co">#&gt;  $ : num [1:300, 1:100] -1.493 0.303 1.172 -2.316 0.224 ...</span></span></code></pre></div>
<p>We can call <code>ptLasso</code>, <code>cv.ptLasso</code>,
<code>plot</code> and <code>predict</code> just as before:</p>
<div class="sourceCode" id="cb82"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, use.case <span class="op">=</span> <span class="st">"timeSeries"</span>, alpha <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span>  <span class="co"># Plot the fitted model</span></span></code></pre></div>
<p><img src="ptLasso_files/figure-html/unnamed-chunk-186-1.png" width="700"></p>
<div class="sourceCode" id="cb83"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">xtest</span>, ytest <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span>  <span class="co"># Predict using the fitted model</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.ptLasso(object = fit, xtest = xtest, ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (Mean squared error):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;             mean response_1 response_2</span></span>
<span><span class="co">#&gt; Pretrain   11.92       12.1      11.75</span></span>
<span><span class="co">#&gt; Individual 11.46       12.1      10.82</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                          </span></span>
<span><span class="co">#&gt; Pretrain   36 (16 common + 20 individual)</span></span>
<span><span class="co">#&gt; Individual 61</span></span>
<span></span>
<span><span class="co"># With cross validation:</span></span>
<span><span class="va">cvfit</span> <span class="op">=</span> <span class="fu"><a href="../reference/cv.ptLasso.html">cv.ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, use.case <span class="op">=</span> <span class="st">"timeSeries"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">cvfit</span>, plot.alphahat <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>  <span class="co"># Plot cross-validated model</span></span></code></pre></div>
<p><img src="ptLasso_files/figure-html/unnamed-chunk-186-2.png" width="700"></p>
<div class="sourceCode" id="cb84"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">cvfit</span>, <span class="va">xtest</span>, ytest <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span>  <span class="co"># Predict using cross-validated model</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.cv.ptLasso(object = cvfit, xtest = xtest, ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0.4 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (Mean squared error):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;             mean response_1 response_2</span></span>
<span><span class="co">#&gt; Pretrain   11.55      12.11      11.00</span></span>
<span><span class="co">#&gt; Individual 11.53      12.11      10.96</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                          </span></span>
<span><span class="co">#&gt; Pretrain   54 (19 common + 35 individual)</span></span>
<span><span class="co">#&gt; Individual 65</span></span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="more-examples-of-pretraining-using-glmnet">More examples of pretraining using <code>glmnet</code><a class="anchor" aria-label="anchor" href="#more-examples-of-pretraining-using-glmnet"></a>
</h2>
<div class="section level3">
<h3 id="multi-response-data-with-mixed-response-types">Multi-response data with mixed response types<a class="anchor" aria-label="anchor" href="#multi-response-data-with-mixed-response-types"></a>
</h3>
<div class="sourceCode" id="cb85"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va"><a href="https://glmnet.stanford.edu" class="external-link">glmnet</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va"><a href="https://github.com/therneau/survival" class="external-link">survival</a></span><span class="op">)</span></span></code></pre></div>
<p>Muti-response data consists of datasets with covariates
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
and multiple outcomes
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mn>1</mn></msub><mo>,</mo><msub><mi>y</mi><mn>2</mn></msub><mo>,</mo><msub><mi>y</mi><mn>3</mn></msub><mo>,</mo><mi>…</mi></mrow><annotation encoding="application/x-tex">y_1, y_2, y_3, \dots</annotation></semantics></math>.
If these outcomes are all continuous, then it may be natural to treat
this as a multitask learning problem (see the section “Multi-response
data with Gaussian responses”). If the outcomes have mixed types however
–
e.g. <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>1</mn></msub><annotation encoding="application/x-tex">y_1</annotation></semantics></math>
is continuous,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>2</mn></msub><annotation encoding="application/x-tex">y_2</annotation></semantics></math>
binary and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>3</mn></msub><annotation encoding="application/x-tex">y_3</annotation></semantics></math>
survival – then the problem is slightly more challenging, because there
are fewer methods developed for this setting.</p>
<p>Pretraining is a natural fit for this task: we often believe that
there is shared information between
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>1</mn></msub><annotation encoding="application/x-tex">y_1</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>2</mn></msub><annotation encoding="application/x-tex">y_2</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>3</mn></msub><annotation encoding="application/x-tex">y_3</annotation></semantics></math>.
If we fit 3 separate models, we never get to take advantage of any
shared information; further, because the outcomes have different types,
there are very few methods to fit <em>one</em> model for all outcomes
(an “overall model”).</p>
<p>So, we will use pretraining to pass information between models. We
will:</p>
<ol style="list-style-type: decimal">
<li>fit a model for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>1</mn></msub><annotation encoding="application/x-tex">y_1</annotation></semantics></math>,</li>
<li>extract the offset and support from this model,</li>
<li>use the offset and support (the usual pretraining) to train models
for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>2</mn></msub><annotation encoding="application/x-tex">y_2</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>3</mn></msub><annotation encoding="application/x-tex">y_3</annotation></semantics></math>.</li>
</ol>
<p>There is one small detail here: we must choose the primary outcome
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>1</mn></msub><annotation encoding="application/x-tex">y_1</annotation></semantics></math>.
This is an important choice because it will form the support and offset
for the other two outcomes. We recommend making this selection using
domain knowledge, but cross-validation (or a validation set) can of
course be used.</p>
<p>Here, we walk through an example with simulated data with three
outcomes
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mn>1</mn></msub><mo>,</mo><msub><mi>y</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">y_1, y_2</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>3</mn></msub><annotation encoding="application/x-tex">y_3</annotation></semantics></math>.
The three outcomes have overlapping support; the first 10 features are
predictive . Outcomes 2 and 3 additionally have 5 features unique to
each of them. We’ll define
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>1</mn></msub><annotation encoding="application/x-tex">y_1</annotation></semantics></math>
to be continuous,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>2</mn></msub><annotation encoding="application/x-tex">y_2</annotation></semantics></math>
to be binomial and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>3</mn></msub><annotation encoding="application/x-tex">y_3</annotation></semantics></math>
to be survival.</p>
<div class="sourceCode" id="cb86"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Define constants</span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">600</span>          <span class="co"># Total number of samples</span></span>
<span><span class="va">ntrain</span> <span class="op">=</span> <span class="fl">300</span>     <span class="co"># Number of training samples</span></span>
<span><span class="va">p</span> <span class="op">=</span> <span class="fl">50</span>           <span class="co"># Number of features</span></span>
<span></span>
<span><span class="co"># Define covariates     </span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">*</span><span class="va">p</span><span class="op">)</span>, <span class="va">n</span>, <span class="va">p</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># y1: continuous response</span></span>
<span><span class="va">beta1</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">.5</span>, <span class="fl">10</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">10</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">y1</span> <span class="op">=</span> <span class="va">x</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># y2: binomial response</span></span>
<span><span class="va">beta2</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">p</span>, min <span class="op">=</span> <span class="fl">0.5</span>, max <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">*</span> <span class="va">beta1</span>  <span class="co"># Shared with group 1</span></span>
<span><span class="va">beta2</span> <span class="op">=</span> <span class="va">beta2</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>, </span>
<span>                  <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="fl">5</span>, min <span class="op">=</span> <span class="fl">0</span>, max <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span>, </span>
<span>                  <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">15</span><span class="op">)</span><span class="op">)</span> <span class="co"># Individual</span></span>
<span><span class="va">y2</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html" class="external-link">rbinom</a></span><span class="op">(</span><span class="va">n</span>, <span class="fl">1</span>, prob <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="op">-</span><span class="va">x</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># y3: survival response</span></span>
<span><span class="va">beta3</span> <span class="op">=</span> <span class="va">beta1</span>  <span class="co"># Shared with group 1</span></span>
<span><span class="va">beta3</span> <span class="op">=</span> <span class="va">beta3</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>, </span>
<span>                  <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="fl">5</span>, min <span class="op">=</span> <span class="op">-</span><span class="fl">0.1</span>, max <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span>,</span>
<span>                  <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">15</span><span class="op">)</span><span class="op">)</span> <span class="co"># Individual</span></span>
<span><span class="va">y3.true</span> <span class="op">=</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">x</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta3</span><span class="op">)</span></span>
<span><span class="va">y3.cens</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span><span class="va">y3</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/survival/man/Surv.html" class="external-link">Surv</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">pmin</a></span><span class="op">(</span><span class="va">y3.true</span>, <span class="va">y3.cens</span><span class="op">)</span>, <span class="va">y3.true</span> <span class="op">&lt;=</span> <span class="va">y3.cens</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Split into train and test</span></span>
<span><span class="va">xtest</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span>, <span class="op">]</span></span>
<span><span class="va">y1test</span> <span class="op">=</span> <span class="va">y1</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">y2test</span> <span class="op">=</span> <span class="va">y2</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">y3test</span> <span class="op">=</span> <span class="va">y3</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span>, <span class="op">]</span></span>
<span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span>, <span class="op">]</span></span>
<span><span class="va">y1</span> <span class="op">=</span> <span class="va">y1</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">]</span></span>
<span><span class="va">y2</span> <span class="op">=</span> <span class="va">y2</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">]</span></span>
<span><span class="va">y3</span> <span class="op">=</span> <span class="va">y3</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span>, <span class="op">]</span></span>
<span></span>
<span><span class="co"># Define training folds</span></span>
<span><span class="va">nfolds</span> <span class="op">=</span> <span class="fl">10</span></span>
<span><span class="va">foldid</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">trunc</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">/</span><span class="va">nfolds</span><span class="op">)</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">]</span></span></code></pre></div>
<p>For the first step of pretraining, train a model for the primary
outcome
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>1</mn></msub><annotation encoding="application/x-tex">y_1</annotation></semantics></math>)
and record the offset and support – these will be used when training the
models for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>2</mn></msub><annotation encoding="application/x-tex">y_2</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>3</mn></msub><annotation encoding="application/x-tex">y_3</annotation></semantics></math>.</p>
<div class="sourceCode" id="cb87"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">y1_fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y1</span>, keep<span class="op">=</span><span class="cn">TRUE</span>, foldid <span class="op">=</span> <span class="va">foldid</span><span class="op">)</span></span>
<span></span>
<span><span class="va">train_offset</span> <span class="op">=</span> <span class="va">y1_fit</span><span class="op">$</span><span class="va">fit.preval</span><span class="op">[</span>, <span class="va">y1_fit</span><span class="op">$</span><span class="va">lambda</span> <span class="op">==</span> <span class="va">y1_fit</span><span class="op">$</span><span class="va">lambda.1se</span><span class="op">]</span></span>
<span><span class="va">support</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">y1_fit</span>, s <span class="op">=</span> <span class="va">y1_fit</span><span class="op">$</span><span class="va">lambda.1se</span><span class="op">)</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span> <span class="op">!=</span> <span class="fl">0</span><span class="op">)</span></span></code></pre></div>
<p>Now we have everything we need to train the models for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>2</mn></msub><annotation encoding="application/x-tex">y_2</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>3</mn></msub><annotation encoding="application/x-tex">y_3</annotation></semantics></math>.
In the following code, we loop over
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0</mn><mo>,</mo><mn>0.1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\alpha = 0, 0.1, \dots, 1</annotation></semantics></math>;
in each step, we (1) train models for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>2</mn></msub><annotation encoding="application/x-tex">y_2</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>3</mn></msub><annotation encoding="application/x-tex">y_3</annotation></semantics></math>
and (2) record the CV error from both models. The CV error will be used
to determine values of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
to use for the final models.</p>
<div class="sourceCode" id="cb88"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cv.error.y2</span> <span class="op">=</span> <span class="va">cv.error.y3</span> <span class="op">=</span> <span class="cn">NULL</span></span>
<span><span class="va">alphalist</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">11</span><span class="op">)</span></span>
<span></span>
<span><span class="kw">for</span><span class="op">(</span><span class="va">alpha</span> <span class="kw">in</span> <span class="va">alphalist</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">pf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="va">alpha</span>, <span class="va">p</span><span class="op">)</span></span>
<span>  <span class="va">pf</span><span class="op">[</span><span class="va">support</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1</span></span>
<span>  </span>
<span>  <span class="va">offset</span> <span class="op">=</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">alpha</span><span class="op">)</span> <span class="op">*</span> <span class="va">train_offset</span></span>
<span>    </span>
<span>  <span class="va">y2_fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y2</span>, </span>
<span>                     foldid <span class="op">=</span> <span class="va">foldid</span>,</span>
<span>                     offset <span class="op">=</span> <span class="va">offset</span>,</span>
<span>                     penalty.factor <span class="op">=</span> <span class="va">pf</span>,</span>
<span>                     family <span class="op">=</span> <span class="st">"binomial"</span>,</span>
<span>                     type.measure <span class="op">=</span> <span class="st">"auc"</span><span class="op">)</span></span>
<span>  <span class="va">cv.error.y2</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">cv.error.y2</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="va">y2_fit</span><span class="op">$</span><span class="va">cvm</span><span class="op">)</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="va">y3_fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y3</span>, </span>
<span>                     foldid <span class="op">=</span> <span class="va">foldid</span>,</span>
<span>                     offset <span class="op">=</span> <span class="va">offset</span>,</span>
<span>                     penalty.factor <span class="op">=</span> <span class="va">pf</span>,</span>
<span>                     family <span class="op">=</span> <span class="st">"cox"</span>,</span>
<span>                     type.measure <span class="op">=</span> <span class="st">"C"</span><span class="op">)</span></span>
<span>  <span class="va">cv.error.y3</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">cv.error.y3</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="va">y3_fit</span><span class="op">$</span><span class="va">cvm</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>Plotting our CV performance suggests the value of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
we should choose for each outcome:</p>
<div class="sourceCode" id="cb89"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html" class="external-link">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">alphalist</span>, <span class="va">cv.error.y2</span>, type <span class="op">=</span> <span class="st">"b"</span>,</span>
<span>     main <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/bquote.html" class="external-link">bquote</a></span><span class="op">(</span><span class="st">"Outcome 2: CV AUC vs "</span> <span class="op">~</span> <span class="va">alpha</span><span class="op">)</span>,</span>
<span>     xlab <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html" class="external-link">expression</a></span><span class="op">(</span><span class="va">alpha</span><span class="op">)</span>,</span>
<span>     ylab <span class="op">=</span> <span class="st">"CV AUC"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="va">alphalist</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html" class="external-link">which.max</a></span><span class="op">(</span><span class="va">cv.error.y2</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">alphalist</span>, <span class="va">cv.error.y3</span>, type <span class="op">=</span> <span class="st">"b"</span>,</span>
<span>     main <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/bquote.html" class="external-link">bquote</a></span><span class="op">(</span><span class="st">"Outcome 3: CV C index vs "</span> <span class="op">~</span> <span class="va">alpha</span><span class="op">)</span>,</span>
<span>     xlab <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html" class="external-link">expression</a></span><span class="op">(</span><span class="va">alpha</span><span class="op">)</span>,</span>
<span>     ylab <span class="op">=</span> <span class="st">"CV C index"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="va">alphalist</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html" class="external-link">which.max</a></span><span class="op">(</span><span class="va">cv.error.y3</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span></code></pre></div>
<p><img src="ptLasso_files/figure-html/unnamed-chunk-203-1.png" width="700"></p>
<p>Now that we have selected our values of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>,
we can fit the final models for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>2</mn></msub><annotation encoding="application/x-tex">y_2</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>3</mn></msub><annotation encoding="application/x-tex">y_3</annotation></semantics></math>:</p>
<div class="sourceCode" id="cb90"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">############################################################</span></span>
<span><span class="co"># Model for y2:</span></span>
<span><span class="co">############################################################</span></span>
<span><span class="va">best.alpha.y2</span> <span class="op">=</span> <span class="va">alphalist</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html" class="external-link">which.max</a></span><span class="op">(</span><span class="va">cv.error.y2</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">pf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="va">best.alpha.y2</span>, <span class="va">p</span><span class="op">)</span>; <span class="va">pf</span><span class="op">[</span><span class="va">support</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1</span></span>
<span></span>
<span><span class="va">y2_fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y2</span>, </span>
<span>                   foldid <span class="op">=</span> <span class="va">foldid</span>,</span>
<span>                   offset <span class="op">=</span> <span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">best.alpha.y2</span><span class="op">)</span> <span class="op">*</span> <span class="va">train_offset</span>,</span>
<span>                   penalty.factor <span class="op">=</span> <span class="va">pf</span>,</span>
<span>                   family <span class="op">=</span> <span class="st">"binomial"</span>,</span>
<span>                   type.measure <span class="op">=</span> <span class="st">"auc"</span><span class="op">)</span></span>
<span></span>
<span><span class="co">############################################################</span></span>
<span><span class="co"># Repeat for y3:</span></span>
<span><span class="co">############################################################</span></span>
<span><span class="va">best.alpha.y3</span> <span class="op">=</span> <span class="va">alphalist</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html" class="external-link">which.max</a></span><span class="op">(</span><span class="va">cv.error.y3</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">pf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="va">best.alpha.y3</span>, <span class="va">p</span><span class="op">)</span>; <span class="va">pf</span><span class="op">[</span><span class="va">support</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1</span></span>
<span></span>
<span><span class="va">y3_fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y3</span>, </span>
<span>                   foldid <span class="op">=</span> <span class="va">foldid</span>,</span>
<span>                   offset <span class="op">=</span> <span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">best.alpha.y3</span><span class="op">)</span> <span class="op">*</span> <span class="va">train_offset</span>,</span>
<span>                   penalty.factor <span class="op">=</span> <span class="va">pf</span>,</span>
<span>                   family <span class="op">=</span> <span class="st">"cox"</span>, </span>
<span>                   type.measure <span class="op">=</span> <span class="st">"C"</span><span class="op">)</span></span></code></pre></div>
<p>We will also train models for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>2</mn></msub><annotation encoding="application/x-tex">y_2</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>3</mn></msub><annotation encoding="application/x-tex">y_3</annotation></semantics></math><em>without</em> pretraining; this is a natural benchmark.</p>
<div class="sourceCode" id="cb91"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">y2_fit_no_pretrain</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y2</span>, foldid <span class="op">=</span> <span class="va">foldid</span>, </span>
<span>                               family <span class="op">=</span> <span class="st">"binomial"</span>, type.measure <span class="op">=</span> <span class="st">"auc"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">y3_fit_no_pretrain</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y3</span>, </span>
<span>                               foldid <span class="op">=</span> <span class="va">foldid</span>, </span>
<span>                               family <span class="op">=</span> <span class="st">"cox"</span>, type.measure <span class="op">=</span> <span class="st">"C"</span><span class="op">)</span></span></code></pre></div>
<p>All of our models have been trained. Let’s compare performance with
and without pretraining; we’ll start with the model for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>2</mn></msub><annotation encoding="application/x-tex">y_2</annotation></semantics></math>.</p>
<div class="sourceCode" id="cb92"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">testoffset</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">y1_fit</span>, <span class="va">xtest</span>, s <span class="op">=</span> <span class="st">"lambda.1se"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Model 2 AUC with pretraining:"</span>, </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="va">y2_fit</span>, <span class="va">xtest</span>, newy <span class="op">=</span> <span class="va">y2test</span>, </span>
<span>                        newoffset <span class="op">=</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">best.alpha.y2</span><span class="op">)</span> <span class="op">*</span> <span class="va">testoffset</span><span class="op">)</span><span class="op">$</span><span class="va">auc</span>, <span class="fl">2</span><span class="op">)</span>,</span>
<span>    fill<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; Model 2 AUC with pretraining: 0.76</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Model 2 AUC without pretraining:"</span>, </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="va">y2_fit_no_pretrain</span>, <span class="va">xtest</span>, newy <span class="op">=</span> <span class="va">y2test</span><span class="op">)</span><span class="op">$</span><span class="va">auc</span>, <span class="fl">2</span><span class="op">)</span></span>
<span>    <span class="op">)</span></span>
<span><span class="co">#&gt; Model 2 AUC without pretraining: 0.66</span></span></code></pre></div>
<p>And now, the models for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>3</mn></msub><annotation encoding="application/x-tex">y_3</annotation></semantics></math>:</p>
<div class="sourceCode" id="cb93"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Model 3 C-index with pretraining:"</span>, </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="va">y3_fit</span>, <span class="va">xtest</span>, newy <span class="op">=</span> <span class="va">y3test</span>, </span>
<span>                        newoffset <span class="op">=</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">best.alpha.y3</span><span class="op">)</span> <span class="op">*</span> <span class="va">testoffset</span><span class="op">)</span><span class="op">$</span><span class="va">C</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Model 3 C-index with pretraining: 0.8</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Model 3 C-index without pretraining:"</span>, </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="va">y3_fit_no_pretrain</span>, <span class="va">xtest</span>, newy <span class="op">=</span> <span class="va">y3test</span><span class="op">)</span><span class="op">$</span><span class="va">C</span>, <span class="fl">2</span><span class="op">)</span></span>
<span>    <span class="op">)</span></span>
<span><span class="co">#&gt; Model 3 C-index without pretraining: 0.78</span></span></code></pre></div>
<p>For both
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>2</mn></msub><annotation encoding="application/x-tex">y_2</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>3</mn></msub><annotation encoding="application/x-tex">y_3</annotation></semantics></math>,
we saw a performance improvement using pretraining. We didn’t
technically need to train the individual (non-pretrained) models for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>2</mn></msub><annotation encoding="application/x-tex">y_2</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>3</mn></msub><annotation encoding="application/x-tex">y_3</annotation></semantics></math>:
during our CV loop to choose
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>,
we saw the cross validation performance for the individual models (the
special case when
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\alpha = 1</annotation></semantics></math>),
and CV recommended a smaller value of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
for both outcomes.</p>
<p>Note that, in this example, we trained a model using
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>1</mn></msub><annotation encoding="application/x-tex">y_1</annotation></semantics></math>,
and then used this model to form the offset and support for the models
for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>2</mn></msub><annotation encoding="application/x-tex">y_2</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>3</mn></msub><annotation encoding="application/x-tex">y_3</annotation></semantics></math>
in parallel. But using pretraining for multi-response data is
<em>flexible</em>. Pretraining is simply a method to pass information
from one model to another, and we are free to choose how information
flows. For example, we chose to pass information from model 1
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>1</mn></msub><annotation encoding="application/x-tex">y_1</annotation></semantics></math>)
to model 2
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>2</mn></msub><annotation encoding="application/x-tex">y_2</annotation></semantics></math>)
and to model 3
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>3</mn></msub><annotation encoding="application/x-tex">y_3</annotation></semantics></math>).
But, we could have instead <em>chained</em> our models to pass
information from model 1 to model 2, and then from model 2 to model 3 in
the following way:</p>
<ol style="list-style-type: decimal">
<li>fit a model for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>1</mn></msub><annotation encoding="application/x-tex">y_1</annotation></semantics></math>,</li>
<li>extract the offset and support from this model,</li>
<li>use the offset and support (the usual pretraining) to train a model
for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>2</mn></msub><annotation encoding="application/x-tex">y_2</annotation></semantics></math>,</li>
<li>extract the offset and support from this second model, and</li>
<li>use them to train a model for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>3</mn></msub><annotation encoding="application/x-tex">y_3</annotation></semantics></math>.</li>
</ol>
<p>In this framework, the model for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>3</mn></msub><annotation encoding="application/x-tex">y_3</annotation></semantics></math>
depends implicitly on both the models for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>1</mn></msub><annotation encoding="application/x-tex">y_1</annotation></semantics></math><em>and</em>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>2</mn></msub><annotation encoding="application/x-tex">y_2</annotation></semantics></math>,
as the offset and support for the model for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>2</mn></msub><annotation encoding="application/x-tex">y_2</annotation></semantics></math>
were informed by the model for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>1</mn></msub><annotation encoding="application/x-tex">y_1</annotation></semantics></math>.
Choosing how information should be passed between outcomes is context
specific and we recommend relying on domain knowledge for selecting an
approach (though many options may be tried and compared with
cross-validation or a validation set).</p>
</div>
<div class="section level3">
<h3 id="conditional-average-treatment-effect-estimation">Conditional average treatment effect estimation<a class="anchor" aria-label="anchor" href="#conditional-average-treatment-effect-estimation"></a>
</h3>
<div class="sourceCode" id="cb94"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va"><a href="https://glmnet.stanford.edu" class="external-link">glmnet</a></span><span class="op">)</span></span></code></pre></div>
<div class="section level4">
<h4 id="background-cate-estimation-and-pretraining">Background: CATE estimation and pretraining<a class="anchor" aria-label="anchor" href="#background-cate-estimation-and-pretraining"></a>
</h4>
<p>In causal inference, we are often interested in predicting the
treatment effect for individual observations; this is called the
conditional average treatment effect (CATE). For example, before
prescribing a drug to a patient, we want to know whether the drug is
likely to work well <em>for that patient</em> - not just whether it
works well on average. One tool to model the CATE is the R-learner
(<span class="citation">Nie and Wager (2021)</span>), which minimizes
the R loss:</p>
<p><span class="math display">$$
\hat{L}_n\{\tau(\cdot)\}=\arg \min_\tau \frac{1}{n}\sum\Bigl[ (y_i-
m^*(x_i)) - (W_i-e^*(x_i))\tau(x_i) \Bigr]^2.
$$</span> Here,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>i</mi></msub><annotation encoding="application/x-tex">x_i</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mi>i</mi></msub><annotation encoding="application/x-tex">y_i</annotation></semantics></math>
are the covariates and outcome for observation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>e</mi><mo>*</mo></msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">e^*(x_i)</annotation></semantics></math>
is the treatment propensity and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>W</mi><mi>i</mi></msub><annotation encoding="application/x-tex">W_i</annotation></semantics></math>
the treatment assignment, and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>m</mi><mo>*</mo></msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">m^*(x_i)</annotation></semantics></math>
is the conditional mean outcome
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mrow><mo stretchy="true" form="prefix">[</mo><msub><mi>y</mi><mi>i</mi></msub><mo>∣</mo><mi>x</mi><mo>=</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">E[y_i \mid x = x_i]</annotation></semantics></math>).
Then,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>τ</mi><mo accent="true">̂</mo></mover><annotation encoding="application/x-tex">\hat\tau</annotation></semantics></math>
is the estimate of the heterogeneous treatment effect function.</p>
<p>This is fitted in stages: first, the R-learner fits
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>m</mi><mo>*</mo></msup><annotation encoding="application/x-tex">m^*</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>e</mi><mo>*</mo></msup><annotation encoding="application/x-tex">e^*</annotation></semantics></math>
to get
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mover><mi>m</mi><mo accent="true">̂</mo></mover><mo>*</mo></msup><annotation encoding="application/x-tex">\hat{m}^*</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mover><mi>e</mi><mo accent="true">̂</mo></mover><mo>*</mo></msup><annotation encoding="application/x-tex">\hat{e}^*</annotation></semantics></math>;
then plugs in
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover><mi>m</mi><mo accent="true">̂</mo></mover><mo>*</mo></msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\hat{m}^*(x_i)</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover><mi>e</mi><mo accent="true">̂</mo></mover><mo>*</mo></msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\hat{e}^*(x_i)</annotation></semantics></math>
to fit
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>τ</mi><annotation encoding="application/x-tex">\tau</annotation></semantics></math>.
A minor detail is that cross-fitting (or prevalidation) is used in the
first stage so that the plugin value for
e.g. <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover><mi>m</mi><mo accent="true">̂</mo></mover><mo>*</mo></msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\hat{m}^*(x_i)</annotation></semantics></math>
comes from a model trained without using
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>i</mi></msub><annotation encoding="application/x-tex">x_i</annotation></semantics></math>.</p>
<p>When
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>τ</mi><annotation encoding="application/x-tex">\tau</annotation></semantics></math>
is a linear function, then the second stage of fitting is
straightforward. The values
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover><mi>m</mi><mo accent="true">̂</mo></mover><mo>*</mo></msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\hat{m}^*(x_i)</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover><mi>e</mi><mo accent="true">̂</mo></mover><mo>*</mo></msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\hat{e}^*(x_i)</annotation></semantics></math>
are known, and we can use linear regression to model
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msup><mover><mi>m</mi><mo accent="true">̂</mo></mover><mo>*</mo></msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">y_i - \hat{m}^*(x_i)</annotation></semantics></math>
as a function of the weighted feature vector
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>W</mi><mi>i</mi></msub><mo>−</mo><msup><mover><mi>e</mi><mo accent="true">̂</mo></mover><mo>*</mo></msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">(W_i-\hat{e}^*(x_i)) x_i</annotation></semantics></math>.
This is what we will do in the following example.</p>
<p>How can pretraining be useful here? Well, we are separately fitting
models for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>m</mi><mo>*</mo></msup><annotation encoding="application/x-tex">m^*</annotation></semantics></math>
(the conditional mean) and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>τ</mi><annotation encoding="application/x-tex">\tau</annotation></semantics></math>
(the heterogeneous treatment effect), and these two functions are likely
to share support: it is sensible to assume that the features that
modulate the mean treatment effect also modulate the heterogeneous
treatment effect. We can use pretraining by (1) training a model for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>m</mi><mo>*</mo></msup><annotation encoding="application/x-tex">m^*</annotation></semantics></math>
and (2) using the support from this model to guide the fitting of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>τ</mi><annotation encoding="application/x-tex">\tau</annotation></semantics></math>.
Note that the offset is not used in this case;
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>m</mi><mo>*</mo></msup><annotation encoding="application/x-tex">m^*</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>τ</mi><annotation encoding="application/x-tex">\tau</annotation></semantics></math>
are designed to predict different outcomes.</p>
</div>
<div class="section level4">
<h4 id="a-simulated-example">A simulated example<a class="anchor" aria-label="anchor" href="#a-simulated-example"></a>
</h4>
<p>Here is an example. We will simplify the problem by assuming
treatment has been randomized – the true
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>e</mi><mo>*</mo></msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">e^*(x_i) = 0.5</annotation></semantics></math>
for all
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>.</p>
<div class="sourceCode" id="cb95"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">600</span>; <span class="va">ntrain</span> <span class="op">=</span> <span class="fl">300</span></span>
<span><span class="va">p</span> <span class="op">=</span> <span class="fl">20</span></span>
<span>     </span>
<span><span class="va">x</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">*</span><span class="va">p</span><span class="op">)</span>, <span class="va">n</span>, <span class="va">p</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Treatment assignment</span></span>
<span><span class="va">w</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html" class="external-link">rbinom</a></span><span class="op">(</span><span class="va">n</span>, <span class="fl">1</span>, <span class="fl">0.5</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># m^*</span></span>
<span><span class="va">m.coefs</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">10</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">10</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">m</span> <span class="op">=</span> <span class="va">x</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">m.coefs</span></span>
<span></span>
<span><span class="co"># tau</span></span>
<span><span class="va">tau.coefs</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">p</span>, <span class="fl">0.5</span>, <span class="fl">1</span><span class="op">)</span><span class="op">*</span><span class="va">m.coefs</span> </span>
<span><span class="va">tau</span> <span class="op">=</span> <span class="fl">1.5</span><span class="op">*</span><span class="va">m</span> <span class="op">+</span> <span class="va">x</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span><span class="va">tau.coefs</span></span>
<span></span>
<span><span class="va">mu</span> <span class="op">=</span> <span class="va">m</span> <span class="op">+</span> <span class="va">w</span> <span class="op">*</span> <span class="va">tau</span></span>
<span><span class="va">y</span>  <span class="op">=</span> <span class="va">mu</span> <span class="op">+</span> <span class="fl">10</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Signal to noise ratio:"</span>, <span class="fu"><a href="https://rdrr.io/r/stats/cor.html" class="external-link">var</a></span><span class="op">(</span><span class="va">mu</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html" class="external-link">var</a></span><span class="op">(</span><span class="va">y</span><span class="op">-</span><span class="va">mu</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Signal to noise ratio: 2.301315</span></span>
<span></span>
<span><span class="co"># Split into train/test</span></span>
<span><span class="va">xtest</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span>, <span class="op">]</span></span>
<span><span class="va">tautest</span> <span class="op">=</span> <span class="va">tau</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span><span class="op">]</span> </span>
<span><span class="va">wtest</span> <span class="op">=</span> <span class="va">w</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span>, <span class="op">]</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">]</span> </span>
<span><span class="va">w</span> <span class="op">=</span> <span class="va">w</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># Define training folds</span></span>
<span><span class="va">nfolds</span> <span class="op">=</span> <span class="fl">10</span></span>
<span><span class="va">foldid</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">trunc</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">/</span><span class="va">nfolds</span><span class="op">)</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">]</span></span></code></pre></div>
<p>We begin model fitting, starting with our estimate of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>e</mi><mo>*</mo></msup><annotation encoding="application/x-tex">e^*</annotation></semantics></math>
(the probability of receiving the treatment). To fit
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>τ</mi><annotation encoding="application/x-tex">\tau</annotation></semantics></math>,
we will also need to record the cross-fitted
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover><mi>e</mi><mo accent="true">̂</mo></mover><mo>*</mo></msup><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\hat{e}^*(x)</annotation></semantics></math>.</p>
<div class="sourceCode" id="cb96"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">e_fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">w</span>, foldid <span class="op">=</span> <span class="va">foldid</span>,</span>
<span>                  family<span class="op">=</span><span class="st">"binomial"</span>, type.measure<span class="op">=</span><span class="st">"deviance"</span>,</span>
<span>                  keep <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="va">e_hat</span> <span class="op">=</span> <span class="va">e_fit</span><span class="op">$</span><span class="va">fit.preval</span><span class="op">[</span>, <span class="va">e_fit</span><span class="op">$</span><span class="va">lambda</span> <span class="op">==</span> <span class="va">e_fit</span><span class="op">$</span><span class="va">lambda.1se</span><span class="op">]</span></span>
<span><span class="va">e_hat</span> <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="op">-</span><span class="va">e_hat</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>Now, stage 1 of pretraining: fit a model for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>m</mi><mo>*</mo></msup><annotation encoding="application/x-tex">m^*</annotation></semantics></math>
and record the support. As before, we also record the cross-fitted
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover><mi>m</mi><mo accent="true">̂</mo></mover><mo>*</mo></msup><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\hat{m}^*(x)</annotation></semantics></math>.</p>
<div class="sourceCode" id="cb97"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">m_fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, foldid <span class="op">=</span> <span class="va">foldid</span>, keep <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="va">m_hat</span> <span class="op">=</span> <span class="va">m_fit</span><span class="op">$</span><span class="va">fit.preval</span><span class="op">[</span>, <span class="va">m_fit</span><span class="op">$</span><span class="va">lambda</span> <span class="op">==</span> <span class="va">m_fit</span><span class="op">$</span><span class="va">lambda.1se</span><span class="op">]</span></span>
<span></span>
<span><span class="va">bhat</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">m_fit</span>, s <span class="op">=</span> <span class="va">m_fit</span><span class="op">$</span><span class="va">lambda.1se</span><span class="op">)</span></span>
<span><span class="va">support</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="va">bhat</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span> <span class="op">!=</span> <span class="fl">0</span><span class="op">)</span></span></code></pre></div>
<p>To fit
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>τ</mi><annotation encoding="application/x-tex">\tau</annotation></semantics></math>,
we will regress
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>y</mi><mo accent="true">̃</mo></mover><mo>=</mo><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msup><mover><mi>m</mi><mo accent="true">̂</mo></mover><mo>*</mo></msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\tilde{y} = y_i - \hat{m}^*(x_i)</annotation></semantics></math>
on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>x</mi><mo accent="true">̃</mo></mover><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>w</mi><mi>i</mi></msub><mo>−</mo><msup><mover><mi>e</mi><mo accent="true">̂</mo></mover><mo>*</mo></msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\tilde{x} = (w_i - \hat{e}^*(x_i)) x_i</annotation></semantics></math>;
we’ll define them here:</p>
<div class="sourceCode" id="cb98"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">y_tilde</span> <span class="op">=</span> <span class="va">y</span> <span class="op">-</span> <span class="va">m_hat</span></span>
<span><span class="va">x_tilde</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="va">w</span> <span class="op">-</span> <span class="va">e_hat</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">x</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>And now, pretraining for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>τ</mi><annotation encoding="application/x-tex">\tau</annotation></semantics></math>.
Loop over
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0</mn><mo>,</mo><mn>0.1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\alpha = 0, 0.1, \dots, 1</annotation></semantics></math>;
for each
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>,
fit a model for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>τ</mi><annotation encoding="application/x-tex">\tau</annotation></semantics></math>
using the penalty factor defined by the support of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mover><mi>m</mi><mo accent="true">̂</mo></mover><annotation encoding="application/x-tex">\hat{m}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>.
We’ll keep track of our CV MSE at each step so that we can choose the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
that minimizes the MSE.</p>
<div class="sourceCode" id="cb99"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cv.error</span> <span class="op">=</span> <span class="cn">NULL</span></span>
<span><span class="va">alphalist</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">11</span><span class="op">)</span></span>
<span></span>
<span><span class="kw">for</span><span class="op">(</span><span class="va">alpha</span> <span class="kw">in</span> <span class="va">alphalist</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">pf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="va">alpha</span>, <span class="va">p</span><span class="op">)</span></span>
<span>  <span class="va">pf</span><span class="op">[</span><span class="va">support</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1</span></span>
<span>  <span class="va">pf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">pf</span><span class="op">)</span> <span class="co"># Don't penalize the intercept</span></span>
<span>  </span>
<span>  <span class="va">tau_fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x_tilde</span>, <span class="va">y_tilde</span>, </span>
<span>                      foldid <span class="op">=</span> <span class="va">foldid</span>,</span>
<span>                      penalty.factor <span class="op">=</span> <span class="va">pf</span>,</span>
<span>                      intercept <span class="op">=</span> <span class="cn">FALSE</span>, <span class="co"># already include in x_tilde</span></span>
<span>                      standardize <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span>  <span class="va">cv.error</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">cv.error</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">min</a></span><span class="op">(</span><span class="va">tau_fit</span><span class="op">$</span><span class="va">cvm</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">alphalist</span>, <span class="va">cv.error</span>, type <span class="op">=</span> <span class="st">"b"</span>,</span>
<span>     xlab <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html" class="external-link">expression</a></span><span class="op">(</span><span class="va">alpha</span><span class="op">)</span>, </span>
<span>     ylab <span class="op">=</span> <span class="st">"CV MSE"</span>, </span>
<span>     main <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/bquote.html" class="external-link">bquote</a></span><span class="op">(</span><span class="st">"CV mean squared error as a function of "</span> <span class="op">~</span> <span class="va">alpha</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="va">alphalist</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html" class="external-link">which.min</a></span><span class="op">(</span><span class="va">cv.error</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span></code></pre></div>
<p><img src="ptLasso_files/figure-html/unnamed-chunk-226-1.png" width="700"></p>
<p>In the plot above, the value at
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\alpha = 1</annotation></semantics></math>
corresponds to the usual R learner, which makes no assumption about a
shared support between
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>τ</mi><annotation encoding="application/x-tex">\tau</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>m</mi><mo>*</mo></msup><annotation encoding="application/x-tex">m^*</annotation></semantics></math>.
Based on the plot, we choose
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.2</mn></mrow><annotation encoding="application/x-tex">\alpha = 0.2</annotation></semantics></math>
as our best performing model:</p>
<div class="sourceCode" id="cb100"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">best.alpha</span> <span class="op">=</span> <span class="va">alphalist</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html" class="external-link">which.min</a></span><span class="op">(</span><span class="va">cv.error</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Chosen alpha:"</span>, <span class="va">best.alpha</span><span class="op">)</span></span>
<span><span class="co">#&gt; Chosen alpha: 0.2</span></span>
<span></span>
<span><span class="va">pf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="va">best.alpha</span>, <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">pf</span><span class="op">[</span><span class="va">support</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1</span></span>
<span><span class="va">pf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">pf</span><span class="op">)</span></span>
<span><span class="va">tau_fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x_tilde</span>, <span class="va">y_tilde</span>, foldid <span class="op">=</span> <span class="va">foldid</span>,</span>
<span>                    penalty.factor <span class="op">=</span> <span class="va">pf</span>,</span>
<span>                    intercept <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>                    standardize <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<p>To concretely compare the pretrained R-learner with the usual
R-learner, we’ll train the usual R-learner here:</p>
<div class="sourceCode" id="cb101"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tau_rlearner</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x_tilde</span>, <span class="va">y_tilde</span>, foldid <span class="op">=</span> <span class="va">foldid</span>, </span>
<span>                         penalty.factor <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                         intercept <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>                         standardize <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<p>As anticipated, pretraining improves the prediction squared error
relative to the R learner – this is how we designed our simulation:</p>
<div class="sourceCode" id="cb102"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">rlearner_preds</span>   <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">tau_rlearner</span>, <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">xtest</span><span class="op">)</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"R-learner PSE: "</span>, </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">rlearner_preds</span> <span class="op">-</span> <span class="va">tautest</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; R-learner PSE:  45.85</span></span>
<span></span>
<span><span class="va">pretrained_preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">tau_fit</span>, <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">xtest</span><span class="op">)</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Pretrained R-learner PSE: "</span>, </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">pretrained_preds</span> <span class="op">-</span> <span class="va">tautest</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Pretrained R-learner PSE:  37.63</span></span></code></pre></div>
</div>
<div class="section level4">
<h4 id="what-if-the-pretraining-assumption-is-wrong">What if the pretraining assumption is wrong?<a class="anchor" aria-label="anchor" href="#what-if-the-pretraining-assumption-is-wrong"></a>
</h4>
<p>Here, we repeat everything from above, only now there is no overlap
in the support of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>m</mi><mo>*</mo></msup><annotation encoding="application/x-tex">m^*</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>τ</mi><annotation encoding="application/x-tex">\tau</annotation></semantics></math>.</p>
<div class="sourceCode" id="cb103"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">######################################################</span></span>
<span><span class="co"># Simulate data</span></span>
<span><span class="co">######################################################</span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">*</span><span class="va">p</span><span class="op">)</span>, <span class="va">n</span>, <span class="va">p</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Treatment assignment</span></span>
<span><span class="va">w</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html" class="external-link">rbinom</a></span><span class="op">(</span><span class="va">n</span>, <span class="fl">1</span>, <span class="fl">0.5</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># m^*</span></span>
<span><span class="va">m.coefs</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">10</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">10</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">m</span> <span class="op">=</span> <span class="va">x</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">m.coefs</span></span>
<span></span>
<span><span class="co"># tau</span></span>
<span><span class="co"># Note these coefficients have no overlap with m.coefs!</span></span>
<span><span class="va">tau.coefs</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">10</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">20</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">tau</span> <span class="op">=</span> <span class="va">x</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span><span class="va">tau.coefs</span></span>
<span></span>
<span><span class="va">mu</span> <span class="op">=</span> <span class="va">m</span> <span class="op">+</span> <span class="va">w</span> <span class="op">*</span> <span class="va">tau</span></span>
<span><span class="va">y</span>  <span class="op">=</span> <span class="va">mu</span> <span class="op">+</span> <span class="fl">10</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Signal to noise ratio:"</span>, <span class="fu"><a href="https://rdrr.io/r/stats/cor.html" class="external-link">var</a></span><span class="op">(</span><span class="va">mu</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html" class="external-link">var</a></span><span class="op">(</span><span class="va">y</span><span class="op">-</span><span class="va">mu</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Signal to noise ratio: 0.6938152</span></span>
<span></span>
<span><span class="co"># Split into train/test</span></span>
<span><span class="va">xtest</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span>, <span class="op">]</span></span>
<span><span class="va">tautest</span> <span class="op">=</span> <span class="va">tau</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span><span class="op">]</span> </span>
<span><span class="va">wtest</span> <span class="op">=</span> <span class="va">w</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span>, <span class="op">]</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">]</span> </span>
<span><span class="va">w</span> <span class="op">=</span> <span class="va">w</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">]</span></span>
<span></span>
<span><span class="co">######################################################</span></span>
<span><span class="co"># Model fitting: e^*</span></span>
<span><span class="co">######################################################</span></span>
<span><span class="va">e_fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">w</span>, foldid <span class="op">=</span> <span class="va">foldid</span>,</span>
<span>                  family<span class="op">=</span><span class="st">"binomial"</span>, type.measure<span class="op">=</span><span class="st">"deviance"</span>,</span>
<span>                  keep <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">e_hat</span> <span class="op">=</span> <span class="va">e_fit</span><span class="op">$</span><span class="va">fit.preval</span><span class="op">[</span>, <span class="va">e_fit</span><span class="op">$</span><span class="va">lambda</span> <span class="op">==</span> <span class="va">e_fit</span><span class="op">$</span><span class="va">lambda.1se</span><span class="op">]</span></span>
<span><span class="va">e_hat</span> <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="op">-</span><span class="va">e_hat</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co">######################################################</span></span>
<span><span class="co"># Model fitting: m^*</span></span>
<span><span class="co">######################################################</span></span>
<span><span class="va">m_fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, foldid <span class="op">=</span> <span class="va">foldid</span>, keep <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="va">m_hat</span> <span class="op">=</span> <span class="va">m_fit</span><span class="op">$</span><span class="va">fit.preval</span><span class="op">[</span>, <span class="va">m_fit</span><span class="op">$</span><span class="va">lambda</span> <span class="op">==</span> <span class="va">m_fit</span><span class="op">$</span><span class="va">lambda.1se</span><span class="op">]</span></span>
<span></span>
<span><span class="va">bhat</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">m_fit</span>, s <span class="op">=</span> <span class="va">m_fit</span><span class="op">$</span><span class="va">lambda.1se</span><span class="op">)</span></span>
<span><span class="va">support</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="va">bhat</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span> <span class="op">!=</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="co">######################################################</span></span>
<span><span class="co"># Pretraining: tau</span></span>
<span><span class="co">######################################################</span></span>
<span><span class="va">y_tilde</span> <span class="op">=</span> <span class="va">y</span> <span class="op">-</span> <span class="va">m_hat</span></span>
<span><span class="va">x_tilde</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="va">w</span> <span class="op">-</span> <span class="va">e_hat</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">x</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">cv.error</span> <span class="op">=</span> <span class="cn">NULL</span></span>
<span><span class="va">alphalist</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">11</span><span class="op">)</span></span>
<span></span>
<span><span class="kw">for</span><span class="op">(</span><span class="va">alpha</span> <span class="kw">in</span> <span class="va">alphalist</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">pf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="va">alpha</span>, <span class="va">p</span><span class="op">)</span></span>
<span>  <span class="va">pf</span><span class="op">[</span><span class="va">support</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1</span></span>
<span>  <span class="va">pf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">pf</span><span class="op">)</span> <span class="co"># Don't penalize the intercept</span></span>
<span>  </span>
<span>  <span class="va">tau_fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x_tilde</span>, <span class="va">y_tilde</span>, </span>
<span>                      foldid <span class="op">=</span> <span class="va">foldid</span>,</span>
<span>                      penalty.factor <span class="op">=</span> <span class="va">pf</span>,</span>
<span>                      intercept <span class="op">=</span> <span class="cn">FALSE</span>, <span class="co"># already include in x_tilde</span></span>
<span>                      standardize <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span>  <span class="va">cv.error</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">cv.error</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">min</a></span><span class="op">(</span><span class="va">tau_fit</span><span class="op">$</span><span class="va">cvm</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Our final model for tau:</span></span>
<span><span class="va">best.alpha</span> <span class="op">=</span> <span class="va">alphalist</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html" class="external-link">which.min</a></span><span class="op">(</span><span class="va">cv.error</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Chosen alpha:"</span>, <span class="va">best.alpha</span><span class="op">)</span></span>
<span><span class="co">#&gt; Chosen alpha: 1</span></span>
<span></span>
<span><span class="va">pf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="va">best.alpha</span>, <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">pf</span><span class="op">[</span><span class="va">support</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1</span></span>
<span><span class="va">pf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">pf</span><span class="op">)</span></span>
<span><span class="va">tau_fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x_tilde</span>, <span class="va">y_tilde</span>, foldid <span class="op">=</span> <span class="va">foldid</span>,</span>
<span>                    penalty.factor <span class="op">=</span> <span class="va">pf</span>,</span>
<span>                    intercept <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>                    standardize <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span></span>
<span><span class="co">######################################################</span></span>
<span><span class="co"># Fit the usual R-learner:</span></span>
<span><span class="co">######################################################</span></span>
<span><span class="va">tau_rlearner</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x_tilde</span>, <span class="va">y_tilde</span>, foldid <span class="op">=</span> <span class="va">foldid</span>, </span>
<span>                         penalty.factor <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                         intercept <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>                         standardize <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span></span>
<span><span class="co">######################################################</span></span>
<span><span class="co"># Measure performance:</span></span>
<span><span class="co">######################################################</span></span>
<span><span class="va">rlearner_preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">tau_rlearner</span>, <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">xtest</span><span class="op">)</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"R-learner prediction squared error: "</span>, </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">rlearner_preds</span> <span class="op">-</span> <span class="va">tautest</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; R-learner prediction squared error:  31.11</span></span>
<span></span>
<span><span class="va">pretrained_preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">tau_fit</span>, <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">xtest</span><span class="op">)</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Pretrained R-learner prediction squared error: "</span>, </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">pretrained_preds</span> <span class="op">-</span> <span class="va">tautest</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Pretrained R-learner prediction squared error:  31.11</span></span></code></pre></div>
<p>Pretraining has not hurt our performance, even though the support of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>m</mi><mo>*</mo></msup><annotation encoding="application/x-tex">m^*</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>τ</mi><annotation encoding="application/x-tex">\tau</annotation></semantics></math>
are not shared. Why? Recall that we defined
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><msup><mi>m</mi><mo>*</mo></msup><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mi>W</mi><mo>*</mo><mi>τ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>x</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">y =  m^*(x) + W * \tau(x) + \epsilon</annotation></semantics></math>,
so the relationship between
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>
is a function of the supports of both
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>m</mi><mo>*</mo></msup><annotation encoding="application/x-tex">m^*</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>τ</mi><annotation encoding="application/x-tex">\tau</annotation></semantics></math>.
In the first stage of pretraining, we fitted
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>m</mi><mo>*</mo></msup><annotation encoding="application/x-tex">m^*</annotation></semantics></math>
using <code>y ~ x</code> – so the support of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>m</mi><mo>*</mo></msup><annotation encoding="application/x-tex">m^*</annotation></semantics></math><em>should</em> include the support of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>τ</mi><annotation encoding="application/x-tex">\tau</annotation></semantics></math>.
As a result, using pretraining with the R-learner should not harm
predictive performance.</p>
</div>
</div>
<div class="section level3">
<h3 id="using-non-linear-bases">Using non-linear bases<a class="anchor" aria-label="anchor" href="#using-non-linear-bases"></a>
</h3>
<div class="sourceCode" id="cb104"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va"><a href="https://glmnet.stanford.edu" class="external-link">glmnet</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va"><a href="https://erincr.github.io/ptLasso/">ptLasso</a></span><span class="op">)</span></span></code></pre></div>
<p>Suppose we have a dataset with features
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
and response
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>,
where the relationship between
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>
is a nonlinear function of the columns of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>.
Can we still use the lasso? Yes! We can <em>pretrain</em> our linear
model using <code>xgboost</code> to obtain basis functions (features).
Let’s walk through an example.</p>
<div class="section level4">
<h4 id="example-1-xgboost-pretraining">Example 1: xgboost pretraining<a class="anchor" aria-label="anchor" href="#example-1-xgboost-pretraining"></a>
</h4>
<div class="sourceCode" id="cb105"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va"><a href="https://github.com/dmlc/xgboost" class="external-link">xgboost</a></span><span class="op">)</span></span>
<span><span class="co">#&gt; Loading required package: xgboost</span></span></code></pre></div>
<p>We start by simulating data
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>1800</mn></mrow><annotation encoding="application/x-tex">n = 1800</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>=</mo><mn>1000</mn></mrow><annotation encoding="application/x-tex">p = 1000</annotation></semantics></math>)
with a continuous response. Our coefficients
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>β</mi><annotation encoding="application/x-tex">\beta</annotation></semantics></math>
are sparse; the first 200 entries will be drawn from a standard
univariate normal, and the remainder are
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>0</mn><annotation encoding="application/x-tex">0</annotation></semantics></math>.
We define
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>
as
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><mn>1</mn><mrow><mo stretchy="true" form="prefix">(</mo><mi>X</mi><mo>&gt;</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow><mi>β</mi><mo>+</mo><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">y = 1(X &gt; 0) \beta + \epsilon</annotation></semantics></math>,
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ϵ</mi><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math>
is noise; we hope that <code>xgboost</code> will learn the splits
corresponding to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">X &gt; 0</annotation></semantics></math>.</p>
<div class="sourceCode" id="cb106"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">1800</span>; <span class="va">p</span> <span class="op">=</span> <span class="fl">1000</span>; <span class="va">noise</span> <span class="op">=</span> <span class="fl">5</span>;</span>
<span></span>
<span><span class="va">x</span>     <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, nrow<span class="op">=</span><span class="va">n</span>, ncol<span class="op">=</span><span class="va">p</span><span class="op">)</span></span>
<span><span class="va">xtest</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, nrow<span class="op">=</span><span class="va">n</span>, ncol<span class="op">=</span><span class="va">p</span><span class="op">)</span></span>
<span></span>
<span><span class="va">x.model</span>     <span class="op">=</span> <span class="fl">1</span><span class="op">*</span><span class="op">(</span><span class="va">x</span> <span class="op">&gt;</span> <span class="fl">0</span><span class="op">)</span>     </span>
<span><span class="va">xtest.model</span> <span class="op">=</span> <span class="fl">1</span><span class="op">*</span><span class="op">(</span><span class="va">xtest</span> <span class="op">&gt;</span> <span class="fl">0</span><span class="op">)</span> </span>
<span></span>
<span><span class="va">beta</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">200</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">200</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">y</span>     <span class="op">=</span> <span class="va">x.model</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta</span> <span class="op">+</span> <span class="va">noise</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span><span class="va">ytest</span> <span class="op">=</span> <span class="va">xtest.model</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta</span> <span class="op">+</span> <span class="va">noise</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span></span>
<span><span class="va">train.folds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span>, <span class="va">n</span><span class="op">/</span><span class="fl">10</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>Now, we run <code>xgboost</code> to get our basis functions:</p>
<div class="sourceCode" id="cb107"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">xgbfit</span>      <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/xgboost/man/xgb.train.html" class="external-link">xgboost</a></span><span class="op">(</span>data<span class="op">=</span><span class="va">x</span>, label<span class="op">=</span><span class="va">y</span>, nrounds<span class="op">=</span><span class="fl">200</span>, max_depth<span class="op">=</span><span class="fl">1</span>, verbose<span class="op">=</span><span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="va">x.boost</span>     <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">xgbfit</span>, <span class="va">x</span>, predleaf <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span></span>
<span><span class="va">xtest.boost</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">xgbfit</span>, <span class="va">xtest</span>, predleaf <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span></span></code></pre></div>
<p>And we are ready for model fitting with <code>cv.glmnet</code>. Our
two baselines are (1) a linear model that does not pretrain with
<code>xgboost</code>, and (2) <code>xgboost</code>. We find that
<code>glmnet</code> together with <code>xgboost</code> outperforms
<code>glmnet</code> alone and <code>xgboost</code> alone.</p>
<div class="sourceCode" id="cb108"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cvfit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x.boost</span>, <span class="va">y</span>, type.measure <span class="op">=</span> <span class="st">"mse"</span>, foldid <span class="op">=</span> <span class="va">train.folds</span><span class="op">)</span></span>
<span><span class="va">cvfit.noboost</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, type.measure <span class="op">=</span> <span class="st">"mse"</span>, foldid <span class="op">=</span> <span class="va">train.folds</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Lasso with xgboost pretraining PSE: "</span>, </span>
<span>    <span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="va">cvfit</span>, newx <span class="op">=</span> <span class="va">xtest.boost</span>, newy <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span><span class="op">$</span><span class="va">mse</span><span class="op">)</span></span>
<span><span class="co">#&gt; Lasso with xgboost pretraining PSE:  46.23225</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Lasso without xgboost pretraining PSE: "</span>, </span>
<span>    <span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="va">cvfit.noboost</span>, newx <span class="op">=</span> <span class="va">xtest</span>, newy <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span><span class="op">$</span><span class="va">mse</span><span class="op">)</span></span>
<span><span class="co">#&gt; Lasso without xgboost pretraining PSE:  60.68818</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"xgboost alone PSE: "</span>, </span>
<span>    <span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">xgbfit</span>, <span class="va">xtest</span><span class="op">)</span>, newy <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span><span class="op">$</span><span class="va">mse</span><span class="op">)</span></span>
<span><span class="co">#&gt; xgboost alone PSE:  49.47738</span></span></code></pre></div>
</div>
<div class="section level4">
<h4 id="example-2-xgboost-pretraining-with-input-groups">Example 2: xgboost pretraining with input groups<a class="anchor" aria-label="anchor" href="#example-2-xgboost-pretraining-with-input-groups"></a>
</h4>
<p>Now, let’s repeat the above supposing our data have input groups. The
only difference here is that we will use <code>cv.ptLasso</code> for our
model instead of <code>cv.glmnet</code>, and we will use the group
indicators as a feature when fitting <code>xgboost</code>.</p>
<p>We start by simulating data with 3 groups
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>600</mn><annotation encoding="application/x-tex">600</annotation></semantics></math>
observations in each group) and a continuous response. As before, we
will simulate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>
as
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><mn>1</mn><mrow><mo stretchy="true" form="prefix">(</mo><mi>X</mi><mo>&gt;</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow><mi>β</mi><mo>+</mo><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">y = 1(X &gt; 0) \beta + \epsilon</annotation></semantics></math>,
only now we have a different
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>β</mi><annotation encoding="application/x-tex">\beta</annotation></semantics></math>
for each group. The coefficients for the groups are in Table
@ref(tab:nonlinear).</p>
<table class="table">
<caption>Coefficients for simulating data for use with xgboost
pretraining</caption>
<thead><tr class="header">
<th align="left"></th>
<th align="right">1-50</th>
<th align="right">51-100</th>
<th align="right">101-150</th>
<th align="right">151-200</th>
<th align="right">201-500</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">group 1</td>
<td align="right">2</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">group 2</td>
<td align="right">2</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">group 3</td>
<td align="right">2</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb109"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">1800</span>; <span class="va">p</span> <span class="op">=</span> <span class="fl">500</span>; <span class="va">k</span> <span class="op">=</span> <span class="fl">3</span>;</span>
<span><span class="va">noise</span> <span class="op">=</span> <span class="fl">5</span>;</span>
<span></span>
<span><span class="va">groups</span> <span class="op">=</span> <span class="va">groupstest</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sort.html" class="external-link">sort</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">k</span>, <span class="va">n</span><span class="op">/</span><span class="va">k</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">x</span>     <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, nrow<span class="op">=</span><span class="va">n</span>, ncol<span class="op">=</span><span class="va">p</span><span class="op">)</span></span>
<span><span class="va">xtest</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, nrow<span class="op">=</span><span class="va">n</span>, ncol<span class="op">=</span><span class="va">p</span><span class="op">)</span></span>
<span></span>
<span><span class="va">x.model</span>     <span class="op">=</span> <span class="fl">1</span><span class="op">*</span><span class="op">(</span><span class="va">x</span> <span class="op">&gt;</span> <span class="fl">0</span><span class="op">)</span>     </span>
<span><span class="va">xtest.model</span> <span class="op">=</span> <span class="fl">1</span><span class="op">*</span><span class="op">(</span><span class="va">xtest</span> <span class="op">&gt;</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="va">common.beta</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">50</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">50</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">beta.1</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">50</span><span class="op">)</span>,  <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">50</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">100</span><span class="op">)</span><span class="op">)</span> </span>
<span><span class="va">beta.2</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">100</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">50</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">150</span><span class="op">)</span><span class="op">)</span> </span>
<span><span class="va">beta.3</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">150</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">50</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">200</span><span class="op">)</span><span class="op">)</span> </span>
<span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">x.model</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">common.beta</span> <span class="op">+</span> <span class="va">noise</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span><span class="va">y</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">1</span><span class="op">]</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="va">x.model</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">1</span>, <span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta.1</span></span>
<span><span class="va">y</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">2</span><span class="op">]</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">2</span><span class="op">]</span> <span class="op">+</span> <span class="va">x.model</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">2</span>, <span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta.2</span></span>
<span><span class="va">y</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">3</span><span class="op">]</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">3</span><span class="op">]</span> <span class="op">+</span> <span class="va">x.model</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">3</span>, <span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta.3</span></span>
<span></span>
<span><span class="va">ytest</span> <span class="op">=</span> <span class="va">xtest.model</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">common.beta</span> <span class="op">+</span> <span class="va">noise</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span><span class="va">ytest</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">1</span><span class="op">]</span> <span class="op">=</span> <span class="va">ytest</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="va">xtest.model</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">1</span>, <span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta.1</span></span>
<span><span class="va">ytest</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">2</span><span class="op">]</span> <span class="op">=</span> <span class="va">ytest</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">2</span><span class="op">]</span> <span class="op">+</span> <span class="va">xtest.model</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">2</span>, <span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta.2</span></span>
<span><span class="va">ytest</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">3</span><span class="op">]</span> <span class="op">=</span> <span class="va">ytest</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">3</span><span class="op">]</span> <span class="op">+</span> <span class="va">xtest.model</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">3</span>, <span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta.3</span></span></code></pre></div>
<p>Here are the dummy variables for our group indicators; we will use
them to fit and predict with <code>xgboost</code>.</p>
<div class="sourceCode" id="cb110"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">group.ids</span>     <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html" class="external-link">model.matrix</a></span><span class="op">(</span><span class="op">~</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">groups</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span> </span>
<span><span class="va">grouptest.ids</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html" class="external-link">model.matrix</a></span><span class="op">(</span><span class="op">~</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">groupstest</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span> </span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">colnames</a></span><span class="op">(</span><span class="va">grouptest.ids</span><span class="op">)</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">colnames</a></span><span class="op">(</span><span class="va">group.ids</span><span class="op">)</span></span></code></pre></div>
<p>Now, let’s train <code>xgboost</code> and <code>predict</code> to get
our new features. Note that we now use <code>max_depth = 2</code>: this
is intended to allow interactions between the group indicators and the
other features.</p>
<div class="sourceCode" id="cb111"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">xgbfit</span>      <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/xgboost/man/xgb.train.html" class="external-link">xgboost</a></span><span class="op">(</span>data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">group.ids</span><span class="op">)</span>, label<span class="op">=</span><span class="va">y</span>, </span>
<span>                      nrounds<span class="op">=</span><span class="fl">200</span>, max_depth<span class="op">=</span><span class="fl">2</span>, verbose<span class="op">=</span><span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="va">x.boost</span>     <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">xgbfit</span>, <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">group.ids</span><span class="op">)</span>, predleaf <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span></span>
<span><span class="va">xtest.boost</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">xgbfit</span>, <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">xtest</span>, <span class="va">grouptest.ids</span><span class="op">)</span>, predleaf <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span></span></code></pre></div>
<p>Finally, we are ready to fit two models trained with
<code>cv.ptLasso</code>: one uses the xgboost features and the other
does not. As before, we find that pretraining with xgboost improves
performance relative to (1) model fitting in the original feature space
and (2) xgboost alone.</p>
<div class="sourceCode" id="cb112"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cvfit</span> <span class="op">=</span> <span class="fu"><a href="../reference/cv.ptLasso.html">cv.ptLasso</a></span><span class="op">(</span><span class="va">x.boost</span>, <span class="va">y</span>, groups<span class="op">=</span><span class="va">groups</span>, type.measure <span class="op">=</span> <span class="st">"mse"</span><span class="op">)</span></span>
<span><span class="va">preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">cvfit</span>, <span class="va">xtest.boost</span>, groups<span class="op">=</span><span class="va">groupstest</span>, alphatype <span class="op">=</span> <span class="st">"varying"</span><span class="op">)</span></span>
<span><span class="va">preds</span> <span class="op">=</span> <span class="va">preds</span><span class="op">$</span><span class="va">yhatpre</span></span>
<span></span>
<span><span class="va">cvfit.noboost</span> <span class="op">=</span> <span class="fu"><a href="../reference/cv.ptLasso.html">cv.ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, groups<span class="op">=</span><span class="va">groups</span>, type.measure <span class="op">=</span> <span class="st">"mse"</span><span class="op">)</span></span>
<span><span class="va">preds.noboost</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">cvfit.noboost</span>, <span class="va">xtest</span>, groups<span class="op">=</span><span class="va">groupstest</span>, </span>
<span>                        alphatype <span class="op">=</span> <span class="st">"varying"</span><span class="op">)</span></span>
<span><span class="va">preds.noboost</span> <span class="op">=</span> <span class="va">preds.noboost</span><span class="op">$</span><span class="va">yhatpre</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"ptLasso with xgboost pretraining PSE: "</span>, </span>
<span>    <span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="va">preds</span>, newy <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span><span class="op">$</span><span class="va">mse</span><span class="op">)</span></span>
<span><span class="co">#&gt; ptLasso with xgboost pretraining PSE:  55.1535</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"ptLasso without xgboost pretraining PSE: "</span>, </span>
<span>    <span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="va">preds.noboost</span>, newy <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span><span class="op">$</span><span class="va">mse</span><span class="op">)</span></span>
<span><span class="co">#&gt; ptLasso without xgboost pretraining PSE:  66.37259</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"xgboost alone PSE: "</span>, </span>
<span>    <span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">xgbfit</span>, <span class="va">xtest</span><span class="op">)</span>, newy <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span><span class="op">$</span><span class="va">mse</span><span class="op">)</span></span>
<span><span class="co">#&gt; xgboost alone PSE:  59.63781</span></span></code></pre></div>
</div>
</div>
<div class="section level3">
<h3 id="unsupervised-pretraining">Unsupervised pretraining<a class="anchor" aria-label="anchor" href="#unsupervised-pretraining"></a>
</h3>
<div class="sourceCode" id="cb113"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va"><a href="https://glmnet.stanford.edu" class="external-link">glmnet</a></span><span class="op">)</span></span></code></pre></div>
<p>Suppose we have a dataset with features
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
and response
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>.
Suppose we also have a large set of <em>unlabeled</em> data
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>X</mi><mo>*</mo></msup><annotation encoding="application/x-tex">X^*</annotation></semantics></math>.
Here, we show how to <em>pretrain</em> a model using
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>X</mi><mo>*</mo></msup><annotation encoding="application/x-tex">X^*</annotation></semantics></math>.
The steps are:</p>
<ol style="list-style-type: decimal">
<li>Do sparse PCA using
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>X</mi><mo>*</mo></msup><annotation encoding="application/x-tex">X^*</annotation></semantics></math>.
Identify the nonzero features in the first principal component
(PC).</li>
<li>Use <code>glmnet</code> (or <code>cv.glmnet</code>) to train model
using
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>.
Define the penalty factor using the support identified by sparse PCA.
Unlike the usual pretraining, there is no offset defined by sparse
PCA.</li>
</ol>
<p>In step 1, we may choose to use the nonzero features from the first
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
PCs instead of just the first PC; in the examples that follow, we use
only the first PC for simplicity.</p>
<p>We will demonstrate unsupervised pretraining using simulated data.
The covariates
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>X</mi><mo>*</mo></msup><annotation encoding="application/x-tex">X^*</annotation></semantics></math>
are drawn from a multivariate normal distribution where the first 10
features describe most of the variance, and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>
is defined as
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mi>β</mi><mo>+</mo><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">X \beta + \epsilon</annotation></semantics></math>,
where only the first 10 coefficients in
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>β</mi><annotation encoding="application/x-tex">\beta</annotation></semantics></math>
are nonzero and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ϵ</mi><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math>
is noise. In this example, we have 10 times as much unlabeled data as
labeled data; this generally happens when labels are difficult to
obtain.</p>
<div class="sourceCode" id="cb114"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va"><a href="http://www.stats.ox.ac.uk/pub/MASS4/" class="external-link">MASS</a></span><span class="op">)</span> <span class="co"># for mvrnorm</span></span>
<span><span class="co">#&gt; Loading required package: MASS</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">100</span>; <span class="va">p</span> <span class="op">=</span> <span class="fl">150</span>; </span>
<span></span>
<span><span class="va">mu</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">sigma</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">p</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">*</span><span class="fl">2</span><span class="op">-</span><span class="fl">1</span>, ncol<span class="op">=</span><span class="va">p</span><span class="op">)</span> </span>
<span><span class="va">sigma</span><span class="op">[</span>, <span class="fl">11</span><span class="op">:</span><span class="va">p</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1e-2</span> <span class="co"># The first 10 features are the most important</span></span>
<span><span class="va">sigma</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="va">sigma</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">sigma</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/diag.html" class="external-link">diag</a></span><span class="op">(</span><span class="va">sigma</span><span class="op">)</span><span class="op">[</span><span class="fl">11</span><span class="op">:</span><span class="va">p</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1</span></span>
<span></span>
<span><span class="va">x</span>     <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/MASS/man/mvrnorm.html" class="external-link">mvrnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, mu <span class="op">=</span> <span class="va">mu</span>, Sigma <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span></span>
<span><span class="va">xtest</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/MASS/man/mvrnorm.html" class="external-link">mvrnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, mu <span class="op">=</span> <span class="va">mu</span>, Sigma <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span></span>
<span><span class="va">xstar</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/MASS/man/mvrnorm.html" class="external-link">mvrnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span> <span class="op">*</span> <span class="va">n</span>, mu <span class="op">=</span> <span class="va">mu</span>, Sigma <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span> <span class="co"># unlabeled</span></span>
<span></span>
<span><span class="va">noise</span> <span class="op">=</span> <span class="fl">3</span></span>
<span><span class="va">beta</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">10</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span> <span class="op">-</span> <span class="fl">10</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">y</span>     <span class="op">=</span> <span class="va">x</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta</span>     <span class="op">+</span> <span class="va">noise</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span><span class="va">ytest</span> <span class="op">=</span> <span class="va">xtest</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta</span> <span class="op">+</span> <span class="va">noise</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span></span>
<span><span class="va">train.folds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span>, <span class="fl">10</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>Now, we do sparse PCA using
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>X</mi><mo>*</mo></msup><annotation encoding="application/x-tex">X^*</annotation></semantics></math>
and we identify the features with nonzero loadings in the first PC. The
argument
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">k = 1</annotation></semantics></math>
means that we only obtain the first PC.</p>
<div class="sourceCode" id="cb115"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va"><a href="https://github.com/erichson/spca" class="external-link">sparsepca</a></span><span class="op">)</span></span>
<span><span class="co">#&gt; Loading required package: sparsepca</span></span>
<span></span>
<span><span class="va">pcs</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/sparsepca/man/spca.html" class="external-link">spca</a></span><span class="op">(</span><span class="va">xstar</span>, k <span class="op">=</span> <span class="fl">1</span>, verbose<span class="op">=</span><span class="cn">FALSE</span>, alpha<span class="op">=</span><span class="fl">1e-2</span>, beta<span class="op">=</span><span class="fl">1e-2</span><span class="op">)</span></span>
<span><span class="va">nonzero.loadings</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="va">pcs</span><span class="op">$</span><span class="va">loadings</span> <span class="op">!=</span> <span class="fl">0</span><span class="op">)</span></span></code></pre></div>
<p>We set ourselves up for success: because of how we simulated our
data, we know that the first 10 features are those that explain the
variance in
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>.
These are also the features that define the relationship between
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>.
Let’s check that sparse PCA has found the right features:</p>
<div class="sourceCode" id="cb116"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">nonzero.loadings</span></span>
<span><span class="co">#&gt; [1]  1  2  3  4  5  7  8 10</span></span></code></pre></div>
<p>Now, we are ready to model! We don’t need to call
<code>ptLasso</code> here. All we need to do is call
<code>cv.glmnet</code> across a grid of values of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
with a different <code>penalty.factor</code> for each call. Note that
<code>offset</code> is not used – sparse PCA identifies <em>which
features</em> may important, but it doesn’t suggest a value for the
fitted coefficients.</p>
<p>To do model selection, we want to know which value of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>α</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
gave us the best CV error. Fortunately, <code>cv.glmnet</code> will
record the CV MSE for each model in a vector called <code>cvm</code>; we
just need to keep track of the minimum error from each model.</p>
<div class="sourceCode" id="cb117"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">alphalist</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">11</span><span class="op">)</span></span>
<span></span>
<span><span class="va">cvm</span> <span class="op">=</span> <span class="cn">NULL</span></span>
<span><span class="kw">for</span><span class="op">(</span><span class="va">alpha</span> <span class="kw">in</span> <span class="va">alphalist</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="co"># Define the penalty factor:</span></span>
<span>  <span class="va">pf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="va">alpha</span>, <span class="va">p</span><span class="op">)</span></span>
<span>  <span class="va">pf</span><span class="op">[</span><span class="va">nonzero.loadings</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1</span></span>
<span>  </span>
<span>  <span class="co"># Train a model:</span></span>
<span>  <span class="va">model</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, family <span class="op">=</span> <span class="st">"gaussian"</span>, type.measure <span class="op">=</span> <span class="st">"mse"</span>,</span>
<span>                              penalty.factor <span class="op">=</span> <span class="va">pf</span>, </span>
<span>                              foldid <span class="op">=</span> <span class="va">train.folds</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Record the minmum CV MSE for this model:</span></span>
<span>  <span class="va">cvm</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">cvm</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">min</a></span><span class="op">(</span><span class="va">model</span><span class="op">$</span><span class="va">cvm</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">best.alpha</span> <span class="op">=</span> <span class="va">alphalist</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html" class="external-link">which.min</a></span><span class="op">(</span><span class="va">cvm</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># Plot performance as a function of alpha</span></span>
<span><span class="co"># with a vertical line to show us the minimum mse:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">alphalist</span>, <span class="va">cvm</span>, </span>
<span>     xlab <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html" class="external-link">expression</a></span><span class="op">(</span><span class="va">alpha</span><span class="op">)</span>, </span>
<span>     ylab <span class="op">=</span> <span class="st">"Mean squared error (CV)"</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="va">best.alpha</span><span class="op">)</span></span></code></pre></div>
<p><img src="ptLasso_files/figure-html/unnamed-chunk-272-1.png" width="700"></p>
<p>So, using CV performance as a metric, we choose
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.2</mn></mrow><annotation encoding="application/x-tex">\alpha = 0.2</annotation></semantics></math>.
Now, we train our final model and predict and measure performance with
our held-out data. We find that pretraining gives us a boost in
performance.</p>
<div class="sourceCode" id="cb118"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="va">best.alpha</span>, <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">pf</span><span class="op">[</span><span class="va">nonzero.loadings</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1</span></span>
<span></span>
<span><span class="va">selected.model</span> <span class="op">=</span>  <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, family <span class="op">=</span> <span class="st">"gaussian"</span>, type.measure <span class="op">=</span> <span class="st">"mse"</span>,</span>
<span>                              penalty.factor <span class="op">=</span> <span class="va">pf</span>, </span>
<span>                              foldid <span class="op">=</span> <span class="va">train.folds</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Prediction squared error with pretraining:</span></span>
<span><span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="va">selected.model</span>, <span class="va">xtest</span>, newy <span class="op">=</span> <span class="va">ytest</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span><span class="op">[</span><span class="st">"mse"</span><span class="op">]</span></span>
<span><span class="co">#&gt; $mse</span></span>
<span><span class="co">#&gt; lambda.min </span></span>
<span><span class="co">#&gt;   11.97648 </span></span>
<span><span class="co">#&gt; attr(,"measure")</span></span>
<span><span class="co">#&gt; [1] "Mean-Squared Error"</span></span>
<span></span>
<span><span class="va">without.pretraining</span> <span class="op">=</span>  <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, family <span class="op">=</span> <span class="st">"gaussian"</span>, type.measure <span class="op">=</span> <span class="st">"mse"</span>,</span>
<span>                                 foldid <span class="op">=</span> <span class="va">train.folds</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Prediction squared error without pretraining:</span></span>
<span><span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="va">without.pretraining</span>, <span class="va">xtest</span>, newy <span class="op">=</span> <span class="va">ytest</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span><span class="op">[</span><span class="st">"mse"</span><span class="op">]</span></span>
<span><span class="co">#&gt; $mse</span></span>
<span><span class="co">#&gt; lambda.min </span></span>
<span><span class="co">#&gt;   13.18393 </span></span>
<span><span class="co">#&gt; attr(,"measure")</span></span>
<span><span class="co">#&gt; [1] "Mean-Squared Error"</span></span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-craig2024pretraining" class="csl-entry">
Craig, Erin, Mert Pilanci, Thomas Le Menestrel, Balasubramanian
Narasimhan, Manuel Rivas, Roozbeh Dehghannasiri, Julia Salzman, Jonathan
Taylor, and Robert Tibshirani. 2024. <span>“Pretraining and the
Lasso.”</span> <em>arXiv Preprint arXiv:2401.12911</em>.
</div>
<div id="ref-glmnet" class="csl-entry">
Friedman, Jerome, Robert Tibshirani, and Trevor Hastie. 2010.
<span>“Regularization Paths for Generalized Linear Models via Coordinate
Descent.”</span> <em>Journal of Statistical Software</em> 33 (1): 1–22.
<a href="https://doi.org/10.18637/jss.v033.i01" class="external-link">https://doi.org/10.18637/jss.v033.i01</a>.
</div>
<div id="ref-odrf" class="csl-entry">
Liu, Yu, and Yingcun Xia. 2022. <span>“<span>ODRF</span>: Consistency of
the Oblique Decision Tree and Its Random Forest.”</span> <em>arXiv
Preprint arXiv:2211.12653</em>.
</div>
<div id="ref-nie2021quasi" class="csl-entry">
Nie, Xinkun, and Stefan Wager. 2021. <span>“Quasi-Oracle Estimation of
Heterogeneous Treatment Effects.”</span> <em>Biometrika</em> 108 (2):
299–319.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by <a href="http://www.erincraig.me" class="external-link">Erin Craig</a>, <a href="http://statistics.stanford.edu/people/robert-tibshirani" class="external-link">Rob Tibshirani</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
