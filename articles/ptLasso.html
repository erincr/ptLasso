<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="ptLasso">
<title>ptLasso Vignette and Manual • ptLasso</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.11/clipboard.min.js" integrity="sha512-7O5pXpc0oCRrxk8RUfDYFgn0nO1t+jLuIOQdOMRp4APB7uZ4vSjspzp5y6YDtDs4VzUSTbWzBFZ/LKJhnyFOKw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="ptLasso Vignette and Manual">
<meta property="og:description" content="ptLasso">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-dark navbar-expand-lg bg-primary" data-bs-theme="dark"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">ptLasso</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item">
  <a class="nav-link" href="../articles/ptLasso.html">Get started</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/DifferentGroupsTrainAndTest.html">Different groups in train and test data</a>
    <a class="dropdown-item" href="../articles/LearningTheInputGroups.html">Learning the input groups</a>
    <a class="dropdown-item" href="../articles/MultitaskLearning.html">Multitask learning or coaching</a>
    <a class="dropdown-item" href="../articles/MultiResponseData.html">Multi-response data with mixed response types</a>
    <a class="dropdown-item" href="../articles/TimeSeriesData.html">Time series</a>
    <a class="dropdown-item" href="../articles/UsingNonlinearBases.html">Pretraining with nonlinear bases</a>
    <a class="dropdown-item" href="../articles/UnsupervisedPretraining.html">Unsupervised pretraining</a>
    <a class="dropdown-item" href="../articles/ConditionalAverageTreatmentEffect.html">Conditional average treatment effects</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav"></ul>
</div>

    
  </div>
</nav><div class="container template-article">


<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>ptLasso Vignette and Manual</h1>
            
      
      
      <div class="d-none name"><code>ptLasso.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction-to-pretraining">Introduction to pretraining<a class="anchor" aria-label="anchor" href="#introduction-to-pretraining"></a>
</h2>
<p>Suppose we have a dataset spanning ten cancers and we want to fit a
lasso penalized Cox model to predict survival time. Some of the cancer
classes in our dataset are large (e.g. breast, lung) and some are small
(e.g. head and neck). There are two obvious approaches: (1) fit a
“pancancer model” to the entire training set and use it to make
predictions for all cancer classes and (2) fit a separate (class
specific) model for each cancer and use it to make predictions for that
class only.</p>
<p>Pretraining (<span class="citation">Craig et al. (2024)</span>) is a
method that bridges these two options; it has a parameter that allows
you to fit the pancancer model, the class specific models, and
everything in between. <code>ptLasso</code> is a package that fits
pretrained models using the <code>glmnet</code> package (<span class="citation">Friedman, Tibshirani, and Hastie (2010)</span>),
including lasso, elasticnet and ridge models .</p>
<p>Our example dataset consisting of ten different cancers is called
<strong>input grouped</strong>. There is a grouping on the rows of <span class="math inline">\(X\)</span> and each row belongs to one of the
cancer classes. Alternatively, data can be <strong>target
grouped</strong>, where there is no grouping on the rows of <span class="math inline">\(X\)</span>, but we have (for example) a
multinomial outcome. We could fit one multinomial model, or we could fit
a set of one-vs-rest models. Pretraining again bridges the two
approaches, and this is described in detail in the section “Target
grouped data”. The remainder of this introduction describes the input
grouped setting.</p>
<p>Importantly, pretraining is a general method to pass information from
one model to another – it has many uses beyond what has already been
discussed here, including time series data, multi-response data with
mixed response types, and multitask learning. Some of these modeling
tasks are not supported by the <code>ptLasso</code> package, and this
vignette shows how to do pretraining for them using the
<code>glmnet</code> package. These sections are marked by the expression
<em>“<code>glmnet</code> only”</em> in their title.</p>
<p>Before we describe pretraining in more detail, we will first give a
quick review of the lasso.</p>
<div class="section level3">
<h3 id="review-of-the-lasso">Review of the lasso<a class="anchor" aria-label="anchor" href="#review-of-the-lasso"></a>
</h3>
<p>For the Gaussian family with data <span class="math inline">\((x_i,y_i), i=1,2,\ldots n\)</span>, the lasso has
the form <span class="math display">\[\begin{equation}
{\rm argmin}_{\beta_0, \beta} \frac{1}{2} \sum_{i=1}^n(y_i- \beta_0
-\sum_{j=1}^p x_{ij}\beta_j)^2 + \lambda \sum_{j=1}^p |\beta_j |.
\end{equation}\]</span> Varying the regularization parameter <span class="math inline">\(\lambda \ge 0\)</span> yields a path of solutions:
an optimal value <span class="math inline">\(\hat\lambda\)</span> is
usually chosen by cross-validation, using for example the
<code>cv.glmnet</code> function from the package
<code>glmnet</code>.</p>
<p>In GLMs and <span class="math inline">\(\ell_1\)</span>-regularized
GLMs, one can include an <em>offset</em>: a pre-specified <span class="math inline">\(n\)</span>-vector that is included as an
additional column to the feature matrix, but whose weight <span class="math inline">\(\beta_j\)</span> is fixed at 1. Secondly, one can
generalize the <span class="math inline">\(\ell_1\)</span> norm to a
weighted norm, taking the form <span class="math display">\[\begin{equation}
\sum_j {\rm pf}_j |\beta_j |
\end{equation}\]</span> where each <span class="math inline">\({\rm
pf}_j \ge 0\)</span> is a <strong>penalty factor</strong> for feature
<span class="math inline">\(j\)</span>. At the extremes, a penalty
factor of zero implies no penalty and means that the feature will always
be included in the model; a penalty factor of <span class="math inline">\(+\infty\)</span> leads to that feature being
discarded (i.e., never entered into the model).</p>
</div>
<div class="section level3">
<h3 id="details-of-pretraining">Details of pretraining<a class="anchor" aria-label="anchor" href="#details-of-pretraining"></a>
</h3>
<p>Pretraining model fitting happens in two steps. First, train a model
using the full data: <span class="math display">\[\begin{equation}
    \hat{\mu}_0, \hat{\theta}_1, \dots, \hat{\theta}_k, \hat{\beta}_0 =
\arg \min_{\mu_0, \theta_1, \dots, \theta_k, \beta_0} \frac{1}{2}
\sum_{k=1}^K \| y_k - \left(\mu_0 \mathbf{1} + \theta_k \mathbf{1} + X_k
\beta_0\right) \|_2^2 + \lambda ||\beta||_1,
\end{equation}\]</span> where:</p>
<ul>
<li>
<span class="math inline">\(X_k, y_k\)</span> are the observations
in group <span class="math inline">\(k\)</span>,</li>
<li>
<span class="math inline">\(\theta_k\)</span> is the group specific
intercept for group <span class="math inline">\(k\)</span> (by
convention, <span class="math inline">\(\hat{\theta}_1 =
0\)</span>),</li>
<li>
<span class="math inline">\(\mu, \beta\)</span> are the overall
intercept and coefficients,</li>
<li>and <span class="math inline">\(\lambda\)</span> is a parameter that
has been chosen (perhaps the value minimizing the CV error).</li>
</ul>
<p>Define <span class="math inline">\(S(\hat\beta_0)\)</span> to be the
support set (the nonzero coefficients) of <span class="math inline">\(\hat{\beta}_0\)</span>.</p>
<p>Then, for each group <span class="math inline">\(k\)</span>, fit an
<em>individual</em> model: find <span class="math inline">\(\hat{\beta}_k\)</span> and <span class="math inline">\(\hat{\mu}_k\)</span> such that <span class="math display">\[\begin{eqnarray}
&amp;&amp; \hat{\mu}_k, \hat{\beta}_k = \arg \min_{\mu_k, \beta_k}
\frac{1}{2}  \| y_k - (1-\alpha) \left(\hat{\mu}_0 \mathbf{1} +
\hat{\theta}_k \mathbf{1} + X_k \hat{\beta}_0\right) - (\mu_k \mathbf{1}
+ X_k \beta_k) \|_2^2 +
\cr &amp;&amp; \phantom{\hat{\mu}_k, \hat{\beta}_k} \lambda_2
\sum_{j=1}^p \Bigl[ I(j \in S(\hat{\beta}_0))+ \frac{1}{\alpha} I(j
\notin S(\hat{\beta}_0))  \Bigr] |\beta_{kj}|,
\label{eq:model}
\end{eqnarray}\]</span> where <span class="math inline">\(\lambda_2 &gt;
0\)</span> and <span class="math inline">\(\alpha\in [0,1]\)</span> are
hyperparameters that may be chosen through cross validation.</p>
<p>This is a lasso linear regression model with two additional
components: <em>offset</em> <span class="math inline">\((1-\alpha)
\left(\hat{\mu}_0 \mathbf{1} + \hat{\theta}_k \mathbf{1} + X_k
\hat{\beta}_0\right)\)</span>, and <em>penalty factor</em> for
coefficient <span class="math inline">\(j\)</span> which is 1 if <span class="math inline">\(j \in S(\hat{\beta}_0)\)</span> and <span class="math inline">\(\frac{1}{\alpha}\)</span> otherwise.</p>
<p>Notice that when <span class="math inline">\(\alpha=0\)</span>, this
returns the overall model fine tuned for each group: this second stage
model is only allowed to fit the residual <span class="math inline">\(y_k - \left(\hat{\mu}_0 \mathbf{1} +
\hat{\theta}_k \mathbf{1} + X_k \hat{\beta}_0\right)\)</span>, and the
penalty factor only allows the use of <span class="math inline">\(\beta_j\)</span> if it was already selected by the
overall model.</p>
<p>At the other extreme, when <span class="math inline">\(\alpha=1\)</span>, this is equivalent to fitting a
separate model for each class. There is no offset, and the lasso penalty
is 1 for all features (the usual lasso penalty).</p>
</div>
<div class="section level3">
<h3 id="ptlasso-under-the-hood">
<code>ptLasso</code> under the hood<a class="anchor" aria-label="anchor" href="#ptlasso-under-the-hood"></a>
</h3>
<p>All model fitting in <code>ptLasso</code> is done with
<code>cv.glmnet</code>. The first step of pretraining is a
straightforward call to <code>cv.glmnet</code>; the second step is done
by calling <code>cv.glmnet</code> with:</p>
<ol style="list-style-type: decimal">
<li>
<code>offset</code> <span class="math inline">\((1-\alpha)
\left(\hat{\mu_0} \mathbf{1} + \hat{\theta}_k \mathbf{1} + X_k
\hat{\beta_0}\right)\)</span> and</li>
<li>
<code>penalty.factor</code>, the <span class="math inline">\(j^\text{th}\)</span> entry of which is <span class="math inline">\(1\)</span> if <span class="math inline">\(j \in
S(\hat{\beta_0})\)</span> and <span class="math inline">\(\frac{1}{\alpha}\)</span> otherwise.</li>
</ol>
<p>Because <code>ptLasso</code> uses <code>cv.glmnet</code>, it inherits
most of the virtues of the <code>glmnet</code> package: for example, it
handles sparse input-matrix formats, as well as range constraints on
coefficients.</p>
<p>Additionally, one call to <code>ptLasso</code> fits an overall model,
pretrained class specific models, and class specific models for each
group (without pretraining). The <code>ptLasso</code> package also
includes methods for prediction and plotting, and a function that
performs K-fold cross-validation.</p>
</div>
</div>
<div class="section level2">
<h2 id="quick-start">Quick start<a class="anchor" aria-label="anchor" href="#quick-start"></a>
</h2>
<div class="section level3">
<h3 id="ptlasso-uses-the-same-syntax-as-glmnet">ptLasso uses the same syntax as glmnet<a class="anchor" aria-label="anchor" href="#ptlasso-uses-the-same-syntax-as-glmnet"></a>
</h3>
<p>For those familiar with <code>glmnet</code>, <code>ptLasso</code> has
a similar structure: <code>ptLasso</code> has functions to train, plot
and predict, and it follows the syntax of <code>glmnet</code>.</p>
<p>Additionally, <code>ptLasso</code> has a parameter <span class="math inline">\(\alpha\)</span> that is analogous to the
elasticnet parameter also called <span class="math inline">\(\alpha\)</span>. To avoid confusion, we will refer
to the elasticnet parameter as <span class="math inline">\(\alpha_{\text{en}}\)</span>. As with <span class="math inline">\(\alpha_{\text{en}}\)</span> in
<code>glmnet</code>, you must specify the value of <span class="math inline">\(\alpha\)</span> that you want to use when calling
<code>ptLasso</code>; the default is <span class="math inline">\(\alpha
= 0.5\)</span>.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># The typical glmnet pipeline: train, plot and predict,</span></span>
<span><span class="co"># using elasticnet parameter 0.2.</span></span>
<span><span class="va">fit</span> <span class="op">=</span> <span class="fu">glmnet</span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span>, alpha <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span>
<span><span class="va">test.preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">Xtest</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># The typical ptLasso pipeline: train, plot and predict,</span></span>
<span><span class="co"># using pretraining parameter 0.5.</span></span>
<span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span>, <span class="va">groups</span>, alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span>
<span><span class="va">test.preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">Xtest</span>, <span class="va">groupstest</span><span class="op">)</span></span></code></pre></div>
<p>There are a few big differences between <code>ptLasso</code> and
<code>glmnet</code>:</p>
<ul>
<li>
<code>ptLasso</code> calls <code>cv.glmnet</code> under the hood:
cross validation over <span class="math inline">\(\lambda\)</span> is
done automatically</li>
<li>the <code>ptLasso</code> package includes <code>cv.ptLasso</code>: a
function to do cross validation over <span class="math inline">\(\alpha\)</span>.</li>
</ul>
<p>With cross validation, the typical <code>ptLasso</code> pipeline
looks like:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/cv.ptLasso.html">cv.ptLasso</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span>, <span class="va">groups</span>, alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span>
<span><span class="va">test.preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">Xtest</span>, <span class="va">groupstest</span><span class="op">)</span></span></code></pre></div>
<p>The <code>predict</code> function uses the value of <span class="math inline">\(\alpha\)</span> that achieved the best average CV
performance across groups. But it is possible to instead use a different
<span class="math inline">\(\alpha\)</span> for each group (specifically
the <span class="math inline">\(\alpha\)</span> that achieved the best
CV performance <em>for each group</em>). An example is at the end of
this section.</p>
</div>
<div class="section level3">
<h3 id="an-example">An example<a class="anchor" aria-label="anchor" href="#an-example"></a>
</h3>
<p>First, we load the <code>ptLasso</code> package:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va"><a href="https://erincr.github.io/ptLasso/">ptLasso</a></span><span class="op">)</span></span>
<span><span class="co">#&gt; Loading required package: ptLasso</span></span>
<span><span class="co">#&gt; Loading required package: ggplot2</span></span>
<span><span class="co">#&gt; Loading required package: glmnet</span></span>
<span><span class="co">#&gt; Loading required package: Matrix</span></span>
<span><span class="co">#&gt; Loaded glmnet 4.1-8</span></span>
<span><span class="co">#&gt; Loading required package: gridExtra</span></span></code></pre></div>
<p>To show how to use <code>ptLasso</code>, we’ll simulate data with 5
groups and a continuous response using the helper function
<code>gaussian.example.data</code>. There are <span class="math inline">\(n = 200\)</span> observations in each group and
<span class="math inline">\(p = 120\)</span> features. All groups share
10 informative features; though the features are shared, they have
different coefficient values. Each group has 10 additional features that
are specific to that group, and all other features are uninformative.
<!--The coefficients for the 5 groups are in Table \@ref(tab:coefs).--></p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="va">out</span> <span class="op">=</span> <span class="fu"><a href="../reference/gaussian.example.data.html">gaussian.example.data</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="va">out</span><span class="op">$</span><span class="va">x</span>; <span class="va">y</span> <span class="op">=</span> <span class="va">out</span><span class="op">$</span><span class="va">y</span>; <span class="va">groups</span> <span class="op">=</span> <span class="va">out</span><span class="op">$</span><span class="va">groups</span></span>
<span></span>
<span><span class="va">outtest</span> <span class="op">=</span> <span class="fu"><a href="../reference/gaussian.example.data.html">gaussian.example.data</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">xtest</span> <span class="op">=</span> <span class="va">outtest</span><span class="op">$</span><span class="va">x</span>; <span class="va">ytest</span> <span class="op">=</span> <span class="va">outtest</span><span class="op">$</span><span class="va">y</span>; <span class="va">groupstest</span> <span class="op">=</span> <span class="va">outtest</span><span class="op">$</span><span class="va">groups</span></span></code></pre></div>
<p>Now we are ready to fit a model using <code>ptLasso</code>. We’ll use
the pretraining parameter <span class="math inline">\(\alpha =
0.5\)</span> (randomly chosen).</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span></code></pre></div>
<!--In practice we recommend choosing $\alpha$ more thoughtfully by using (1) a validation set to measure performance for a few different choices of $\alpha$ (e.g. $0, 0.25, 0.5, 0.75, 1.0$), or (2) `cv.ptLasso`, which will recommend a choice of $\alpha$ based on CV performance.-->
<p>The function <code>ptLasso</code> used <code>cv.glmnet</code> to fit
11 models:</p>
<ul>
<li>the <em>overall</em> model (using all 5 groups),</li>
<li>the 5 <em>pretrained</em> models (one for each group) and</li>
<li>the 5 <em>individual</em> models (one for each group).</li>
</ul>
<p>A call to <code>plot</code> displays the cross validation curves for
each model. The top row shows the overall model, the middle row the
pretrained models, and the bottom row the individual models.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span></code></pre></div>
<p><img src="ptLasso_files/figure-html/unnamed-chunk-6-1.png" width="700"></p>
<p><code>predict</code> makes predictions from all <span class="math inline">\(11\)</span> models. It returns a list
containing:</p>
<ol style="list-style-type: decimal">
<li>
<code>yhatoverall</code> (predictions from the overall model),</li>
<li>
<code>yhatpre</code> (predictions from the pretrained models)
and</li>
<li>
<code>yhatind</code> (predictions from the individual models).</li>
</ol>
<p>By default, <code>predict</code> uses <code>lambda.min</code> for all
<span class="math inline">\(11\)</span> <code>cv.glmnet</code> models;
you could instead specify <code>s = lambda.1se</code> or use a numeric
value. Whatever value of <span class="math inline">\(\lambda\)</span>
you choose will be used for all models (overall, pretrained and
individual).</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">xtest</span>, groupstest<span class="op">=</span><span class="va">groupstest</span><span class="op">)</span></span></code></pre></div>
<p>If you also provide <code>ytest</code> (for model validation),
<code>predict</code> will additionally compute performance measures.
<!---For continuous outcomes, `predict` computes the mean squared prediction error by default; the argument `type.measure = "mae"` would compute the mean absolute prediction error instead.---></p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">xtest</span>, groupstest<span class="op">=</span><span class="va">groupstest</span>, ytest<span class="op">=</span><span class="va">ytest</span><span class="op">)</span></span>
<span><span class="va">preds</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.ptLasso(object = fit, xtest = xtest, groupstest = groupstest,  </span></span>
<span><span class="co">#&gt;     ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0.5 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (Mean squared error):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            allGroups  mean group_1 group_2 group_3 group_4 group_5    r^2</span></span>
<span><span class="co">#&gt; Overall        755.7 755.7   836.0   554.9   565.4   777.9  1044.0 0.5371</span></span>
<span><span class="co">#&gt; Pretrain       503.2 503.2   550.6   443.3   553.5   505.6   462.9 0.6918</span></span>
<span><span class="co">#&gt; Individual     532.8 532.8   584.1   443.2   567.2   550.5   518.9 0.6736</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                          </span></span>
<span><span class="co">#&gt; Overall    64                            </span></span>
<span><span class="co">#&gt; Pretrain   94 (21 common + 73 individual)</span></span>
<span><span class="co">#&gt; Individual 109</span></span></code></pre></div>
<p>To access the coefficients of the fitted models, use
<code>coef</code> as usual. This returns a list with the coefficients of
the individual models, pretrained models and overall models, as returned
by <code>glmnet</code>.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">all.coefs</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">fit</span>, s<span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">all.coefs</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "individual" "pretrain"   "overall"</span></span></code></pre></div>
<p>The entries for the individual and pretrained models are lists with
one entry for each group. Because we have 5 groups, we’ll have 5 sets of
coefficients.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">all.coefs</span><span class="op">$</span><span class="va">pretrain</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 5</span></span></code></pre></div>
<p>The first few coefficients for group 1 from the pretrained model
are:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">all.coefs</span><span class="op">$</span><span class="va">pretrain</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">#&gt; 6 x 1 sparse Matrix of class "dgCMatrix"</span></span>
<span><span class="co">#&gt;                     s1</span></span>
<span><span class="co">#&gt; (Intercept)  0.5088629</span></span>
<span><span class="co">#&gt; V1          -4.0203684</span></span>
<span><span class="co">#&gt; V2           .        </span></span>
<span><span class="co">#&gt; V3           .        </span></span>
<span><span class="co">#&gt; V4          -0.1923623</span></span>
<span><span class="co">#&gt; V5          -0.6581933</span></span></code></pre></div>
<p>When we used <code>ptLasso</code> to fit a model, we chose <span class="math inline">\(\alpha = 0.5\)</span>. In practice we recommend
choosing <span class="math inline">\(\alpha\)</span> more thoughtfully
by using (1) a validation set to measure performance for a few different
choices of <span class="math inline">\(\alpha\)</span> (e.g. <span class="math inline">\(0, 0.25, 0.5, 0.75, 1.0\)</span>) or (2) the
function <code>cv.ptLasso</code>.</p>
<p>The call to <code>cv.ptLasso</code> is nearly identical to that for
<code>ptLasso</code>. By default, <code>cv.ptLasso</code> will try <span class="math inline">\(\alpha = 0, 0.1, 0.2, \dots, 1\)</span>, but this
can be changed with the argument <code>alphalist</code>. After fitting,
printing the <code>cv.ptLasso</code> object shows the cross validated
mean squared error for all models.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cvfit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cv.ptLasso.html">cv.ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span><span class="op">)</span></span>
<span><span class="va">cvfit</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; cv.ptLasso(x = x, y = y, groups = groups, family = "gaussian",  </span></span>
<span><span class="co">#&gt;     type.measure = "mse", use.case = "inputGroups", group.intercepts = TRUE) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; type.measure:  mse </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            alpha overall  mean wtdMean group_1 group_2 group_3 group_4 group_5</span></span>
<span><span class="co">#&gt; Overall            696.4 696.4   696.4   739.5   500.8   566.4   669.4  1005.9</span></span>
<span><span class="co">#&gt; Pretrain     0.0   523.2 523.2   523.2   511.2   475.1   513.8   521.5   594.3</span></span>
<span><span class="co">#&gt; Pretrain     0.1   512.9 512.9   512.9   417.7   471.3   554.8   537.5   583.4</span></span>
<span><span class="co">#&gt; Pretrain     0.2   501.0 501.0   501.0   415.3   449.9   539.1   496.4   604.2</span></span>
<span><span class="co">#&gt; Pretrain     0.3   494.5 494.5   494.5   409.4   432.8   536.9   512.2   581.3</span></span>
<span><span class="co">#&gt; Pretrain     0.4   486.9 486.9   486.9   390.7   420.2   536.0   522.4   565.1</span></span>
<span><span class="co">#&gt; Pretrain     0.5   507.2 507.2   507.2   411.3   451.4   577.4   532.5   563.7</span></span>
<span><span class="co">#&gt; Pretrain     0.6   506.9 506.9   506.9   382.7   448.0   573.1   497.0   633.6</span></span>
<span><span class="co">#&gt; Pretrain     0.7   504.9 504.9   504.9   377.7   485.2   582.1   507.0   572.7</span></span>
<span><span class="co">#&gt; Pretrain     0.8   496.4 496.4   496.4   395.9   471.5   573.7   488.8   552.1</span></span>
<span><span class="co">#&gt; Pretrain     0.9   526.0 526.0   526.0   384.4   482.8   605.6   522.9   634.2</span></span>
<span><span class="co">#&gt; Pretrain     1.0   538.8 538.8   538.8   422.4   506.6   604.4   533.8   626.8</span></span>
<span><span class="co">#&gt; Individual         538.8 538.8   538.8   422.4   506.6   604.4   533.8   626.8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alphahat (fixed) = 0.4</span></span>
<span><span class="co">#&gt; alphahat (varying):</span></span>
<span><span class="co">#&gt; group_1 group_2 group_3 group_4 group_5 </span></span>
<span><span class="co">#&gt;     0.7     0.4     0.0     0.8     0.8</span></span></code></pre></div>
<p>Plotting the <code>cv.ptLasso</code> object visualizes performance as
a function of <span class="math inline">\(\alpha\)</span>.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">cvfit</span><span class="op">)</span></span></code></pre></div>
<p><img src="ptLasso_files/figure-html/unnamed-chunk-13-1.png" width="500"></p>
<p>And, as with <code>ptLasso</code>, we can <code>predict</code>. By
default, <code>predict</code> uses the <span class="math inline">\(\alpha\)</span> that minimized the cross validated
MSE.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">cvfit</span>, <span class="va">xtest</span>, groupstest<span class="op">=</span><span class="va">groupstest</span>, ytest<span class="op">=</span><span class="va">ytest</span><span class="op">)</span></span>
<span><span class="va">preds</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.cv.ptLasso(object = cvfit, xtest = xtest, groupstest = groupstest,  </span></span>
<span><span class="co">#&gt;     ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0.4 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (Mean squared error):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            allGroups  mean group_1 group_2 group_3 group_4 group_5    r^2</span></span>
<span><span class="co">#&gt; Overall        757.1 757.1   815.7   542.6   567.1   792.7  1067.5 0.5362</span></span>
<span><span class="co">#&gt; Pretrain       511.1 511.1   579.7   460.1   547.5   502.9   465.6 0.6869</span></span>
<span><span class="co">#&gt; Individual     527.9 527.9   563.5   441.8   567.2   548.0   518.9 0.6766</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                          </span></span>
<span><span class="co">#&gt; Overall    50                            </span></span>
<span><span class="co">#&gt; Pretrain   86 (29 common + 57 individual)</span></span>
<span><span class="co">#&gt; Individual 109</span></span></code></pre></div>
<p>We could instead use the argument <code>alphatype = "varying"</code>
to use a different <span class="math inline">\(\alpha\)</span> for each
group – we choose the <span class="math inline">\(\alpha\)</span> that
minimizes the CV MSE for each group:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">cvfit</span>, <span class="va">xtest</span>, groupstest<span class="op">=</span><span class="va">groupstest</span>, ytest<span class="op">=</span><span class="va">ytest</span>, </span>
<span>                alphatype<span class="op">=</span><span class="st">"varying"</span><span class="op">)</span></span>
<span><span class="va">preds</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.cv.ptLasso(object = cvfit, xtest = xtest, groupstest = groupstest,  </span></span>
<span><span class="co">#&gt;     ytest = ytest, alphatype = "varying") </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha:</span></span>
<span><span class="co">#&gt; group_1 group_2 group_3 group_4 group_5 </span></span>
<span><span class="co">#&gt;     0.7     0.4     0.0     0.8     0.8 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (Mean squared error):</span></span>
<span><span class="co">#&gt;            overall  mean wtdMean group_1 group_2 group_3 group_4 group_5</span></span>
<span><span class="co">#&gt; Overall      757.1 757.1   757.1   815.7   542.6   567.1   792.7  1067.5</span></span>
<span><span class="co">#&gt; Pretrain     505.0 505.0   505.0   502.6   460.1   542.4   537.9   481.8</span></span>
<span><span class="co">#&gt; Individual   527.9 527.9   527.9   563.5   441.8   567.2   548.0   518.9</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                           </span></span>
<span><span class="co">#&gt; Overall    50                             </span></span>
<span><span class="co">#&gt; Pretrain   103 (29 common + 74 individual)</span></span>
<span><span class="co">#&gt; Individual 109</span></span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="other-details">Other details<a class="anchor" aria-label="anchor" href="#other-details"></a>
</h2>
<div class="section level3">
<h3 id="choosing-alpha-the-pretraining-parameter">Choosing <span class="math inline">\(\alpha\)</span>, the
pretraining parameter<a class="anchor" aria-label="anchor" href="#choosing-alpha-the-pretraining-parameter"></a>
</h3>
<p>Selecting the parameter <span class="math inline">\(\alpha\)</span>
is an important part of pretraining. The simplest way to do this is to
use <code>cv.ptLasso</code> – this will automatically perform
pretraining for a range of <span class="math inline">\(\alpha\)</span>
values and return the CV performance for each. The default values for
<span class="math inline">\(\alpha\)</span> are <span class="math inline">\(0, 0.1, 0.2, \dots, 1\)</span>.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cvfit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cv.ptLasso.html">cv.ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span><span class="op">)</span></span>
<span><span class="va">cvfit</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; cv.ptLasso(x = x, y = y, groups = groups, family = "gaussian",  </span></span>
<span><span class="co">#&gt;     type.measure = "mse", use.case = "inputGroups", group.intercepts = TRUE) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; type.measure:  mse </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            alpha overall  mean wtdMean group_1 group_2 group_3 group_4 group_5</span></span>
<span><span class="co">#&gt; Overall            699.7 699.7   699.7   748.4   501.9   575.6   663.0  1009.9</span></span>
<span><span class="co">#&gt; Pretrain     0.0   518.6 518.6   518.6   470.1   471.5   547.0   540.7   563.7</span></span>
<span><span class="co">#&gt; Pretrain     0.1   506.0 506.0   506.0   429.7   452.1   538.7   551.1   558.3</span></span>
<span><span class="co">#&gt; Pretrain     0.2   495.3 495.3   495.3   393.6   460.6   565.5   530.9   526.1</span></span>
<span><span class="co">#&gt; Pretrain     0.3   490.4 490.4   490.4   390.4   436.5   546.3   511.6   567.4</span></span>
<span><span class="co">#&gt; Pretrain     0.4   487.5 487.5   487.5   383.7   438.8   545.6   509.4   560.3</span></span>
<span><span class="co">#&gt; Pretrain     0.5   481.2 481.2   481.2   364.9   429.7   548.5   513.4   549.7</span></span>
<span><span class="co">#&gt; Pretrain     0.6   504.1 504.1   504.1   393.1   460.0   586.4   531.9   549.0</span></span>
<span><span class="co">#&gt; Pretrain     0.7   511.5 511.5   511.5   393.2   462.7   584.3   492.9   624.3</span></span>
<span><span class="co">#&gt; Pretrain     0.8   509.1 509.1   509.1   382.4   496.2   597.9   503.4   565.6</span></span>
<span><span class="co">#&gt; Pretrain     0.9   501.5 501.5   501.5   404.0   481.6   581.9   488.3   552.0</span></span>
<span><span class="co">#&gt; Pretrain     1.0   517.1 517.1   517.1   409.1   488.9   612.7   484.7   590.1</span></span>
<span><span class="co">#&gt; Individual         517.1 517.1   517.1   409.1   488.9   612.7   484.7   590.1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alphahat (fixed) = 0.5</span></span>
<span><span class="co">#&gt; alphahat (varying):</span></span>
<span><span class="co">#&gt; group_1 group_2 group_3 group_4 group_5 </span></span>
<span><span class="co">#&gt;     0.5     0.5     0.1     1.0     0.2</span></span></code></pre></div>
<p>Of course, you can specify the values of <span class="math inline">\(\alpha\)</span> to consider:</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cvfit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cv.ptLasso.html">cv.ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, alphalist <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.5</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">cvfit</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; cv.ptLasso(x = x, y = y, groups = groups, alphalist = c(0, 0.5,  </span></span>
<span><span class="co">#&gt;     1), family = "gaussian", type.measure = "mse", use.case = "inputGroups",  </span></span>
<span><span class="co">#&gt;     group.intercepts = TRUE) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; type.measure:  mse </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            alpha overall  mean wtdMean group_1 group_2 group_3 group_4 group_5</span></span>
<span><span class="co">#&gt; Overall            708.8 708.8   708.8   739.0   514.4   575.4   665.0  1050.1</span></span>
<span><span class="co">#&gt; Pretrain     0.0   524.4 524.4   524.4   481.7   485.7   529.4   526.8   598.4</span></span>
<span><span class="co">#&gt; Pretrain     0.5   496.3 496.3   496.3   365.0   448.5   569.3   507.5   591.1</span></span>
<span><span class="co">#&gt; Pretrain     1.0   526.4 526.4   526.4   399.4   513.5   611.8   492.9   614.6</span></span>
<span><span class="co">#&gt; Individual         526.4 526.4   526.4   399.4   513.5   611.8   492.9   614.6</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alphahat (fixed) = 0.5</span></span>
<span><span class="co">#&gt; alphahat (varying):</span></span>
<span><span class="co">#&gt; group_1 group_2 group_3 group_4 group_5 </span></span>
<span><span class="co">#&gt;     0.5     0.5     0.0     1.0     0.5</span></span></code></pre></div>
<p>At prediction time, <code>cv.ptLasso</code> uses the <span class="math inline">\(\alpha\)</span> that had the best CV performance
on average across all groups. We could instead choose to use a different
<span class="math inline">\(\alpha\)</span> for each group, as
<code>cv.ptLasso</code> already figured out which <span class="math inline">\(\alpha\)</span> optimizes the CV performance for
each group. To use group-specific values of <span class="math inline">\(\alpha\)</span>, specify
<code>alphatype = "varying"</code> at prediction time. In this example,
the best group-specific <span class="math inline">\(\alpha\)</span>
values all happen to be <span class="math inline">\(0.5\)</span> – the
same as the overall <span class="math inline">\(\alpha\)</span>.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">###############################################</span></span>
<span><span class="co"># Common alpha for all groups:</span></span>
<span><span class="co">###############################################</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">cvfit</span>, <span class="va">xtest</span>, <span class="va">groupstest</span>, ytest<span class="op">=</span><span class="va">ytest</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.cv.ptLasso(object = cvfit, xtest = xtest, groupstest = groupstest,  </span></span>
<span><span class="co">#&gt;     ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0.5 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (Mean squared error):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            allGroups  mean group_1 group_2 group_3 group_4 group_5    r^2</span></span>
<span><span class="co">#&gt; Overall        757.1 757.1   815.7   542.6   567.1   792.7  1067.5 0.5362</span></span>
<span><span class="co">#&gt; Pretrain       507.0 507.0   556.6   446.3   556.6   504.1   471.4 0.6894</span></span>
<span><span class="co">#&gt; Individual     527.9 527.9   572.6   443.2   562.4   550.5   510.7 0.6766</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                          </span></span>
<span><span class="co">#&gt; Overall    50                            </span></span>
<span><span class="co">#&gt; Pretrain   95 (25 common + 70 individual)</span></span>
<span><span class="co">#&gt; Individual 110</span></span></code></pre></div>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co">###############################################</span></span>
<span><span class="co"># Different alpha for each group:</span></span>
<span><span class="co">###############################################</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">cvfit</span>, <span class="va">xtest</span>, <span class="va">groupstest</span>, ytest<span class="op">=</span><span class="va">ytest</span>, alphatype <span class="op">=</span> <span class="st">"varying"</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.cv.ptLasso(object = cvfit, xtest = xtest, groupstest = groupstest,  </span></span>
<span><span class="co">#&gt;     ytest = ytest, alphatype = "varying") </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha:</span></span>
<span><span class="co">#&gt; group_1 group_2 group_3 group_4 group_5 </span></span>
<span><span class="co">#&gt;     0.5     0.5     0.0     1.0     0.5 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (Mean squared error):</span></span>
<span><span class="co">#&gt;            overall  mean wtdMean group_1 group_2 group_3 group_4 group_5</span></span>
<span><span class="co">#&gt; Overall      757.1 757.1   757.1   815.7   542.6   567.1   792.7  1067.5</span></span>
<span><span class="co">#&gt; Pretrain     517.3 517.3   517.3   556.6   446.3   561.5   550.5   471.4</span></span>
<span><span class="co">#&gt; Individual   527.9 527.9   527.9   572.6   443.2   562.4   550.5   510.7</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                          </span></span>
<span><span class="co">#&gt; Overall    50                            </span></span>
<span><span class="co">#&gt; Pretrain   99 (25 common + 74 individual)</span></span>
<span><span class="co">#&gt; Individual 110</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="choosing-lambda-the-lasso-path-parameter-for-the-first-stage-of-pretraining">Choosing <span class="math inline">\(\lambda\)</span>, the lasso
path parameter, for the first stage of pretraining<a class="anchor" aria-label="anchor" href="#choosing-lambda-the-lasso-path-parameter-for-the-first-stage-of-pretraining"></a>
</h3>
<p>The first step of pretraining fits the overall model with
<code>cv.glmnet</code> and selects a model along the <span class="math inline">\(\lambda\)</span> path. The second stage uses the
overall model’s support and predictions to train the group-specific
models.</p>
<p>At train time, we need to know choose a value of <span class="math inline">\(\lambda\)</span> to use for the first stage. This
can be specified in <code>ptLasso</code> with the argument
<code>overall.lambda</code>. The default value is “lambda.1se” – this
usually had slightly better performance in simulations and real data
examples than “lambda.min”. But this is easy to change:
<code>overall.lambda</code> can accept “lambda.1se” or “lambda.min” (as
in <code>predict.cv.glmnet</code>).</p>
<p>Whatever choice is made at train time will be automatically used at
test time, and this cannot be changed. The fitted model from the second
stage of pretraining expects the offset to have been computed using a
particular model – it does not make sense to compute the offset using a
model with a different <span class="math inline">\(\lambda\)</span>.</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Default:</span></span>
<span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>, overall.lambda <span class="op">=</span> <span class="st">"lambda.1se"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Alternative:</span></span>
<span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>, overall.lambda <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="fitting-elasticnet-or-ridge-models">Fitting elasticnet or ridge models<a class="anchor" aria-label="anchor" href="#fitting-elasticnet-or-ridge-models"></a>
</h3>
<p>By default, <code>ptLasso</code> fits lasso penalized models; in
<code>glmnet</code>, this corresponds to the elasticnet parameter <span class="math inline">\(\alpha_\text{en} = 1\)</span> (where the subscript
<code>en</code> stands for “elasticnet”). Fitting pretrained elasticnet
or ridge models is also possible with <code>ptLasso</code>: use argument
<code>en.alpha</code> between <span class="math inline">\(0\)</span>
(ridge) and <span class="math inline">\(1\)</span> (lasso). Here is an
example using the pretraining parameter <span class="math inline">\(\alpha = 0.5\)</span> and the elasticnet parameter
<code>en.alpha = 0.2</code>.</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, </span>
<span>               alpha <span class="op">=</span> <span class="fl">0.5</span>,    <span class="co"># pretraining parameter</span></span>
<span>               en.alpha <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span> <span class="co"># elasticnet parameter</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="printing-progress-during-model-training">Printing progress during model training<a class="anchor" aria-label="anchor" href="#printing-progress-during-model-training"></a>
</h3>
<p>When models take a long time to train, it can be useful to print out
progress during training. <code>ptLasso</code> has two ways to do this
(and they can be combined). First, we can simply print out which model
is being fitted using <code>verbose = TRUE</code>:</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>, verbose <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; Fitting overall model</span></span>
<span><span class="co">#&gt; Fitting individual models</span></span>
<span><span class="co">#&gt;  Fitting individual model 1 / 5</span></span>
<span><span class="co">#&gt;  Fitting individual model 2 / 5</span></span>
<span><span class="co">#&gt;  Fitting individual model 3 / 5</span></span>
<span><span class="co">#&gt;  Fitting individual model 4 / 5</span></span>
<span><span class="co">#&gt;  Fitting individual model 5 / 5</span></span>
<span><span class="co">#&gt; Fitting pretrained lasso models</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 1 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 2 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 3 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 4 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 5 / 5</span></span></code></pre></div>
<p>We can also print out a progress bar for <em>each model</em> that is
being fit – this functionality comes directly from
<code>cv.glmnet</code>, and follows its notation. (To avoid cluttering
this document, we do not run the following example.)</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>, trace.it <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<p>And of course, we can combine these to print out (1) which model is
being trained and (2) the corresponding progress bar.</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>, verbose <span class="op">=</span> <span class="cn">TRUE</span>, trace.it <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="using-individual-and-overall-models-that-were-previously-trained">Using individual and overall models that were previously
trained<a class="anchor" aria-label="anchor" href="#using-individual-and-overall-models-that-were-previously-trained"></a>
</h3>
<p><code>ptLasso</code> will fit the overall and individual models.
However, if you have already trained the overall or individual models,
you can save compute time by passing them directly to
<code>ptLasso</code> – they will not be refitted.
<strong><code>ptLasso</code> expects that these models were fitted using
the same training data that you pass to <code>ptLasso</code>, and that
they were fitted with the argument <code>keep = TRUE</code>.</strong>
Here is an example. We will fit an overall model and individual models,
and then we will show how to pass them to <code>ptLasso</code>. Using
<code>verbose = TRUE</code> in the call to <code>ptLasso</code> shows us
what models are being trained (and confirms that we are not refitting
the overall and individual models).</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">overall.model</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, keep <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">individual.models</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">lapply</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span>, </span>
<span>                           <span class="kw">function</span><span class="op">(</span><span class="va">kk</span><span class="op">)</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="va">kk</span>, <span class="op">]</span>, </span>
<span>                                                  <span class="va">y</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="va">kk</span><span class="op">]</span>, </span>
<span>                                                  keep <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, </span>
<span>               fitoverall <span class="op">=</span> <span class="va">overall.model</span>,</span>
<span>               fitind <span class="op">=</span> <span class="va">individual.models</span>,</span>
<span>               verbose <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; Fitting pretrained lasso models</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 1 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 2 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 3 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 4 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 5 / 5</span></span></code></pre></div>
<p>Of course we could pass just the overall <em>or</em> individual
models to `ptLasso:</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, fitoverall <span class="op">=</span> <span class="va">overall.model</span>, verbose <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; Fitting individual models</span></span>
<span><span class="co">#&gt;  Fitting individual model 1 / 5</span></span>
<span><span class="co">#&gt;  Fitting individual model 2 / 5</span></span>
<span><span class="co">#&gt;  Fitting individual model 3 / 5</span></span>
<span><span class="co">#&gt;  Fitting individual model 4 / 5</span></span>
<span><span class="co">#&gt;  Fitting individual model 5 / 5</span></span>
<span><span class="co">#&gt; Fitting pretrained lasso models</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 1 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 2 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 3 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 4 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 5 / 5</span></span></code></pre></div>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, fitind <span class="op">=</span> <span class="va">individual.models</span>, verbose <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; Fitting overall model</span></span>
<span><span class="co">#&gt; Fitting pretrained lasso models</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 1 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 2 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 3 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 4 / 5</span></span>
<span><span class="co">#&gt;  Fitting pretrained model 5 / 5</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="fitting-the-overall-model-without-group-specific-intercepts">Fitting the overall model without group-specific intercepts<a class="anchor" aria-label="anchor" href="#fitting-the-overall-model-without-group-specific-intercepts"></a>
</h3>
<p>When we fit the overall model with input grouped data, we solve the
following: <span class="math display">\[\begin{equation}
    \hat{\mu_0}, \hat{\theta_2}, \dots, \hat{\theta_K}, \hat{\beta_0} =
\arg \min_{\mu, \theta_2, \dots, \theta_k, \beta} \frac{1}{2}
\sum_{k=1}^K \| y_k - \left(\mu \mathbf{1} + \theta_k \mathbf{1} + X_k
\beta\right) \|_2^2 + \lambda ||\beta||_1,
\end{equation}\]</span> where <span class="math inline">\(\hat{\theta_1}\)</span> is defined to be <span class="math inline">\(0\)</span>. We can instead omit <span class="math inline">\(\theta_1, \dots, \theta_K\)</span> and instead fit
the following: <span class="math display">\[\begin{equation}
    \hat{\mu_0}, \hat{\beta_0} = \arg \min_{\mu, \beta} \frac{1}{2}
\sum_{k=1}^K \| y_k - \left(\mu \mathbf{1} + X_k \beta\right) \|_2^2 +
\lambda ||\beta||_1.
\end{equation}\]</span> This may be useful in settings where the groups
are different between train and test sets (see “Different groups in
train and test data” under “Input grouped data”). To do this, use the
argument <code>group.intercepts = FALSE</code>.</p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cvfit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cv.ptLasso.html">cv.ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, group.intercepts <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="va">cvfit</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; cv.ptLasso(x = x, y = y, groups = groups, group.intercepts = FALSE,  </span></span>
<span><span class="co">#&gt;     family = "gaussian", type.measure = "mse", use.case = "inputGroups") </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; type.measure:  mse </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            alpha overall  mean wtdMean group_1 group_2 group_3 group_4 group_5</span></span>
<span><span class="co">#&gt; Overall            695.7 695.7   695.7   709.7   495.0   576.7   676.0  1021.1</span></span>
<span><span class="co">#&gt; Pretrain     0.0   503.8 503.8   503.8   452.1   460.5   509.6   534.6   562.1</span></span>
<span><span class="co">#&gt; Pretrain     0.1   488.5 488.5   488.5   415.6   452.6   509.6   526.1   538.9</span></span>
<span><span class="co">#&gt; Pretrain     0.2   494.6 494.6   494.6   411.9   464.2   514.3   523.4   559.4</span></span>
<span><span class="co">#&gt; Pretrain     0.3   490.0 490.0   490.0   404.3   435.2   535.2   496.3   579.1</span></span>
<span><span class="co">#&gt; Pretrain     0.4   470.2 470.2   470.2   364.4   442.5   524.3   482.8   537.3</span></span>
<span><span class="co">#&gt; Pretrain     0.5   500.4 500.4   500.4   378.2   504.5   547.1   497.7   574.3</span></span>
<span><span class="co">#&gt; Pretrain     0.6   492.4 492.4   492.4   363.9   460.1   571.9   511.2   554.9</span></span>
<span><span class="co">#&gt; Pretrain     0.7   498.0 498.0   498.0   383.0   467.0   573.8   497.4   568.8</span></span>
<span><span class="co">#&gt; Pretrain     0.8   511.5 511.5   511.5   393.9   510.4   588.7   484.7   579.9</span></span>
<span><span class="co">#&gt; Pretrain     0.9   515.5 515.5   515.5   408.0   488.4   626.1   483.1   572.0</span></span>
<span><span class="co">#&gt; Pretrain     1.0   521.4 521.4   521.4   407.0   504.5   589.6   507.4   598.8</span></span>
<span><span class="co">#&gt; Individual         521.4 521.4   521.4   407.0   504.5   589.6   507.4   598.8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alphahat (fixed) = 0.4</span></span>
<span><span class="co">#&gt; alphahat (varying):</span></span>
<span><span class="co">#&gt; group_1 group_2 group_3 group_4 group_5 </span></span>
<span><span class="co">#&gt;     0.6     0.3     0.0     0.4     0.4</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="arguments-for-use-in-cv-glmnet">Arguments for use in <code>cv.glmnet</code><a class="anchor" aria-label="anchor" href="#arguments-for-use-in-cv-glmnet"></a>
</h3>
<p>Because model fitting is done with <code>cv.glmnet</code>,
<code>ptLasso</code> can take and pass arguments to
<code>cv.glmnet</code>. Notable choices include
<code>penalty.factor</code>, <code>weights</code>,
<code>upper.limits</code>, <code>lower.limits</code> and
<code>en.alpha</code> (known as <code>alpha</code> in
<code>glmnet</code>). Please refer to the <code>glmnet</code>
documentation for more information on their use.</p>
<p><code>ptLasso</code> does not support the arguments
<code>intercept</code>, <code>offset</code>, <code>fit</code> and
<code>check.args</code>.</p>
</div>
<div class="section level3">
<h3 id="parallelizing-model-fitting">Parallelizing model fitting<a class="anchor" aria-label="anchor" href="#parallelizing-model-fitting"></a>
</h3>
<p>For large datasets, we can parallelize model fitting within the calls
to <code>cv.glmnet</code>. As in <code>cv.glmnet</code>, pass the
argument <code>parallel = TRUE</code>, and register parallel
beforehand:</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va">doMC</span><span class="op">)</span></span>
<span><span class="fu">registerDoMC</span><span class="op">(</span>cores <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></span>
<span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, groups <span class="op">=</span> <span class="va">groups</span>, family <span class="op">=</span> <span class="st">"gaussian"</span>, type.measure <span class="op">=</span> <span class="st">"mse"</span>, </span>
<span>              parallel<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="input-grouped-data">Input grouped data<a class="anchor" aria-label="anchor" href="#input-grouped-data"></a>
</h2>
<div class="section level3">
<h3 id="base-case-input-grouped-data-with-a-binomial-outcome">Base case: input grouped data with a binomial outcome<a class="anchor" aria-label="anchor" href="#base-case-input-grouped-data-with-a-binomial-outcome"></a>
</h3>
<p>In the Quick Start, we applied <code>ptLasso</code> to data with a
continuous response. Here, we’ll use data with a binary outcome. This
creates a dataset with <span class="math inline">\(k = 3\)</span> groups
(each with <span class="math inline">\(100\)</span> observations), 5
shared coefficients, and 5 coefficients specific to each group.</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="va">out</span> <span class="op">=</span> <span class="fu"><a href="../reference/binomial.example.data.html">binomial.example.data</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="va">out</span><span class="op">$</span><span class="va">x</span>; <span class="va">y</span> <span class="op">=</span> <span class="va">out</span><span class="op">$</span><span class="va">y</span>; <span class="va">groups</span> <span class="op">=</span> <span class="va">out</span><span class="op">$</span><span class="va">groups</span></span>
<span></span>
<span><span class="va">outtest</span> <span class="op">=</span> <span class="fu"><a href="../reference/binomial.example.data.html">binomial.example.data</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">xtest</span> <span class="op">=</span> <span class="va">outtest</span><span class="op">$</span><span class="va">x</span>; <span class="va">ytest</span> <span class="op">=</span> <span class="va">outtest</span><span class="op">$</span><span class="va">y</span>; <span class="va">groupstest</span> <span class="op">=</span> <span class="va">outtest</span><span class="op">$</span><span class="va">groups</span></span></code></pre></div>
<p>We can fit and predict as before. By default,
<code>predict.ptLasso</code> will compute and return the
<em>deviance</em> on the test set.</p>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>, family <span class="op">=</span> <span class="st">"binomial"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">xtest</span>, <span class="va">groupstest</span>, ytest <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.ptLasso(object = fit, xtest = xtest, groupstest = groupstest,  </span></span>
<span><span class="co">#&gt;     ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0.5 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (Deviance):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            allGroups  mean wtdMean group_1 group_2 group_3</span></span>
<span><span class="co">#&gt; Overall        1.359 1.359   1.359   1.334   1.321   1.421</span></span>
<span><span class="co">#&gt; Pretrain       1.279 1.279   1.279   1.272   1.169   1.397</span></span>
<span><span class="co">#&gt; Individual     1.283 1.283   1.283   1.265   1.186   1.399</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                        </span></span>
<span><span class="co">#&gt; Overall    7                           </span></span>
<span><span class="co">#&gt; Pretrain   12 (3 common + 9 individual)</span></span>
<span><span class="co">#&gt; Individual 20</span></span></code></pre></div>
<p>We could instead compute the AUC by specifying the
<code>type.measure</code> in the call to <code>ptLasso</code>. Note:
<code>type.measure</code> is specified during model fitting and not
prediction because it is used in each call to
<code>cv.glmnet</code>.</p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>, family <span class="op">=</span> <span class="st">"binomial"</span>, </span>
<span>              type.measure <span class="op">=</span> <span class="st">"auc"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">xtest</span>, <span class="va">groupstest</span>, ytest <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.ptLasso(object = fit, xtest = xtest, groupstest = groupstest,  </span></span>
<span><span class="co">#&gt;     ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0.5 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (AUC):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            allGroups   mean wtdMean group_1 group_2 group_3</span></span>
<span><span class="co">#&gt; Overall       0.6026 0.6039  0.6039  0.6161  0.6877  0.5080</span></span>
<span><span class="co">#&gt; Pretrain      0.6407 0.6524  0.6524  0.6936  0.7447  0.5190</span></span>
<span><span class="co">#&gt; Individual    0.6442 0.6618  0.6618  0.6936  0.7732  0.5186</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                         </span></span>
<span><span class="co">#&gt; Overall    15                           </span></span>
<span><span class="co">#&gt; Pretrain   39 (3 common + 36 individual)</span></span>
<span><span class="co">#&gt; Individual 40</span></span></code></pre></div>
<p>To fit the overall and individual models, we can use elasticnet
instead of lasso by defining the parameter <code>en.alpha</code>. (as in
<code>glmnet</code> and described in the section “Fitting elasticnet or
ridge models”).</p>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>, family <span class="op">=</span> <span class="st">"binomial"</span>, </span>
<span>              type.measure <span class="op">=</span> <span class="st">"auc"</span>, </span>
<span>              en.alpha <span class="op">=</span> <span class="fl">.5</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">xtest</span>, <span class="va">groupstest</span>, ytest <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.ptLasso(object = fit, xtest = xtest, groupstest = groupstest,  </span></span>
<span><span class="co">#&gt;     ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0.5 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (AUC):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            allGroups   mean wtdMean group_1 group_2 group_3</span></span>
<span><span class="co">#&gt; Overall       0.6041 0.6018  0.6018  0.5928  0.6704  0.5422</span></span>
<span><span class="co">#&gt; Pretrain      0.6270 0.6547  0.6547  0.6781  0.7720  0.5141</span></span>
<span><span class="co">#&gt; Individual    0.6387 0.6598  0.6598  0.6756  0.7820  0.5218</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                         </span></span>
<span><span class="co">#&gt; Overall    3                            </span></span>
<span><span class="co">#&gt; Pretrain   39 (3 common + 36 individual)</span></span>
<span><span class="co">#&gt; Individual 36</span></span></code></pre></div>
<p>Using cross validation is the same as in the Gaussian case:</p>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##################################################</span></span>
<span><span class="co"># Fit:</span></span>
<span><span class="co">##################################################</span></span>
<span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/cv.ptLasso.html">cv.ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, family <span class="op">=</span> <span class="st">"binomial"</span>, type.measure <span class="op">=</span> <span class="st">"auc"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Warning: from glmnet C++ code (error code -100); Convergence for 100th lambda</span></span>
<span><span class="co">#&gt; value not reached after maxit=100000 iterations; solutions for larger lambdas</span></span>
<span><span class="co">#&gt; returned</span></span>
<span><span class="co">#&gt; Warning: from glmnet C++ code (error code -100); Convergence for 100th lambda</span></span>
<span><span class="co">#&gt; value not reached after maxit=100000 iterations; solutions for larger lambdas</span></span>
<span><span class="co">#&gt; returned</span></span>
<span><span class="co">#&gt; Warning: from glmnet C++ code (error code -92); Convergence for 92th lambda</span></span>
<span><span class="co">#&gt; value not reached after maxit=100000 iterations; solutions for larger lambdas</span></span>
<span><span class="co">#&gt; returned</span></span>
<span><span class="co">#&gt; Warning: from glmnet C++ code (error code -90); Convergence for 90th lambda</span></span>
<span><span class="co">#&gt; value not reached after maxit=100000 iterations; solutions for larger lambdas</span></span>
<span><span class="co">#&gt; returned</span></span></code></pre></div>
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co">##################################################</span></span>
<span><span class="co"># Predict with a common alpha for all groups:</span></span>
<span><span class="co">##################################################</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">xtest</span>, <span class="va">groupstest</span>, ytest <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.cv.ptLasso(object = fit, xtest = xtest, groupstest = groupstest,  </span></span>
<span><span class="co">#&gt;     ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0.7 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (AUC):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            allGroups   mean wtdMean group_1 group_2 group_3</span></span>
<span><span class="co">#&gt; Overall       0.5990 0.5960  0.5960  0.6030  0.6644  0.5206</span></span>
<span><span class="co">#&gt; Pretrain      0.6401 0.6640  0.6640  0.6965  0.7732  0.5222</span></span>
<span><span class="co">#&gt; Individual    0.6559 0.6707  0.6707  0.6936  0.7808  0.5377</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                         </span></span>
<span><span class="co">#&gt; Overall    7                            </span></span>
<span><span class="co">#&gt; Pretrain   40 (3 common + 37 individual)</span></span>
<span><span class="co">#&gt; Individual 37</span></span></code></pre></div>
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co">##################################################</span></span>
<span><span class="co"># Predict with a different alpha for each group:</span></span>
<span><span class="co">##################################################</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">xtest</span>, <span class="va">groupstest</span>, ytest <span class="op">=</span> <span class="va">ytest</span>, alphatype <span class="op">=</span> <span class="st">"varying"</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.cv.ptLasso(object = fit, xtest = xtest, groupstest = groupstest,  </span></span>
<span><span class="co">#&gt;     ytest = ytest, alphatype = "varying") </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha:</span></span>
<span><span class="co">#&gt; group_1 group_2 group_3 </span></span>
<span><span class="co">#&gt;     0.2     0.5     0.2 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (AUC):</span></span>
<span><span class="co">#&gt;            overall   mean wtdMean group_1 group_2 group_3</span></span>
<span><span class="co">#&gt; Overall     0.5990 0.5960  0.5960  0.6030  0.6644  0.5206</span></span>
<span><span class="co">#&gt; Pretrain    0.6359 0.6573  0.6573  0.6838  0.7736  0.5145</span></span>
<span><span class="co">#&gt; Individual  0.6559 0.6707  0.6707  0.6936  0.7808  0.5377</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                         </span></span>
<span><span class="co">#&gt; Overall    7                            </span></span>
<span><span class="co">#&gt; Pretrain   40 (3 common + 37 individual)</span></span>
<span><span class="co">#&gt; Individual 37</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="base-case-input-grouped-survival-data">Base case: input grouped survival data<a class="anchor" aria-label="anchor" href="#base-case-input-grouped-survival-data"></a>
</h3>
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va"><a href="https://github.com/therneau/survival" class="external-link">survival</a></span><span class="op">)</span></span>
<span><span class="co">#&gt; Loading required package: survival</span></span></code></pre></div>
<p>Now, we will simulate survival times with 3 groups; the three groups
have overlapping support, with 5 shared features and each has 5
individual features. To compute survival time, we start by computing
<span class="math inline">\(\text{survival} = X \beta +
\epsilon\)</span>, where <span class="math inline">\(\beta\)</span> is
specific to each group and <span class="math inline">\(\epsilon\)</span>
is noise. Because survival times must be positive, we modify this to be
<span class="math inline">\(\text{survival} = \text{survival} + 1.1 *
\text{abs}(\text{min}(\text{survival}))\)</span>.</p>
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">600</span>; <span class="va">ntrain</span> <span class="op">=</span> <span class="fl">300</span></span>
<span><span class="va">p</span> <span class="op">=</span> <span class="fl">50</span></span>
<span>     </span>
<span><span class="va">x</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">*</span><span class="va">p</span><span class="op">)</span>, <span class="va">n</span>, <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">beta1</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">5</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">5</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">beta2</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">p</span><span class="op">)</span> <span class="op">*</span> <span class="va">beta1</span> <span class="co"># Shared support</span></span>
<span><span class="va">beta2</span> <span class="op">=</span> <span class="va">beta2</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">5</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">5</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">10</span><span class="op">)</span><span class="op">)</span> <span class="co"># Individual features</span></span>
<span></span>
<span><span class="va">beta3</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">p</span><span class="op">)</span> <span class="op">*</span> <span class="va">beta1</span> <span class="co"># Shared support</span></span>
<span><span class="va">beta3</span> <span class="op">=</span> <span class="va">beta3</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">5</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">15</span><span class="op">)</span><span class="op">)</span> <span class="co"># Individual features</span></span>
<span></span>
<span><span class="co"># Randomly split into groups</span></span>
<span><span class="va">groups</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, <span class="va">n</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compute survival times:</span></span>
<span><span class="va">survival</span> <span class="op">=</span> <span class="va">x</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta1</span></span>
<span><span class="va">survival</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">2</span><span class="op">]</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">2</span>, <span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta2</span></span>
<span><span class="va">survival</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">3</span><span class="op">]</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">3</span>, <span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta3</span></span>
<span><span class="va">survival</span> <span class="op">=</span> <span class="va">survival</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span><span class="va">survival</span> <span class="op">=</span> <span class="va">survival</span> <span class="op">+</span> <span class="fl">1.1</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">abs</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">min</a></span><span class="op">(</span><span class="va">survival</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Censoring times from a random uniform distribution:</span></span>
<span><span class="va">censoring</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">n</span>, min <span class="op">=</span> <span class="fl">1</span>, max <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Did we observe surivival or censoring?</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/survival/man/Surv.html" class="external-link">Surv</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">pmin</a></span><span class="op">(</span><span class="va">survival</span>, <span class="va">censoring</span><span class="op">)</span>, <span class="va">survival</span> <span class="op">&lt;=</span> <span class="va">censoring</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Split into train and test:</span></span>
<span><span class="va">xtest</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">300</span><span class="op">)</span>, <span class="op">]</span></span>
<span><span class="va">ytest</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">300</span><span class="op">)</span>, <span class="op">]</span></span>
<span><span class="va">groupstest</span> <span class="op">=</span> <span class="va">groups</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">300</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">300</span>, <span class="op">]</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">300</span>, <span class="op">]</span></span>
<span><span class="va">groups</span> <span class="op">=</span> <span class="va">groups</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">300</span><span class="op">]</span></span></code></pre></div>
<p>Training with <code>ptLasso</code> is much the same as it was for the
continuous and binomial cases; the only difference is that we specify
<code>family = "cox"</code>. By default, <code>ptLasso</code> uses the
partial likelihood for model selection. We could instead use the C
index.</p>
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">############################################################</span></span>
<span><span class="co"># Default -- use partial likelihood as the type.measure:</span></span>
<span><span class="co">############################################################</span></span>
<span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>, family <span class="op">=</span> <span class="st">"cox"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">xtest</span>, <span class="va">groupstest</span>, ytest <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.ptLasso(object = fit, xtest = xtest, groupstest = groupstest,  </span></span>
<span><span class="co">#&gt;     ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0.5 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (Deviance):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            allGroups  mean wtdMean group_1 group_2 group_3</span></span>
<span><span class="co">#&gt; Overall        381.2 87.60   89.36   99.49  106.53   56.79</span></span>
<span><span class="co">#&gt; Pretrain       396.3 87.86   88.66   93.31   96.54   73.72</span></span>
<span><span class="co">#&gt; Individual     425.2 99.07   99.54  111.68  101.85   83.67</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                         </span></span>
<span><span class="co">#&gt; Overall    10                           </span></span>
<span><span class="co">#&gt; Pretrain   20 (4 common + 16 individual)</span></span>
<span><span class="co">#&gt; Individual 24</span></span></code></pre></div>
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co">############################################################</span></span>
<span><span class="co"># Alternatively -- use the C index:</span></span>
<span><span class="co">############################################################</span></span>
<span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>, family <span class="op">=</span> <span class="st">"cox"</span>, type.measure <span class="op">=</span> <span class="st">"C"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Warning: from glmnet C++ code (error code -30075); Numerical error at 75th</span></span>
<span><span class="co">#&gt; lambda value; solutions for larger values of lambda returned</span></span></code></pre></div>
<div class="sourceCode" id="cb41"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">xtest</span>, <span class="va">groupstest</span>, ytest <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.ptLasso(object = fit, xtest = xtest, groupstest = groupstest,  </span></span>
<span><span class="co">#&gt;     ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0.5 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (C-index):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            allGroups   mean wtdMean group_1 group_2 group_3</span></span>
<span><span class="co">#&gt; Overall       0.8545 0.8673  0.8608  0.9139  0.7746  0.9133</span></span>
<span><span class="co">#&gt; Pretrain      0.8359 0.8396  0.8393  0.9152  0.8173  0.7864</span></span>
<span><span class="co">#&gt; Individual    0.7925 0.7985  0.8008  0.9075  0.8007  0.6873</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                         </span></span>
<span><span class="co">#&gt; Overall    6                            </span></span>
<span><span class="co">#&gt; Pretrain   35 (4 common + 31 individual)</span></span>
<span><span class="co">#&gt; Individual 37</span></span></code></pre></div>
<p>The call to <code>cv.ptLasso</code> is again much the same; we only
need to specify <code>family</code> (“cox”) and
<code>type.measure</code> (if we want to use the C index instead of the
partial likelihood).</p>
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##################################################</span></span>
<span><span class="co"># Fit:</span></span>
<span><span class="co">##################################################</span></span>
<span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/cv.ptLasso.html">cv.ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">groups</span>, family <span class="op">=</span> <span class="st">"cox"</span>, type.measure <span class="op">=</span> <span class="st">"C"</span><span class="op">)</span></span>
<span></span>
<span><span class="co">##################################################</span></span>
<span><span class="co"># Predict with a common alpha for all groups:</span></span>
<span><span class="co">##################################################</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">xtest</span>, <span class="va">groupstest</span>, ytest <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.cv.ptLasso(object = fit, xtest = xtest, groupstest = groupstest,  </span></span>
<span><span class="co">#&gt;     ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0.2 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (C-index):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            allGroups   mean wtdMean group_1 group_2 group_3</span></span>
<span><span class="co">#&gt; Overall       0.8527 0.8652  0.8586  0.9113  0.7711  0.9133</span></span>
<span><span class="co">#&gt; Pretrain      0.8501 0.8795  0.8742  0.9177  0.8043  0.9164</span></span>
<span><span class="co">#&gt; Individual    0.7865 0.8005  0.8033  0.9126  0.8078  0.6811</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                        </span></span>
<span><span class="co">#&gt; Overall    8                           </span></span>
<span><span class="co">#&gt; Pretrain   13 (4 common + 9 individual)</span></span>
<span><span class="co">#&gt; Individual 31</span></span></code></pre></div>
<div class="sourceCode" id="cb43"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co">##################################################</span></span>
<span><span class="co"># Predict with a different alpha for each group:</span></span>
<span><span class="co">##################################################</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">xtest</span>, <span class="va">groupstest</span>, ytest <span class="op">=</span> <span class="va">ytest</span>, alphatype <span class="op">=</span> <span class="st">"varying"</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.cv.ptLasso(object = fit, xtest = xtest, groupstest = groupstest,  </span></span>
<span><span class="co">#&gt;     ytest = ytest, alphatype = "varying") </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha:</span></span>
<span><span class="co">#&gt; group_1 group_2 group_3 </span></span>
<span><span class="co">#&gt;     0.3     0.4     0.4 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (C-index):</span></span>
<span><span class="co">#&gt;            overall   mean wtdMean group_1 group_2 group_3</span></span>
<span><span class="co">#&gt; Overall     0.8527 0.8652  0.8586  0.9113  0.7711  0.9133</span></span>
<span><span class="co">#&gt; Pretrain    0.8081 0.8493  0.8475  0.9229  0.8078  0.8173</span></span>
<span><span class="co">#&gt; Individual  0.7865 0.8005  0.8033  0.9126  0.8078  0.6811</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                         </span></span>
<span><span class="co">#&gt; Overall    8                            </span></span>
<span><span class="co">#&gt; Pretrain   28 (4 common + 24 individual)</span></span>
<span><span class="co">#&gt; Individual 31</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="different-groups-in-train-and-test-data">Different groups in train and test data<a class="anchor" aria-label="anchor" href="#different-groups-in-train-and-test-data"></a>
</h3>
<p>Suppose we observe groups at test time that were unobserved at train
time. For example, our training set may consist of <span class="math inline">\(K\)</span> <em>people</em> – each with many
observations – and at test time, we wish to make predictions for
observations from new people. We can still use pretraining in this
setting: train a model using all data, and use this to guide the
training for person-specific models.</p>
<p>Now however, we also fit an extra model to predict the similarity of
test observations to the observations from each of the <em>training
people</em>. To train this model, we use the (training) observation
matrix <span class="math inline">\(X\)</span> and the response <span class="math inline">\(y_{\text{sim}}\)</span>, where <span class="math inline">\(y_{\text{sim}} = k\)</span> for all observations
from the <span class="math inline">\(k^\text{th}\)</span> person. When
used for prediction, this model gives us a similarity (or probability)
vector of length <span class="math inline">\(K\)</span> that sums to 1,
describing how similar an observation is to each training person.</p>
<p>At test time, we make predictions from (1) each pretrained
person-specific model and (2) the person-similarity model, and we
compute the weighted average of the pretrained predictions with respect
to the similarity vector. Here is an example using simulated data.</p>
<div class="sourceCode" id="cb44"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Start with 5 people, each with 300 observations and 200 features.</span></span>
<span><span class="co"># 3 people will be used for training, and 2 for testing.</span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">300</span><span class="op">*</span><span class="fl">5</span>; <span class="va">p</span> <span class="op">=</span> <span class="fl">200</span>;</span>
<span><span class="va">groups</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sort.html" class="external-link">sort</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span>, <span class="va">n</span><span class="op">/</span><span class="fl">5</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># We will have different coefficients for each of the 3 training people, </span></span>
<span><span class="co"># and the first 3 features are shared support.</span></span>
<span><span class="va">beta.group1</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>, <span class="fl">1</span>, <span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="fl">3</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">6</span><span class="op">)</span><span class="op">)</span>; </span>
<span><span class="va">beta.group2</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>, <span class="fl">1</span>, <span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">3</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="fl">3</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">9</span><span class="op">)</span><span class="op">)</span>; </span>
<span><span class="va">beta.group3</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>, <span class="fl">1</span>, <span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">6</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="fl">3</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">12</span><span class="op">)</span><span class="op">)</span>; </span>
<span></span>
<span><span class="co"># The two test people are each a combination of of the training people.</span></span>
<span><span class="co"># Person 4 will have observations drawn from classes 1 and 2, and</span></span>
<span><span class="co"># Person 5 will have observations drawn from classes 1 and 3.</span></span>
<span><span class="co"># The vector "hidden groups" is a latent variable - used to simulate data</span></span>
<span><span class="co"># but unobserved in real data.</span></span>
<span><span class="va">hidden.gps</span> <span class="op">=</span> <span class="va">groups</span></span>
<span><span class="va">hidden.gps</span><span class="op">[</span><span class="va">hidden.gps</span> <span class="op">==</span> <span class="fl">4</span><span class="op">]</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">4</span><span class="op">)</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">hidden.gps</span><span class="op">[</span><span class="va">hidden.gps</span> <span class="op">==</span> <span class="fl">5</span><span class="op">]</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">5</span><span class="op">)</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># We modify X according to group membership;</span></span>
<span><span class="co"># we want X to cluster into groups 1, 2 and 3.</span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="va">n</span>, ncol <span class="op">=</span> <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">x</span><span class="op">[</span><span class="va">hidden.gps</span> <span class="op">==</span> <span class="fl">1</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">hidden.gps</span> <span class="op">==</span> <span class="fl">1</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span> <span class="op">+</span> <span class="fl">1</span></span>
<span><span class="va">x</span><span class="op">[</span><span class="va">hidden.gps</span> <span class="op">==</span> <span class="fl">2</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">hidden.gps</span> <span class="op">==</span> <span class="fl">2</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span> <span class="op">+</span> <span class="fl">2</span></span>
<span><span class="va">x</span><span class="op">[</span><span class="va">hidden.gps</span> <span class="op">==</span> <span class="fl">3</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">hidden.gps</span> <span class="op">==</span> <span class="fl">3</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span> <span class="op">+</span> <span class="fl">3</span></span>
<span></span>
<span><span class="co"># And now, we compute y using betas 1, 2 and 3: </span></span>
<span><span class="va">x.beta</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">n</span><span class="op">)</span></span>
<span><span class="va">x.beta</span><span class="op">[</span><span class="va">hidden.gps</span> <span class="op">==</span> <span class="fl">1</span><span class="op">]</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">hidden.gps</span> <span class="op">==</span> <span class="fl">1</span>, <span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta.group1</span> </span>
<span><span class="va">x.beta</span><span class="op">[</span><span class="va">hidden.gps</span> <span class="op">==</span> <span class="fl">2</span><span class="op">]</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">hidden.gps</span> <span class="op">==</span> <span class="fl">2</span>, <span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta.group2</span> </span>
<span><span class="va">x.beta</span><span class="op">[</span><span class="va">hidden.gps</span> <span class="op">==</span> <span class="fl">3</span><span class="op">]</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">hidden.gps</span> <span class="op">==</span> <span class="fl">3</span>, <span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta.group3</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">x.beta</span> <span class="op">+</span> <span class="fl">5</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span></code></pre></div>
<p>We’re ready to split into train, validation and test sets. We will
use people 1, 2 and 3 for training and validation (two-thirds train,
one-third validation), and people 4 and 5 for testing.</p>
<div class="sourceCode" id="cb45"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">trn.index</span> <span class="op">=</span> <span class="va">groups</span> <span class="op">&lt;</span> <span class="fl">4</span></span>
<span><span class="va">val.sample</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">trn.index</span><span class="op">)</span>, <span class="fl">1</span><span class="op">/</span><span class="fl">3</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">trn.index</span><span class="op">)</span>, replace <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span></span>
<span><span class="va">xtrain</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">trn.index</span>, <span class="op">]</span><span class="op">[</span><span class="op">-</span><span class="va">val.sample</span>, <span class="op">]</span></span>
<span><span class="va">ytrain</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="va">trn.index</span><span class="op">]</span><span class="op">[</span><span class="op">-</span><span class="va">val.sample</span><span class="op">]</span></span>
<span><span class="va">gpstrain</span> <span class="op">=</span> <span class="va">groups</span><span class="op">[</span><span class="va">trn.index</span><span class="op">]</span><span class="op">[</span><span class="op">-</span><span class="va">val.sample</span><span class="op">]</span></span>
<span></span>
<span><span class="va">xval</span>   <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">trn.index</span>, <span class="op">]</span><span class="op">[</span><span class="va">val.sample</span>, <span class="op">]</span> </span>
<span><span class="va">yval</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="va">trn.index</span><span class="op">]</span><span class="op">[</span><span class="va">val.sample</span><span class="op">]</span></span>
<span><span class="va">gpsval</span> <span class="op">=</span> <span class="va">groups</span><span class="op">[</span><span class="va">trn.index</span><span class="op">]</span><span class="op">[</span><span class="va">val.sample</span><span class="op">]</span></span>
<span></span>
<span><span class="va">xtest</span>  <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="op">!</span><span class="va">trn.index</span>, <span class="op">]</span></span>
<span><span class="va">ytest</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="op">!</span><span class="va">trn.index</span><span class="op">]</span></span>
<span><span class="va">gpstest</span> <span class="op">=</span> <span class="va">groups</span><span class="op">[</span><span class="op">!</span><span class="va">trn.index</span><span class="op">]</span></span></code></pre></div>
<p>We start with pretraining, where the person ID is the grouping
variable.</p>
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cvfit</span> <span class="op">=</span> <span class="fu"><a href="../reference/cv.ptLasso.html">cv.ptLasso</a></span><span class="op">(</span><span class="va">xtrain</span>, <span class="va">ytrain</span>, <span class="va">gpstrain</span>, </span>
<span>                   type.measure <span class="op">=</span> <span class="st">"mse"</span>, </span>
<span>                   group.intercepts <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>                   overall.lambda <span class="op">=</span> <span class="st">"lambda.1se"</span><span class="op">)</span></span></code></pre></div>
<p>Now, we train a model to predict the person ID from the covariates.
Because this example is simulated, we can measure the performance of our
model on test data (via the confusion matrix comparing predicted group
labels to true labels). In real settings, this would be impossible.</p>
<div class="sourceCode" id="cb47"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">simmod</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">xtrain</span>, <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">gpstrain</span><span class="op">)</span>, family <span class="op">=</span> <span class="st">"multinomial"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Peek at performance on test data.</span></span>
<span><span class="co"># Not possible with real data.</span></span>
<span><span class="va">class.preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">simmod</span>, <span class="va">xtest</span>, type<span class="op">=</span><span class="st">"response"</span><span class="op">)</span><span class="op">[</span>, , <span class="fl">1</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/table.html" class="external-link">table</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">class.preds</span>, <span class="fl">1</span>, <span class="va">which.max</span><span class="op">)</span>, </span>
<span>      <span class="va">hidden.gps</span><span class="op">[</span><span class="va">groups</span> <span class="op">&gt;=</span> <span class="fl">4</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="co">#&gt;    </span></span>
<span><span class="co">#&gt;       1   2   3</span></span>
<span><span class="co">#&gt;   1 260  37   3</span></span>
<span><span class="co">#&gt;   2  39  82  29</span></span>
<span><span class="co">#&gt;   3   0  36 114</span></span></code></pre></div>
<p>Finally we can make predictions: we have everything we need. For each
test observation, we will get the pretrained prediction for all 3
training classes. Our final predictions are the weighted combination of
the predictions from <code>ptLasso</code> and the class predictions from
<code>glmnet</code>.</p>
<div class="sourceCode" id="cb48"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">alphahat</span>  <span class="op">=</span> <span class="va">cvfit</span><span class="op">$</span><span class="va">alphahat</span></span>
<span><span class="va">bestmodel</span> <span class="op">=</span> <span class="va">cvfit</span><span class="op">$</span><span class="va">fit</span><span class="op">[[</span><span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="va">cvfit</span><span class="op">$</span><span class="va">alphalist</span> <span class="op">==</span> <span class="va">alphahat</span><span class="op">)</span><span class="op">]</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Chosen alpha is"</span>, <span class="va">alphahat</span>, <span class="st">".\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Chosen alpha is 0.5 .</span></span></code></pre></div>
<div class="sourceCode" id="cb49"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">offset</span> <span class="op">=</span> <span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">alphahat</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">bestmodel</span><span class="op">$</span><span class="va">fitoverall</span>, <span class="va">xtest</span>, s <span class="op">=</span> <span class="st">"lambda.1se"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Get the prediction for all three classes for each test observation. </span></span>
<span><span class="co"># This will be a matrix with three columns; one for each class.</span></span>
<span><span class="va">pretrained.preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/do.call.html" class="external-link">do.call</a></span><span class="op">(</span><span class="va">cbind</span>, </span>
<span>                        <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">lapply</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, </span>
<span>                               <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">bestmodel</span><span class="op">$</span><span class="va">fitpre</span><span class="op">[[</span><span class="va">i</span><span class="op">]</span><span class="op">]</span>, </span>
<span>                                                   <span class="va">xtest</span>,</span>
<span>                                                   newoffset <span class="op">=</span> <span class="va">offset</span><span class="op">)</span></span>
<span>                      <span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/colSums-methods.html" class="external-link">rowSums</a></span><span class="op">(</span><span class="va">pretrained.preds</span> <span class="op">*</span> <span class="va">class.preds</span><span class="op">)</span>, newy <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span><span class="op">$</span><span class="va">mse</span></span>
<span><span class="co">#&gt; [1] 28.17891</span></span>
<span><span class="co">#&gt; attr(,"measure")</span></span>
<span><span class="co">#&gt; [1] "Mean-Squared Error"</span></span></code></pre></div>
<p>There are two reasonable baselines. The first is the overall model
with no grouping at all, and the second is the set of individual models
(one for each group).</p>
<div class="sourceCode" id="cb50"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">########################################################</span></span>
<span><span class="co"># Baseline 1: overall model</span></span>
<span><span class="co">########################################################</span></span>
<span><span class="va">overall.predictions</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">cvfit</span><span class="op">$</span><span class="va">fitoverall</span>, <span class="va">xtest</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="va">overall.predictions</span>, newy <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span><span class="op">$</span><span class="va">mse</span></span>
<span><span class="co">#&gt; lambda.1se </span></span>
<span><span class="co">#&gt;   29.64747 </span></span>
<span><span class="co">#&gt; attr(,"measure")</span></span>
<span><span class="co">#&gt; [1] "Mean-Squared Error"</span></span></code></pre></div>
<div class="sourceCode" id="cb51"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co">########################################################</span></span>
<span><span class="co"># Baseline 2: individual models</span></span>
<span><span class="co">########################################################</span></span>
<span><span class="va">individual.preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/do.call.html" class="external-link">do.call</a></span><span class="op">(</span><span class="va">cbind</span>, </span>
<span>                           <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">lapply</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, </span>
<span>                                  <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">bestmodel</span><span class="op">$</span><span class="va">fitind</span><span class="op">[[</span><span class="va">i</span><span class="op">]</span><span class="op">]</span>, </span>
<span>                                                      <span class="va">xtest</span>,</span>
<span>                                                      type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span></span>
<span>                      <span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/colSums-methods.html" class="external-link">rowSums</a></span><span class="op">(</span><span class="va">individual.preds</span> <span class="op">*</span> <span class="va">class.preds</span><span class="op">)</span>, newy <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span><span class="op">$</span><span class="va">mse</span></span>
<span><span class="co">#&gt; [1] 29.17333</span></span>
<span><span class="co">#&gt; attr(,"measure")</span></span>
<span><span class="co">#&gt; [1] "Mean-Squared Error"</span></span></code></pre></div>
<p>What we have done – taking a weighted average of predictions with
respect to similarity to each person – makes sense mathematically.
However, we have found better empirical results if we instead train a
supervised learning algorithm to make the final prediction <span class="math inline">\(\hat{y}\)</span> using the pretrained model
predictions and the class similarity predictions as features. So, let’s
do that here, using our so-far-untouched validation set.</p>
<div class="sourceCode" id="cb52"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">val.offset</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">bestmodel</span><span class="op">$</span><span class="va">fitoverall</span>, <span class="va">xval</span>, s <span class="op">=</span> <span class="st">"lambda.1se"</span><span class="op">)</span></span>
<span><span class="va">val.offset</span> <span class="op">=</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">alphahat</span><span class="op">)</span> <span class="op">*</span> <span class="va">val.offset</span></span>
<span><span class="va">val.preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/do.call.html" class="external-link">do.call</a></span><span class="op">(</span><span class="va">cbind</span>, </span>
<span>                    <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">lapply</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">bestmodel</span><span class="op">$</span><span class="va">fitpre</span><span class="op">[[</span><span class="va">i</span><span class="op">]</span><span class="op">]</span>, </span>
<span>                                                    <span class="va">xval</span>,</span>
<span>                                                    newoffset <span class="op">=</span> <span class="va">val.offset</span>,</span>
<span>                                                    type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span></span>
<span>                      <span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="va">val.class.preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">simmod</span>, <span class="va">xval</span><span class="op">)</span><span class="op">[</span>, , <span class="fl">1</span><span class="op">]</span></span>
<span></span>
<span><span class="va">pred.data</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">val.preds</span>, <span class="va">val.class.preds</span>, <span class="va">val.preds</span> <span class="op">*</span> <span class="va">val.class.preds</span><span class="op">)</span> </span>
<span><span class="va">final.model</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">pred.data</span>, <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/colSums-methods.html" class="external-link">rowSums</a></span><span class="op">(</span><span class="va">val.preds</span> <span class="op">*</span> <span class="va">val.class.preds</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">pred.data.test</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">pretrained.preds</span>, </span>
<span>                       <span class="va">class.preds</span>, </span>
<span>                       <span class="va">pretrained.preds</span> <span class="op">*</span> <span class="va">class.preds</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">final.model</span>, <span class="va">pred.data.test</span><span class="op">)</span>, newy <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span><span class="op">$</span><span class="va">mse</span></span>
<span><span class="co">#&gt; lambda.1se </span></span>
<span><span class="co">#&gt;   28.28504 </span></span>
<span><span class="co">#&gt; attr(,"measure")</span></span>
<span><span class="co">#&gt; [1] "Mean-Squared Error"</span></span></code></pre></div>
<p>Comparing performance of all models side-by-side shows that (1) using
input groups improved performance – including for the individual models
and (2) including the final model did not help performance (but we still
recommend trying this with real data).</p>
<div class="sourceCode" id="cb53"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">rd</span> <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">x</span>, <span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Overall model PSE: "</span>, </span>
<span>    <span class="fu">rd</span><span class="op">(</span><span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="va">overall.predictions</span>, newy <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span><span class="op">$</span><span class="va">mse</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Overall model PSE:  29.65</span></span></code></pre></div>
<div class="sourceCode" id="cb54"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Individual model PSE: "</span>, </span>
<span>    <span class="fu">rd</span><span class="op">(</span><span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/colSums-methods.html" class="external-link">rowSums</a></span><span class="op">(</span><span class="va">individual.preds</span><span class="op">*</span><span class="va">class.preds</span><span class="op">)</span>, newy <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span><span class="op">$</span><span class="va">mse</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Individual model PSE:  29.17</span></span></code></pre></div>
<div class="sourceCode" id="cb55"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Pretraining model PSE: "</span>, </span>
<span>    <span class="fu">rd</span><span class="op">(</span><span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/colSums-methods.html" class="external-link">rowSums</a></span><span class="op">(</span><span class="va">pretrained.preds</span><span class="op">*</span><span class="va">class.preds</span><span class="op">)</span>, newy <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span><span class="op">$</span><span class="va">mse</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Pretraining model PSE:  28.18</span></span></code></pre></div>
<div class="sourceCode" id="cb56"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Pretraining model + final prediction model PSE: "</span>, </span>
<span>    <span class="fu">rd</span><span class="op">(</span><span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">final.model</span>, </span>
<span>                          <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">pretrained.preds</span>, </span>
<span>                                <span class="va">class.preds</span>, </span>
<span>                                <span class="va">pretrained.preds</span> <span class="op">*</span> <span class="va">class.preds</span><span class="op">)</span></span>
<span>                      <span class="op">)</span>, </span>
<span>              newy <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span><span class="op">$</span><span class="va">mse</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Pretraining model + final prediction model PSE:  28.29</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="learning-the-input-groups">Learning the input groups<a class="anchor" aria-label="anchor" href="#learning-the-input-groups"></a>
</h3>
<p>Suppose we have a dataset with features <span class="math inline">\(X\)</span> and response <span class="math inline">\(y\)</span>, and no input grouping. Suppose we also
have a small set of meaningful features <span class="math inline">\(Z\)</span> that we expect to stratify observations
(e.g. in biomedicine, <span class="math inline">\(Z\)</span> may consist
of age and sex). In this setting, we can <em>learn</em> input groups
using <span class="math inline">\(Z\)</span>.</p>
<p>The steps to do this are as follows.</p>
<ol style="list-style-type: decimal">
<li>Partition data into two sets: one to learn the grouping and one to
do pretraining.</li>
<li>With the first set, train a small CART tree using <span class="math inline">\(Z\)</span> and <span class="math inline">\(y\)</span>.</li>
<li>Make predictions for the remaining data; assign observations to
groups according to their terminal nodes.</li>
<li>Apply pretraining using the learned group assignments.</li>
</ol>
<p>Here, we show an example using simulated data. We use
<code>rpart</code> to train a CART tree. The package <code>ODRF</code>
(<span class="citation">Liu and Xia (2022)</span>) is another good
choice – it fits a linear model in each terminal node, which is closer
to what pretraining does, and may therefore have better performance.</p>
<div class="sourceCode" id="cb57"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va"><a href="https://github.com/bethatkinson/rpart" class="external-link">rpart</a></span><span class="op">)</span></span>
<span><span class="co">#&gt; Loading required package: rpart</span></span></code></pre></div>
<p>Simulate data with a binary outcome: <span class="math inline">\(X\)</span> is drawn from a random normal (with
<span class="math inline">\(p = 50\)</span> uncorrelated features), and
<span class="math inline">\(Z\)</span> is simulated as age (uniform
between 20 and 90) and sex (half 0, half 1). The <em>true</em> groups
are (1) age under 50, (2) age over 50 and sex = 0 and (3) age over 50
and sex = 1.</p>
<div class="sourceCode" id="cb58"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">1000</span>; <span class="va">p</span> <span class="op">=</span> <span class="fl">50</span></span>
<span><span class="va">groupvars</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span>age <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">n</span>, min <span class="op">=</span> <span class="fl">20</span>, max <span class="op">=</span> <span class="fl">90</span><span class="op">)</span><span class="op">)</span>, </span>
<span>                  sex <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>, <span class="va">n</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">groups</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">n</span><span class="op">)</span></span>
<span><span class="va">groups</span><span class="op">[</span><span class="va">groupvars</span><span class="op">[</span>, <span class="st">"age"</span><span class="op">]</span> <span class="op">&gt;</span> <span class="fl">50</span> <span class="op">&amp;</span> <span class="va">groupvars</span><span class="op">[</span>, <span class="st">"sex"</span><span class="op">]</span> <span class="op">==</span> <span class="fl">0</span><span class="op">]</span> <span class="op">=</span> <span class="fl">2</span></span>
<span><span class="va">groups</span><span class="op">[</span><span class="va">groupvars</span><span class="op">[</span>, <span class="st">"age"</span><span class="op">]</span> <span class="op">&gt;</span> <span class="fl">50</span> <span class="op">&amp;</span> <span class="va">groupvars</span><span class="op">[</span>, <span class="st">"sex"</span><span class="op">]</span> <span class="op">==</span> <span class="fl">1</span><span class="op">]</span> <span class="op">=</span> <span class="fl">3</span></span></code></pre></div>
<p>Now, we’ll define coefficients <span class="math inline">\(\beta_k\)</span> such that <span class="math inline">\(P(y_i = 1 \mid x_i) = \frac{1}{1 + \exp(-x_i^T
\beta_k)}\)</span> for each group. Across groups, three coefficients are
shared, three are group-specific and the rest are 0. Each group has a
unique intercept to adjust its baseline risk.</p>
<div class="sourceCode" id="cb59"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">beta.group1</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.1</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.2</span>, <span class="fl">0.3</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">6</span><span class="op">)</span><span class="op">)</span>; </span>
<span><span class="va">beta.group2</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.1</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">3</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.2</span>, <span class="fl">0.3</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">9</span><span class="op">)</span><span class="op">)</span>; </span>
<span><span class="va">beta.group3</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.1</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">6</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.2</span>, <span class="fl">0.3</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">12</span><span class="op">)</span><span class="op">)</span>; </span>
<span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="va">n</span>, ncol <span class="op">=</span> <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">x.beta</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">n</span><span class="op">)</span></span>
<span><span class="va">x.beta</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">1</span><span class="op">]</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">1</span>, <span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta.group1</span> <span class="op">-</span> <span class="fl">0.75</span></span>
<span><span class="va">x.beta</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">2</span><span class="op">]</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">2</span>, <span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta.group2</span> </span>
<span><span class="va">x.beta</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">3</span><span class="op">]</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">3</span>, <span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta.group3</span> <span class="op">+</span> <span class="fl">0.75</span></span>
<span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html" class="external-link">rbinom</a></span><span class="op">(</span><span class="va">n</span>, size <span class="op">=</span> <span class="fl">1</span>, prob <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="op">-</span><span class="va">x.beta</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Now that we have our data, we will partition it into 3 datasets: </span></span>
<span><span class="co"># one to cluster, one to train models and one to test performance.</span></span>
<span><span class="va">xcluster</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">250</span>, <span class="op">]</span>; <span class="va">xtrain</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="fl">251</span><span class="op">:</span><span class="fl">750</span>, <span class="op">]</span>; <span class="va">xtest</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="fl">751</span><span class="op">:</span><span class="fl">1000</span>, <span class="op">]</span>;</span>
<span><span class="va">ycluster</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">250</span><span class="op">]</span>;   <span class="va">ytrain</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="fl">251</span><span class="op">:</span><span class="fl">750</span><span class="op">]</span>;   <span class="va">ytest</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="fl">751</span><span class="op">:</span><span class="fl">1000</span><span class="op">]</span>;</span>
<span></span>
<span><span class="va">zcluster</span> <span class="op">=</span> <span class="va">groupvars</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">250</span>, <span class="op">]</span>; </span>
<span><span class="va">ztrain</span> <span class="op">=</span> <span class="va">groupvars</span><span class="op">[</span><span class="fl">251</span><span class="op">:</span><span class="fl">750</span>, <span class="op">]</span>; </span>
<span><span class="va">ztest</span> <span class="op">=</span> <span class="va">groupvars</span><span class="op">[</span><span class="fl">751</span><span class="op">:</span><span class="fl">1000</span>, <span class="op">]</span>;</span>
<span></span>
<span><span class="co"># We will use this just to see how our clustering performed.</span></span>
<span><span class="co"># Not possible with real data!</span></span>
<span><span class="va">groupstrain</span> <span class="op">=</span> <span class="va">groups</span><span class="op">[</span><span class="fl">251</span><span class="op">:</span><span class="fl">750</span><span class="op">]</span>; </span></code></pre></div>
<p>By design, <span class="math inline">\(P(y = 1)\)</span> is different
across groups:</p>
<div class="sourceCode" id="cb60"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_boxplot.html" class="external-link">geom_boxplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">groups</span>, y<span class="op">=</span><span class="fl">1</span><span class="op">/</span><span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="op">-</span><span class="va">x.beta</span><span class="op">)</span><span class="op">)</span>, group <span class="op">=</span> <span class="va">groups</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Group"</span>, y <span class="op">=</span> <span class="st">"P(y = 1)"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html" class="external-link">theme_minimal</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p><img src="ptLasso_files/figure-html/unnamed-chunk-126-1.png" width="384"></p>
<p>We cluster using <code>rpart</code>. Note that we use
<code>maxdepth = 2</code>: an obvious choice because we simulated the
data and we know that there is a second-level interaction (age + sex)
that determines outcome. In general, however, we recommend keeping this
tree small (<code>maxdepth</code> smaller than 4) so that it is easily
interpretable.</p>
<div class="sourceCode" id="cb61"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">treefit</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/rpart/man/rpart.html" class="external-link">rpart</a></span><span class="op">(</span><span class="va">ycluster</span><span class="op">~</span><span class="va">.</span>, </span>
<span>                data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span><span class="va">zcluster</span>, <span class="va">ycluster</span><span class="op">)</span>, </span>
<span>                control<span class="op">=</span><span class="fu"><a href="https://rdrr.io/pkg/rpart/man/rpart.control.html" class="external-link">rpart.control</a></span><span class="op">(</span>maxdepth<span class="op">=</span><span class="fl">2</span>, minbucket<span class="op">=</span><span class="fl">20</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">treefit</span></span>
<span><span class="co">#&gt; n= 250 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; node), split, n, deviance, yval</span></span>
<span><span class="co">#&gt;       * denotes terminal node</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; 1) root 250 61.82400 0.4480000  </span></span>
<span><span class="co">#&gt;   2) age&lt; 50.5 111 23.18919 0.2972973 *</span></span>
<span><span class="co">#&gt;   3) age&gt;=50.5 139 34.10072 0.5683453  </span></span>
<span><span class="co">#&gt;     6) sex&lt; 0.5 56 13.92857 0.4642857 *</span></span>
<span><span class="co">#&gt;     7) sex&gt;=0.5 83 19.15663 0.6385542 *</span></span></code></pre></div>
<p>We want our tree to return the ID of the terminal node for each
observation instead of class probabilities. The following is a trick
that causes <code>predict</code> to behave as desired.</p>
<div class="sourceCode" id="cb62"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">leaf</span><span class="op">=</span><span class="va">treefit</span><span class="op">$</span><span class="va">frame</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span><span class="op">==</span><span class="st">"&lt;leaf&gt;"</span>   </span>
<span><span class="va">treefit</span><span class="op">$</span><span class="va">frame</span><span class="op">[</span><span class="va">leaf</span>,<span class="st">"yval"</span><span class="op">]</span><span class="op">=</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">leaf</span><span class="op">)</span></span>
<span></span>
<span><span class="va">predgroupstrain</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">treefit</span>, <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span><span class="va">ztrain</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">predgroupstest</span>  <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">treefit</span>, <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span><span class="va">ztest</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>Finally, we are ready to apply pretraining using the predicted groups
as our grouping variable.</p>
<div class="sourceCode" id="cb63"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cvfit</span> <span class="op">=</span> <span class="fu"><a href="../reference/cv.ptLasso.html">cv.ptLasso</a></span><span class="op">(</span><span class="va">xtrain</span>, <span class="va">ytrain</span>, <span class="va">predgroupstrain</span>, family <span class="op">=</span> <span class="st">"binomial"</span>, </span>
<span>                   type.measure <span class="op">=</span> <span class="st">"auc"</span>, nfolds <span class="op">=</span> <span class="fl">10</span>, </span>
<span>                   overall.lambda <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">cvfit</span>, <span class="va">xtest</span>, <span class="va">predgroupstest</span>, ytest <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.cv.ptLasso(object = cvfit, xtest = xtest, groupstest = predgroupstest,  </span></span>
<span><span class="co">#&gt;     ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (AUC):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            allGroups   mean wtdMean group_1 group_2 group_3</span></span>
<span><span class="co">#&gt; Overall       0.7081 0.6448  0.6399  0.6085  0.6575  0.6684</span></span>
<span><span class="co">#&gt; Pretrain      0.7109 0.6590  0.6526  0.6147  0.6823  0.6800</span></span>
<span><span class="co">#&gt; Individual    0.7058 0.6525  0.6477  0.6085  0.6428  0.7063</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                       </span></span>
<span><span class="co">#&gt; Overall    8                          </span></span>
<span><span class="co">#&gt; Pretrain   8 (8 common + 0 individual)</span></span>
<span><span class="co">#&gt; Individual 19</span></span></code></pre></div>
<p>Note that the overall model trained by <code>cv.ptLasso</code> takes
advantage of the clustering: it fits a unique intercept for each group.
Performance would have been much worse if we hadn’t done any clustering
at all:</p>
<div class="sourceCode" id="cb64"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">baseline.model</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">xtrain</span>, <span class="va">ytrain</span>, family <span class="op">=</span> <span class="st">"binomial"</span>, type.measure <span class="op">=</span> <span class="st">"auc"</span>, nfolds <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="va">baseline.model</span>, newx<span class="op">=</span><span class="va">xtest</span>, newy<span class="op">=</span><span class="va">ytest</span><span class="op">)</span><span class="op">$</span><span class="va">auc</span></span>
<span><span class="co">#&gt; [1] 0.6050242</span></span>
<span><span class="co">#&gt; attr(,"measure")</span></span>
<span><span class="co">#&gt; [1] "AUC"</span></span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="target-grouped-data">Target grouped data<a class="anchor" aria-label="anchor" href="#target-grouped-data"></a>
</h2>
<p>Now we turn to the <strong>target grouped</strong> setting. Suppose
we have a dataset with a multinomial outcome, and no other grouping on
the observations. For example, our data might look like the
following:</p>
<div class="sourceCode" id="cb65"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">500</span>; <span class="va">p</span> <span class="op">=</span> <span class="fl">75</span>; <span class="va">k</span> <span class="op">=</span> <span class="fl">3</span></span>
<span><span class="va">X</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="va">n</span>, ncol <span class="op">=</span> <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">k</span>, <span class="va">n</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="va">Xtest</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="va">n</span>, ncol <span class="op">=</span> <span class="va">p</span><span class="op">)</span></span></code></pre></div>
<p>Each row in <span class="math inline">\(X\)</span> belongs to class
1, 2 or 3, and we wish to predict class membership. We could fit a
single multinomial model to the data:</p>
<div class="sourceCode" id="cb66"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">multinomial</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span>, family <span class="op">=</span> <span class="st">"multinomial"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">multipreds</span>  <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">multinomial</span>, <span class="va">Xtest</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span></span>
<span><span class="va">multipreds.class</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">multipreds</span>, <span class="fl">1</span>, <span class="va">which.max</span><span class="op">)</span></span></code></pre></div>
<p>Or, we could fit 3 one-vs-rest models; at prediction time, we would
assign observations to the class with the highest probability.</p>
<div class="sourceCode" id="cb67"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">class1</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span> <span class="op">==</span> <span class="fl">1</span>, family <span class="op">=</span> <span class="st">"binomial"</span><span class="op">)</span></span>
<span><span class="va">class2</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span> <span class="op">==</span> <span class="fl">2</span>, family <span class="op">=</span> <span class="st">"binomial"</span><span class="op">)</span></span>
<span><span class="va">class3</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span> <span class="op">==</span> <span class="fl">3</span>, family <span class="op">=</span> <span class="st">"binomial"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">ovrpreds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">class1</span>, <span class="va">Xtest</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">class2</span>, <span class="va">Xtest</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">class3</span>, <span class="va">Xtest</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">ovrpreds.class</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">ovrpreds</span>, <span class="fl">1</span>, <span class="va">which.max</span><span class="op">)</span></span></code></pre></div>
<p>Another alternative is to do pretraining, which fits something <em>in
between</em> one model for all data and three separate models.
<code>ptLasso</code> will do this for you, using the arguments
<code>family = "multinomial"</code> and
<code>use.case = "targetGroups"</code>.</p>
<div class="sourceCode" id="cb68"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span>, groups <span class="op">=</span> <span class="va">y</span>, alpha <span class="op">=</span> <span class="fl">0.5</span>,</span>
<span>              family <span class="op">=</span> <span class="st">"multinomial"</span>, use.case <span class="op">=</span> <span class="st">"targetGroups"</span><span class="op">)</span></span></code></pre></div>
<p>But what exactly is pretraining doing here? We’ll walk through an
example, doing pretraining “by hand”. The steps are:</p>
<ol style="list-style-type: decimal">
<li>Train an overall model: a multinomial model using a penalty on the
coefficients <span class="math inline">\(\beta\)</span> so that each
coefficient is either 0 or nonzero for all classes.</li>
<li>Train individual one-vs-rest models using the penalty factor and
offset defined by the overall model (as in the input grouped
setting).</li>
</ol>
<p>To train the overall model, we use <code>cv.glmnet</code> with
<code>type.multinomial = "grouped"</code>. This puts a penalty on <span class="math inline">\(\beta\)</span> to force coefficients to be
<em>in</em> or <em>out</em> of the model for all classes. This is
analogous to the overall model in the input grouped setting: we want to
first learn <strong>shared</strong> information.</p>
<div class="sourceCode" id="cb69"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">multinomial</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span>, family <span class="op">=</span> <span class="st">"multinomial"</span>, </span>
<span>                        type.multinomial <span class="op">=</span> <span class="st">"grouped"</span>,</span>
<span>                        keep <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<p>Then, we fit 3 one-vs-rest models using the support and offset from
the multinomial model.</p>
<div class="sourceCode" id="cb70"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># The support of the overall model:</span></span>
<span><span class="va">nonzero.coefs</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">multinomial</span>, s <span class="op">=</span> <span class="st">"lambda.1se"</span><span class="op">)</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span> <span class="op">!=</span> <span class="fl">0</span><span class="op">)</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># The offsets - one for each class:</span></span>
<span><span class="va">offset</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">multinomial</span>, <span class="va">X</span>, s <span class="op">=</span> <span class="st">"lambda.1se"</span><span class="op">)</span></span>
<span><span class="va">offset.class1</span> <span class="op">=</span> <span class="va">offset</span><span class="op">[</span>, <span class="fl">1</span>, <span class="fl">1</span><span class="op">]</span></span>
<span><span class="va">offset.class2</span> <span class="op">=</span> <span class="va">offset</span><span class="op">[</span>, <span class="fl">2</span>, <span class="fl">1</span><span class="op">]</span></span>
<span><span class="va">offset.class3</span> <span class="op">=</span> <span class="va">offset</span><span class="op">[</span>, <span class="fl">3</span>, <span class="fl">1</span><span class="op">]</span></span></code></pre></div>
<p>Now we have everything we need to train the one-vs-rest models. As
always, we have the pretraining parameter <span class="math inline">\(\alpha\)</span> - for this example, let’s use
<span class="math inline">\(\alpha = 0.5\)</span>:</p>
<div class="sourceCode" id="cb71"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">alpha</span> <span class="op">=</span> <span class="fl">0.5</span></span>
<span><span class="va">penalty.factor</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="va">alpha</span>, <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">penalty.factor</span><span class="op">[</span><span class="va">nonzero.coefs</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1</span></span>
<span></span>
<span><span class="va">class1</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span> <span class="op">==</span> <span class="fl">1</span>, family <span class="op">=</span> <span class="st">"binomial"</span>, </span>
<span>                   offset <span class="op">=</span> <span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">alpha</span><span class="op">)</span> <span class="op">*</span> <span class="va">offset.class1</span>,</span>
<span>                   penalty.factor <span class="op">=</span> <span class="va">penalty.factor</span><span class="op">)</span></span>
<span><span class="va">class2</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span> <span class="op">==</span> <span class="fl">2</span>, family <span class="op">=</span> <span class="st">"binomial"</span>, </span>
<span>                   offset <span class="op">=</span> <span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">alpha</span><span class="op">)</span> <span class="op">*</span> <span class="va">offset.class2</span>,</span>
<span>                   penalty.factor <span class="op">=</span> <span class="va">penalty.factor</span><span class="op">)</span></span>
<span><span class="va">class3</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">y</span> <span class="op">==</span> <span class="fl">3</span>, family <span class="op">=</span> <span class="st">"binomial"</span>, </span>
<span>                   offset <span class="op">=</span> <span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">alpha</span><span class="op">)</span> <span class="op">*</span> <span class="va">offset.class3</span>,</span>
<span>                   penalty.factor <span class="op">=</span> <span class="va">penalty.factor</span><span class="op">)</span></span></code></pre></div>
<p>And we’re done with pretraining! To predict, we again assign each row
to the class with the highest prediction:</p>
<div class="sourceCode" id="cb72"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">newoffset</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">multinomial</span>, <span class="va">X</span>, s <span class="op">=</span> <span class="st">"lambda.1se"</span><span class="op">)</span></span>
<span><span class="va">ovrpreds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">class1</span>, <span class="va">Xtest</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span>, newoffset <span class="op">=</span> <span class="va">newoffset</span><span class="op">[</span>, <span class="fl">1</span>, <span class="fl">1</span><span class="op">]</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">class2</span>, <span class="va">Xtest</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span>, newoffset <span class="op">=</span> <span class="va">newoffset</span><span class="op">[</span>, <span class="fl">2</span>, <span class="fl">1</span><span class="op">]</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">class3</span>, <span class="va">Xtest</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span>, newoffset <span class="op">=</span> <span class="va">newoffset</span><span class="op">[</span>, <span class="fl">3</span>, <span class="fl">1</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="va">ovrpreds.class</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">ovrpreds</span>, <span class="fl">1</span>, <span class="va">which.max</span><span class="op">)</span></span></code></pre></div>
<p>This is all done automatically within <code>ptLasso</code>; we show a
more detailed example in the next section. The example above is intended
only to show how pretraining works for multinomial outcomes, and some
technical details have been omitted. (For example, <code>ptLasso</code>
takes care of crossfitting between the first and second steps.)</p>
<div class="section level3">
<h3 id="base-case-data-with-a-multinomial-outcome">Base case: data with a multinomial outcome<a class="anchor" aria-label="anchor" href="#base-case-data-with-a-multinomial-outcome"></a>
</h3>
<p>We will use <code>ptLasso</code> for data with a multinomial outcome.
First, let’s simulate multinomial data with 5 classes. We start by
drawing <span class="math inline">\(X\)</span> from a normal
distribution (uncorrelated features), and then we shift the columns
differently for each group.</p>
<div class="sourceCode" id="cb73"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">500</span>; <span class="va">p</span> <span class="op">=</span> <span class="fl">75</span>; <span class="va">k</span> <span class="op">=</span> <span class="fl">5</span></span>
<span><span class="va">class.sizes</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="va">n</span><span class="op">/</span><span class="va">k</span>, <span class="va">k</span><span class="op">)</span></span>
<span><span class="va">ncommon</span> <span class="op">=</span> <span class="fl">3</span>; <span class="va">nindiv</span> <span class="op">=</span> <span class="fl">5</span>;</span>
<span><span class="va">shift.common</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">.2</span>, <span class="fl">.2</span>, length.out <span class="op">=</span> <span class="va">k</span><span class="op">)</span></span>
<span><span class="va">shift.indiv</span>  <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">.1</span>, <span class="fl">.1</span>, length.out <span class="op">=</span> <span class="va">k</span><span class="op">)</span></span>
<span></span>
<span><span class="va">x</span>     <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, <span class="va">n</span>, <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">xtest</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, <span class="va">n</span>, <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">ytest</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">sapply</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">class.sizes</span><span class="op">)</span>, <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="va">i</span>, <span class="va">class.sizes</span><span class="op">[</span><span class="va">i</span><span class="op">]</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">start</span> <span class="op">=</span> <span class="va">ncommon</span> <span class="op">+</span> <span class="fl">1</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">k</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">end</span> <span class="op">=</span> <span class="va">start</span> <span class="op">+</span> <span class="va">nindiv</span> <span class="op">-</span> <span class="fl">1</span></span>
<span>  <span class="va">x</span><span class="op">[</span><span class="va">y</span> <span class="op">==</span> <span class="va">i</span>, <span class="fl">1</span><span class="op">:</span><span class="va">ncommon</span><span class="op">]</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">y</span> <span class="op">==</span> <span class="va">i</span>, <span class="fl">1</span><span class="op">:</span><span class="va">ncommon</span><span class="op">]</span> <span class="op">+</span> <span class="va">shift.common</span><span class="op">[</span><span class="va">i</span><span class="op">]</span></span>
<span>  <span class="va">x</span><span class="op">[</span><span class="va">y</span> <span class="op">==</span> <span class="va">i</span>, <span class="va">start</span><span class="op">:</span><span class="va">end</span><span class="op">]</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">y</span> <span class="op">==</span> <span class="va">i</span>, <span class="va">start</span><span class="op">:</span><span class="va">end</span><span class="op">]</span> <span class="op">+</span> <span class="va">shift.indiv</span><span class="op">[</span><span class="va">i</span><span class="op">]</span></span>
<span>  </span>
<span>  <span class="va">xtest</span><span class="op">[</span><span class="va">ytest</span> <span class="op">==</span> <span class="va">i</span>, <span class="fl">1</span><span class="op">:</span><span class="va">ncommon</span><span class="op">]</span> <span class="op">=</span> <span class="va">xtest</span><span class="op">[</span><span class="va">ytest</span> <span class="op">==</span> <span class="va">i</span>, <span class="fl">1</span><span class="op">:</span><span class="va">ncommon</span><span class="op">]</span> <span class="op">+</span> <span class="va">shift.common</span><span class="op">[</span><span class="va">i</span><span class="op">]</span></span>
<span>  <span class="va">xtest</span><span class="op">[</span><span class="va">ytest</span> <span class="op">==</span> <span class="va">i</span>, <span class="va">start</span><span class="op">:</span><span class="va">end</span><span class="op">]</span> <span class="op">=</span> <span class="va">xtest</span><span class="op">[</span><span class="va">ytest</span> <span class="op">==</span> <span class="va">i</span>, <span class="va">start</span><span class="op">:</span><span class="va">end</span><span class="op">]</span> <span class="op">+</span> <span class="va">shift.indiv</span><span class="op">[</span><span class="va">i</span><span class="op">]</span></span>
<span>  <span class="va">start</span> <span class="op">=</span> <span class="va">end</span> <span class="op">+</span> <span class="fl">1</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>The calls to <code>ptLasso</code> and <code>cv.ptLasso</code> are
almost the same as in the input grouped setting, only now we specify
<code>use.case = "targetGroups"</code>. Note also that we use
<code>groups = y</code>. The call to <code>predict</code> does not
require a <code>groups</code> argument because the groups are unknown at
prediction time.</p>
<div class="sourceCode" id="cb74"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">################################################################################</span></span>
<span><span class="co"># Fit the pretrained model.</span></span>
<span><span class="co"># By default, ptLasso uses type.measure = "deviance", but for ease of</span></span>
<span><span class="co"># interpretability, we use type.measure = "class" (the misclassification rate).</span></span>
<span><span class="co">################################################################################</span></span>
<span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span>, groups <span class="op">=</span> <span class="va">y</span>, family <span class="op">=</span> <span class="st">"multinomial"</span>, </span>
<span>              use.case <span class="op">=</span> <span class="st">"targetGroups"</span>, type.measure <span class="op">=</span> <span class="st">"class"</span><span class="op">)</span></span>
<span></span>
<span><span class="co">################################################################################</span></span>
<span><span class="co"># Predict</span></span>
<span><span class="co">################################################################################</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">xtest</span>, ytest <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.ptLasso(object = fit, xtest = xtest, ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0.5 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (Misclassification error):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            overall   mean group_1 group_2 group_3 group_4 group_5</span></span>
<span><span class="co">#&gt; Overall      0.772                                               </span></span>
<span><span class="co">#&gt; Pretrain     0.748 0.2008   0.202     0.2     0.2     0.2   0.202</span></span>
<span><span class="co">#&gt; Individual   0.754 0.2000   0.202     0.2     0.2     0.2   0.198</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                         </span></span>
<span><span class="co">#&gt; Overall    52                           </span></span>
<span><span class="co">#&gt; Pretrain   41 (8 common + 33 individual)</span></span>
<span><span class="co">#&gt; Individual 33</span></span></code></pre></div>
<div class="sourceCode" id="cb75"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co">################################################################################</span></span>
<span><span class="co"># Fit with CV to choose the alpha parameter</span></span>
<span><span class="co">################################################################################</span></span>
<span><span class="va">cvfit</span> <span class="op">=</span> <span class="fu"><a href="../reference/cv.ptLasso.html">cv.ptLasso</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span>, groups <span class="op">=</span> <span class="va">y</span>, family <span class="op">=</span> <span class="st">"multinomial"</span>, </span>
<span>              use.case <span class="op">=</span> <span class="st">"targetGroups"</span>, type.measure <span class="op">=</span> <span class="st">"class"</span><span class="op">)</span></span>
<span></span>
<span><span class="co">################################################################################</span></span>
<span><span class="co"># Predict using one alpha for all classes</span></span>
<span><span class="co">################################################################################</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">cvfit</span>, <span class="va">xtest</span>, ytest <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.cv.ptLasso(object = cvfit, xtest = xtest, ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0.5 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (Misclassification error):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            overall   mean group_1 group_2 group_3 group_4 group_5</span></span>
<span><span class="co">#&gt; Overall      0.758                                               </span></span>
<span><span class="co">#&gt; Pretrain     0.748 0.2016     0.2     0.2     0.2     0.2   0.208</span></span>
<span><span class="co">#&gt; Individual   0.786 0.2000     0.2     0.2     0.2     0.2   0.200</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                         </span></span>
<span><span class="co">#&gt; Overall    67                           </span></span>
<span><span class="co">#&gt; Pretrain   46 (8 common + 38 individual)</span></span>
<span><span class="co">#&gt; Individual 21</span></span></code></pre></div>
<div class="sourceCode" id="cb76"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co">################################################################################</span></span>
<span><span class="co"># Predict using a separate alpha for each class</span></span>
<span><span class="co">################################################################################</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">cvfit</span>, <span class="va">xtest</span>, ytest <span class="op">=</span> <span class="va">ytest</span>, alphatype <span class="op">=</span> <span class="st">"varying"</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.cv.ptLasso(object = cvfit, xtest = xtest, ytest = ytest,  </span></span>
<span><span class="co">#&gt;     alphatype = "varying") </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0.4 0.7 0.7 0 0.5 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (Misclassification error):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            overall   mean group_1 group_2 group_3 group_4 group_5</span></span>
<span><span class="co">#&gt; Overall      0.758                                               </span></span>
<span><span class="co">#&gt; Pretrain     0.778 0.2028   0.202   0.202   0.202     0.2   0.208</span></span>
<span><span class="co">#&gt; Individual   0.786 0.2000   0.200   0.200   0.200     0.2   0.200</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                         </span></span>
<span><span class="co">#&gt; Overall    67                           </span></span>
<span><span class="co">#&gt; Pretrain   63 (8 common + 55 individual)</span></span>
<span><span class="co">#&gt; Individual 21</span></span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="multi-response-data-with-gaussian-responses">Multi-response data with Gaussian responses<a class="anchor" aria-label="anchor" href="#multi-response-data-with-gaussian-responses"></a>
</h2>
<p>Multitask learning consists of data <span class="math inline">\(X\)</span> with two or more responses <span class="math inline">\(y_1, \dots, y_j\)</span>. We usually assume that
there is shared signal across the responses, and that performance can be
improved by jointly fitting models for the responses.</p>
<p>Here, we suppose that we wish to predict multiple <strong>Gaussian
responses</strong>. (If the goal is to predict multiple responses of a
different type, see the section “Multi-response data with mixed response
types”.)</p>
<p>Pretraining is a natural choice for multitask learning – it allows us
to pass information between models for the different responses. The
overview for our approach is to:</p>
<ol style="list-style-type: decimal">
<li>fit a multi-response Gaussian model using a group lasso penalty
(more below),</li>
<li>extract the support (shared across responses) and offsets (one for
each response), and</li>
<li>fit a model for each response, using the shared support and
appropriate offset.</li>
</ol>
<p>Importantly, the group lasso penalty behaves like the lasso, but on
the whole group of coefficients for each response: they are either all
zero, or else none are zero (see the <code>glmnet</code> documentation
about <code>family = "mgaussian"</code> for more detail). As a result,
the multi-response Gaussian model is forced to choose the same support
for all responses <span class="math inline">\(y_1, \dots, y_j\)</span>.
This encourages learning <em>across</em> all responses in the first
stage; in the second stage, then, we find features that are specific to
each individual response <span class="math inline">\(y_k\)</span>.</p>
<p>This is all done with the function <code>ptLasso</code>, using the
argument <code>use.case = "multiresponse"</code>.</p>
<p>We will illustrate this with simulated data with two Gaussian
responses; the two responses share the first 5 features, and they each
have 5 features of their own. The two responses are quite related, with
Pearson correlation around 0.5.</p>
<div class="sourceCode" id="cb77"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">1000</span>; <span class="va">ntrain</span> <span class="op">=</span> <span class="fl">500</span>;</span>
<span><span class="va">p</span> <span class="op">=</span> <span class="fl">500</span></span>
<span><span class="va">sigma</span> <span class="op">=</span> <span class="fl">2</span></span>
<span>     </span>
<span><span class="va">x</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">*</span><span class="va">p</span><span class="op">)</span>, <span class="va">n</span>, <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">beta1</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">5</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="fl">5</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span> <span class="op">-</span> <span class="fl">10</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">beta2</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">5</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">5</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="fl">5</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span> <span class="op">-</span> <span class="fl">15</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">mu</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">x</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta1</span>, <span class="va">x</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta2</span><span class="op">)</span></span>
<span><span class="va">y</span>  <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">mu</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="va">sigma</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span>, </span>
<span>           <span class="va">mu</span><span class="op">[</span>, <span class="fl">2</span><span class="op">]</span> <span class="op">+</span> <span class="va">sigma</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"SNR for the two tasks:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/diag.html" class="external-link">diag</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html" class="external-link">var</a></span><span class="op">(</span><span class="va">mu</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html" class="external-link">var</a></span><span class="op">(</span><span class="va">y</span><span class="op">-</span><span class="va">mu</span><span class="op">)</span><span class="op">)</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; SNR for the two tasks: 1.6 1.44</span></span></code></pre></div>
<div class="sourceCode" id="cb78"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Correlation between two tasks:"</span>, <span class="fu"><a href="https://rdrr.io/r/stats/cor.html" class="external-link">cor</a></span><span class="op">(</span><span class="va">y</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span>, <span class="va">y</span><span class="op">[</span>, <span class="fl">2</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Correlation between two tasks: 0.5164748</span></span></code></pre></div>
<div class="sourceCode" id="cb79"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># Split into train and test</span></span>
<span><span class="va">xtest</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span>, <span class="op">]</span></span>
<span><span class="va">ytest</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span>, <span class="op">]</span></span>
<span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span>, <span class="op">]</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span>, <span class="op">]</span></span></code></pre></div>
<p>Now, we are ready to call <code>ptLasso</code> with our covariates
<code>x</code> and response matrix <code>y</code>, and we specify the
argument <code>use.case = "multiresponse"</code>. A call to
<code>plot</code> shows the CV curves over the lasso parameter <span class="math inline">\(\lambda\)</span> for each model.</p>
<div class="sourceCode" id="cb80"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/ptLasso.html">ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, use.case <span class="op">=</span> <span class="st">"multiresponse"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span></code></pre></div>
<p><img src="ptLasso_files/figure-html/unnamed-chunk-155-1.png" width="700"></p>
<p>To choose the pretraining parameter <span class="math inline">\(\alpha\)</span>, we can use
<code>cv.ptLasso</code>. Using <code>plot</code>, we can view the CV
curve for pretraining together with the overall model (multi-response
Gaussian model) and the individual model (a separate Gaussian model for
each response).</p>
<div class="sourceCode" id="cb81"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="../reference/cv.ptLasso.html">cv.ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, use.case <span class="op">=</span> <span class="st">"multiresponse"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span></code></pre></div>
<p><img src="ptLasso_files/figure-html/unnamed-chunk-156-1.png" width="672"></p>
<p>As in previous examples, we can predict using the
<code>predict</code>; if <code>ytest</code> is supplied, this will print
the mean squared error as well as the support size for the pretrained,
overall and individual models using the single <span class="math inline">\(\alpha\)</span> that minimizes the the average CV
MSE across both responses.</p>
<div class="sourceCode" id="cb82"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">xtest</span>, ytest <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span></span>
<span><span class="va">preds</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.cv.ptLasso(object = fit, xtest = xtest, ytest = ytest) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha =  0.2 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (Mean squared error):</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;            allGroups  mean response_1 response_2</span></span>
<span><span class="co">#&gt; Overall        9.394 4.697      4.227      5.168</span></span>
<span><span class="co">#&gt; Pretrain       8.907 4.453      4.186      4.721</span></span>
<span><span class="co">#&gt; Individual     9.465 4.733      4.243      5.222</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                         </span></span>
<span><span class="co">#&gt; Overall    57                           </span></span>
<span><span class="co">#&gt; Pretrain   23 (19 common + 4 individual)</span></span>
<span><span class="co">#&gt; Individual 80</span></span></code></pre></div>
<p>Also as before, we can choose to use the value of <span class="math inline">\(\alpha\)</span> that minimizes the CV MSE for
<em>each</em> response.</p>
<div class="sourceCode" id="cb83"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">xtest</span>, ytest <span class="op">=</span> <span class="va">ytest</span>, alphatype <span class="op">=</span> <span class="st">"varying"</span><span class="op">)</span></span>
<span><span class="va">preds</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  </span></span>
<span><span class="co">#&gt; predict.cv.ptLasso(object = fit, xtest = xtest, ytest = ytest,  </span></span>
<span><span class="co">#&gt;     alphatype = "varying") </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; alpha:</span></span>
<span><span class="co">#&gt; group_1 group_2 </span></span>
<span><span class="co">#&gt;     0.3     0.2 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Performance (Mean squared error):</span></span>
<span><span class="co">#&gt;            allGroups  mean response_1 response_2</span></span>
<span><span class="co">#&gt; Overall        9.394 4.697      4.227      5.168</span></span>
<span><span class="co">#&gt; Pretrain       8.877 4.438      4.156      4.721</span></span>
<span><span class="co">#&gt; Individual     9.465 4.733      4.243      5.222</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Support size:</span></span>
<span><span class="co">#&gt;                                         </span></span>
<span><span class="co">#&gt; Overall    57                           </span></span>
<span><span class="co">#&gt; Pretrain   23 (19 common + 4 individual)</span></span>
<span><span class="co">#&gt; Individual 80</span></span></code></pre></div>
<div class="section level3">
<h3 id="multi-response-data-with-mixed-response-types-glmnet-only">Multi-response data with mixed response types (<code>glmnet</code>
only)<a class="anchor" aria-label="anchor" href="#multi-response-data-with-mixed-response-types-glmnet-only"></a>
</h3>
<p>Muti-response data consists of datasets with covariates <span class="math inline">\(X\)</span> and multiple outcomes <span class="math inline">\(y_1, y_2, y_3, \dots\)</span>. If these outcomes
are all continuous, then it may be natural to treat this as a multitask
learning problem (see the section “Multi-response data with Gaussian
responses”). If the outcomes have mixed types however – e.g. <span class="math inline">\(y_1\)</span> is continuous, <span class="math inline">\(y_2\)</span> binary and <span class="math inline">\(y_3\)</span> survival – then the problem is
slightly more challenging, because there are fewer methods developed for
this setting.</p>
<p>Pretraining is a natural fit for this task: we often believe that
there is shared information between <span class="math inline">\(y_1\)</span>, <span class="math inline">\(y_2\)</span> and <span class="math inline">\(y_3\)</span>. If we fit 3 separate models, we
never get to take advantage of any shared information; further, because
the outcomes have different types, there are very few methods to fit
<em>one</em> model for all outcomes (an “overall model”).</p>
<p>So, we will use pretraining to pass information between models. Our
plan is similar to the time series example; we will:</p>
<ol style="list-style-type: decimal">
<li>fit a model for <span class="math inline">\(y_1\)</span>,</li>
<li>extract the offset and support from this model,</li>
<li>use the offset and support (the usual pretraining) to train models
for <span class="math inline">\(y_2\)</span> and <span class="math inline">\(y_3\)</span>.</li>
</ol>
<p>There is one small detail here: we must choose the primary outcome
<span class="math inline">\(y_1\)</span>. This is an important choice
because it will form the support and offset for the other two outcomes.
We recommend making this selection using domain knowledge, but
cross-validation (or a validation set) can of course be used.</p>
<p>Here, we walk through an example with simulated data with three
outcomes <span class="math inline">\(y_1, y_2\)</span> and <span class="math inline">\(y_3\)</span>. The 3 outcomes have an overlapping
support; the first 10 features are shared. Outcomes 2 and 3 additionally
have 5 features unique to them. We’ll define <span class="math inline">\(y_1\)</span> to be continuous, <span class="math inline">\(y_2\)</span> to be binomial and <span class="math inline">\(y_3\)</span> to be survival.</p>
<div class="sourceCode" id="cb84"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">600</span>; <span class="va">ntrain</span> <span class="op">=</span> <span class="fl">300</span></span>
<span><span class="va">p</span> <span class="op">=</span> <span class="fl">50</span></span>
<span>     </span>
<span><span class="va">x</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">*</span><span class="va">p</span><span class="op">)</span>, <span class="va">n</span>, <span class="va">p</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># y1: continuous response</span></span>
<span><span class="va">beta1</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">.5</span>, <span class="fl">10</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">10</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">y1</span> <span class="op">=</span> <span class="va">x</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># y2: binomial response</span></span>
<span><span class="va">beta2</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">p</span>, min <span class="op">=</span> <span class="fl">0.5</span>, max <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">*</span> <span class="va">beta1</span>  <span class="co"># Shared with group 1</span></span>
<span><span class="va">beta2</span> <span class="op">=</span> <span class="va">beta2</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>, </span>
<span>                  <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="fl">5</span>, min <span class="op">=</span> <span class="fl">0</span>, max <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span>, </span>
<span>                  <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">15</span><span class="op">)</span><span class="op">)</span> <span class="co"># Individual</span></span>
<span><span class="va">y2</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html" class="external-link">rbinom</a></span><span class="op">(</span><span class="va">n</span>, <span class="fl">1</span>, prob <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="op">-</span><span class="va">x</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># y3: survival response</span></span>
<span><span class="va">beta3</span> <span class="op">=</span> <span class="va">beta1</span>  <span class="co"># Shared with group 1</span></span>
<span><span class="va">beta3</span> <span class="op">=</span> <span class="va">beta3</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>, </span>
<span>                  <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="fl">5</span>, min <span class="op">=</span> <span class="op">-</span><span class="fl">0.1</span>, max <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span>,</span>
<span>                  <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">15</span><span class="op">)</span><span class="op">)</span> <span class="co"># Individual</span></span>
<span><span class="va">y3.true</span> <span class="op">=</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">x</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta3</span><span class="op">)</span></span>
<span><span class="va">y3.cens</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span><span class="va">y3</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/survival/man/Surv.html" class="external-link">Surv</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">pmin</a></span><span class="op">(</span><span class="va">y3.true</span>, <span class="va">y3.cens</span><span class="op">)</span>, <span class="va">y3.true</span> <span class="op">&lt;=</span> <span class="va">y3.cens</span><span class="op">)</span></span></code></pre></div>
<p>We split into train and test sets, and define training folds:</p>
<div class="sourceCode" id="cb85"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Split into train and test</span></span>
<span><span class="va">xtest</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span>, <span class="op">]</span></span>
<span><span class="va">y1test</span> <span class="op">=</span> <span class="va">y1</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">y2test</span> <span class="op">=</span> <span class="va">y2</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">y3test</span> <span class="op">=</span> <span class="va">y3</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span>, <span class="op">]</span></span>
<span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span>, <span class="op">]</span></span>
<span><span class="va">y1</span> <span class="op">=</span> <span class="va">y1</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">]</span></span>
<span><span class="va">y2</span> <span class="op">=</span> <span class="va">y2</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">]</span></span>
<span><span class="va">y3</span> <span class="op">=</span> <span class="va">y3</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span>, <span class="op">]</span></span>
<span></span>
<span><span class="co"># Define training folds</span></span>
<span><span class="va">nfolds</span> <span class="op">=</span> <span class="fl">10</span></span>
<span><span class="va">foldid</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">trunc</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">/</span><span class="va">nfolds</span><span class="op">)</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">]</span></span></code></pre></div>
<p>For the first step of pretraining, train a model for the primary
outcome (<span class="math inline">\(y_1\)</span>) and record the offset
and support – these will be used when training the models for <span class="math inline">\(y_2\)</span> and <span class="math inline">\(y_3\)</span>.</p>
<div class="sourceCode" id="cb86"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">y1_fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y1</span>, keep<span class="op">=</span><span class="cn">TRUE</span>, foldid <span class="op">=</span> <span class="va">foldid</span><span class="op">)</span></span>
<span></span>
<span><span class="va">train_offset</span> <span class="op">=</span> <span class="va">y1_fit</span><span class="op">$</span><span class="va">fit.preval</span><span class="op">[</span>, <span class="va">y1_fit</span><span class="op">$</span><span class="va">lambda</span> <span class="op">==</span> <span class="va">y1_fit</span><span class="op">$</span><span class="va">lambda.1se</span><span class="op">]</span></span>
<span><span class="va">support</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">y1_fit</span>, s <span class="op">=</span> <span class="va">y1_fit</span><span class="op">$</span><span class="va">lambda.1se</span><span class="op">)</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span> <span class="op">!=</span> <span class="fl">0</span><span class="op">)</span></span></code></pre></div>
<p>Now we have everything we need to train the models for <span class="math inline">\(y_2\)</span> and <span class="math inline">\(y_3\)</span>. In the following code, we loop over
<span class="math inline">\(\alpha = 0, 0.1, \dots, 1\)</span>; in each
step, we (1) train models for <span class="math inline">\(y_2\)</span>
and <span class="math inline">\(y_3\)</span> and (2) record the CV error
from both models. The CV error will be used to determine values of <span class="math inline">\(\alpha\)</span> to use for the final models.</p>
<div class="sourceCode" id="cb87"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cv.error.y2</span> <span class="op">=</span> <span class="va">cv.error.y3</span> <span class="op">=</span> <span class="cn">NULL</span></span>
<span><span class="va">alphalist</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">11</span><span class="op">)</span></span>
<span></span>
<span><span class="kw">for</span><span class="op">(</span><span class="va">alpha</span> <span class="kw">in</span> <span class="va">alphalist</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">pf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="va">alpha</span>, <span class="va">p</span><span class="op">)</span></span>
<span>  <span class="va">pf</span><span class="op">[</span><span class="va">support</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1</span></span>
<span>  </span>
<span>  <span class="va">offset</span> <span class="op">=</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">alpha</span><span class="op">)</span> <span class="op">*</span> <span class="va">train_offset</span></span>
<span>    </span>
<span>  <span class="va">y2_fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y2</span>, </span>
<span>                     foldid <span class="op">=</span> <span class="va">foldid</span>,</span>
<span>                     offset <span class="op">=</span> <span class="va">offset</span>,</span>
<span>                     penalty.factor <span class="op">=</span> <span class="va">pf</span>,</span>
<span>                     family <span class="op">=</span> <span class="st">"binomial"</span>,</span>
<span>                     type.measure <span class="op">=</span> <span class="st">"auc"</span><span class="op">)</span></span>
<span>  <span class="va">cv.error.y2</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">cv.error.y2</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="va">y2_fit</span><span class="op">$</span><span class="va">cvm</span><span class="op">)</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="va">y3_fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y3</span>, </span>
<span>                     foldid <span class="op">=</span> <span class="va">foldid</span>,</span>
<span>                     offset <span class="op">=</span> <span class="va">offset</span>,</span>
<span>                     penalty.factor <span class="op">=</span> <span class="va">pf</span>,</span>
<span>                     family <span class="op">=</span> <span class="st">"cox"</span>,</span>
<span>                     type.measure <span class="op">=</span> <span class="st">"C"</span><span class="op">)</span></span>
<span>  <span class="va">cv.error.y3</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">cv.error.y3</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="va">y3_fit</span><span class="op">$</span><span class="va">cvm</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>Plotting our CV performance suggests the value of <span class="math inline">\(\alpha\)</span> we should choose for each
outcome:</p>
<div class="sourceCode" id="cb88"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html" class="external-link">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">alphalist</span>, <span class="va">cv.error.y2</span>, type <span class="op">=</span> <span class="st">"b"</span>,</span>
<span>     main <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/bquote.html" class="external-link">bquote</a></span><span class="op">(</span><span class="st">"Outcome 2: CV AUC vs "</span> <span class="op">~</span> <span class="va">alpha</span><span class="op">)</span>,</span>
<span>     xlab <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html" class="external-link">expression</a></span><span class="op">(</span><span class="va">alpha</span><span class="op">)</span>,</span>
<span>     ylab <span class="op">=</span> <span class="st">"CV AUC"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="va">alphalist</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html" class="external-link">which.max</a></span><span class="op">(</span><span class="va">cv.error.y2</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">alphalist</span>, <span class="va">cv.error.y3</span>, type <span class="op">=</span> <span class="st">"b"</span>,</span>
<span>     main <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/bquote.html" class="external-link">bquote</a></span><span class="op">(</span><span class="st">"Outcome 3: CV C index vs "</span> <span class="op">~</span> <span class="va">alpha</span><span class="op">)</span>,</span>
<span>     xlab <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html" class="external-link">expression</a></span><span class="op">(</span><span class="va">alpha</span><span class="op">)</span>,</span>
<span>     ylab <span class="op">=</span> <span class="st">"CV C index"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="va">alphalist</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html" class="external-link">which.max</a></span><span class="op">(</span><span class="va">cv.error.y3</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span></code></pre></div>
<p><img src="ptLasso_files/figure-html/unnamed-chunk-173-1.png" width="672"></p>
<p>Fit the final models for <span class="math inline">\(y_2\)</span> and
<span class="math inline">\(y_3\)</span>:</p>
<div class="sourceCode" id="cb89"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">############################################################</span></span>
<span><span class="co"># Model for y2:</span></span>
<span><span class="co">############################################################</span></span>
<span><span class="va">best.alpha.y2</span> <span class="op">=</span> <span class="va">alphalist</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html" class="external-link">which.max</a></span><span class="op">(</span><span class="va">cv.error.y2</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Chosen alpha (y_2):"</span>, <span class="va">best.alpha.y2</span><span class="op">)</span></span>
<span><span class="co">#&gt; Chosen alpha (y_2): 0.3</span></span></code></pre></div>
<div class="sourceCode" id="cb90"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">pf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="va">best.alpha.y2</span>, <span class="va">p</span><span class="op">)</span>; <span class="va">pf</span><span class="op">[</span><span class="va">support</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1</span></span>
<span></span>
<span><span class="va">y2_fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y2</span>, </span>
<span>                   foldid <span class="op">=</span> <span class="va">foldid</span>,</span>
<span>                   offset <span class="op">=</span> <span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">best.alpha.y2</span><span class="op">)</span> <span class="op">*</span> <span class="va">train_offset</span>,</span>
<span>                   penalty.factor <span class="op">=</span> <span class="va">pf</span>,</span>
<span>                   family <span class="op">=</span> <span class="st">"binomial"</span>,</span>
<span>                   type.measure <span class="op">=</span> <span class="st">"auc"</span><span class="op">)</span></span>
<span></span>
<span><span class="co">############################################################</span></span>
<span><span class="co"># Repeat for y3:</span></span>
<span><span class="co">############################################################</span></span>
<span><span class="va">best.alpha.y3</span> <span class="op">=</span> <span class="va">alphalist</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html" class="external-link">which.max</a></span><span class="op">(</span><span class="va">cv.error.y3</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Chosen alpha (y_3):"</span>, <span class="va">best.alpha.y3</span><span class="op">)</span></span>
<span><span class="co">#&gt; Chosen alpha (y_3): 0.7</span></span></code></pre></div>
<div class="sourceCode" id="cb91"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">pf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="va">best.alpha.y3</span>, <span class="va">p</span><span class="op">)</span>; <span class="va">pf</span><span class="op">[</span><span class="va">support</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1</span></span>
<span></span>
<span><span class="va">y3_fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y3</span>, </span>
<span>                   foldid <span class="op">=</span> <span class="va">foldid</span>,</span>
<span>                   offset <span class="op">=</span> <span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">best.alpha.y3</span><span class="op">)</span> <span class="op">*</span> <span class="va">train_offset</span>,</span>
<span>                   penalty.factor <span class="op">=</span> <span class="va">pf</span>,</span>
<span>                   family <span class="op">=</span> <span class="st">"cox"</span>, </span>
<span>                   type.measure <span class="op">=</span> <span class="st">"C"</span><span class="op">)</span></span></code></pre></div>
<p>We will also train models for <span class="math inline">\(y_2\)</span> and <span class="math inline">\(y_3\)</span> <em>without</em> pretraining; this is
a natural benchmark.</p>
<div class="sourceCode" id="cb92"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">y2_fit_no_pretrain</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y2</span>, foldid <span class="op">=</span> <span class="va">foldid</span>, </span>
<span>                               family <span class="op">=</span> <span class="st">"binomial"</span>, type.measure <span class="op">=</span> <span class="st">"auc"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">y3_fit_no_pretrain</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y3</span>, </span>
<span>                               foldid <span class="op">=</span> <span class="va">foldid</span>, </span>
<span>                               family <span class="op">=</span> <span class="st">"cox"</span>, type.measure <span class="op">=</span> <span class="st">"C"</span><span class="op">)</span></span></code></pre></div>
<p>All of our models have been trained. Let’s compare performance with
and without pretraining; we’ll start with the model for <span class="math inline">\(y_2\)</span>.</p>
<div class="sourceCode" id="cb93"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">testoffset</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">y1_fit</span>, <span class="va">xtest</span>, s <span class="op">=</span> <span class="st">"lambda.1se"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Model 2 AUC with pretraining:"</span>, </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="va">y2_fit</span>, <span class="va">xtest</span>, newy <span class="op">=</span> <span class="va">y2test</span>, </span>
<span>                        newoffset <span class="op">=</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">best.alpha.y2</span><span class="op">)</span> <span class="op">*</span> <span class="va">testoffset</span><span class="op">)</span><span class="op">$</span><span class="va">auc</span>, <span class="fl">2</span><span class="op">)</span>,</span>
<span>    fill<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; Model 2 AUC with pretraining: 0.76</span></span></code></pre></div>
<div class="sourceCode" id="cb94"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Model 2 AUC without pretraining:"</span>, </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="va">y2_fit_no_pretrain</span>, <span class="va">xtest</span>, newy <span class="op">=</span> <span class="va">y2test</span><span class="op">)</span><span class="op">$</span><span class="va">auc</span>, <span class="fl">2</span><span class="op">)</span></span>
<span>    <span class="op">)</span></span>
<span><span class="co">#&gt; Model 2 AUC without pretraining: 0.66</span></span></code></pre></div>
<p>And now, the models for <span class="math inline">\(y_3\)</span>:</p>
<div class="sourceCode" id="cb95"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Model 3 C-index with pretraining:"</span>, </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="va">y3_fit</span>, <span class="va">xtest</span>, newy <span class="op">=</span> <span class="va">y3test</span>, </span>
<span>                        newoffset <span class="op">=</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">best.alpha.y3</span><span class="op">)</span> <span class="op">*</span> <span class="va">testoffset</span><span class="op">)</span><span class="op">$</span><span class="va">C</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Model 3 C-index with pretraining: 0.8</span></span></code></pre></div>
<div class="sourceCode" id="cb96"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Model 3 C-index without pretraining:"</span>, </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="va">y3_fit_no_pretrain</span>, <span class="va">xtest</span>, newy <span class="op">=</span> <span class="va">y3test</span><span class="op">)</span><span class="op">$</span><span class="va">C</span>, <span class="fl">2</span><span class="op">)</span></span>
<span>    <span class="op">)</span></span>
<span><span class="co">#&gt; Model 3 C-index without pretraining: 0.78</span></span></code></pre></div>
<p>For both <span class="math inline">\(y_2\)</span> and <span class="math inline">\(y_3\)</span>, we saw a performance improvement
using pretraining. We didn’t technically need to train the individual
(non-pretrained) models for <span class="math inline">\(y_2\)</span> and
<span class="math inline">\(y_3\)</span>: during our CV loop to choose
<span class="math inline">\(\alpha\)</span>, we saw the cross validation
performance for the individual models (the special case when <span class="math inline">\(\alpha = 1\)</span>), and CV recommended a smaller
value of <span class="math inline">\(\alpha\)</span> for both
outcomes.</p>
<p>Note that, in this example, we trained a model using <span class="math inline">\(y_1\)</span>, and then used this model to form the
offset and support for the models for <span class="math inline">\(y_2\)</span> and <span class="math inline">\(y_3\)</span> in parallel. But using pretraining
for multi-response data is <em>flexible</em>. Pretraining is simply a
method to pass information from one model to another, and we are free to
choose how information flows. For example, we chose to pass information
from model 1 (<span class="math inline">\(y_1\)</span>) to model 2
(<span class="math inline">\(y_2\)</span>) and to model 3 (<span class="math inline">\(y_3\)</span>). But, we could have instead
<em>chained</em> our models to pass information from model 1 to model 2,
and then from model 2 to model 3 in the following way:</p>
<ol style="list-style-type: decimal">
<li>fit a model for <span class="math inline">\(y_1\)</span>,</li>
<li>extract the offset and support from this model,</li>
<li>use the offset and support (the usual pretraining) to train a model
for <span class="math inline">\(y_2\)</span>,</li>
<li>extract the offset and support from this second model, and</li>
<li>use them to train a model for <span class="math inline">\(y_3\)</span>.</li>
</ol>
<p>In this framework, the model for <span class="math inline">\(y_3\)</span> depends implicitly on both the models
for <span class="math inline">\(y_1\)</span> <em>and</em> <span class="math inline">\(y_2\)</span>, as the offset and support for the
model for <span class="math inline">\(y_2\)</span> were informed by the
model for <span class="math inline">\(y_1\)</span>. Choosing how
information should be passed between outcomes is context specific and we
recommend relying on domain knowledge for selecting an approach (though
many options may be tried and compared with cross-validation or a
validation set).</p>
</div>
</div>
<div class="section level2">
<h2 id="time-series-data-glmnet-only">Time series data (<code>glmnet</code> only)<a class="anchor" aria-label="anchor" href="#time-series-data-glmnet-only"></a>
</h2>
<p>We may have repeated measurements of <span class="math inline">\(X\)</span> and <span class="math inline">\(y\)</span> across time; for example, we may
observe patients at two different points in time. We expect that the
relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(y\)</span> will be different at time 1 and time 2,
but not completely unrelated. Therefore, pretraining can be useful: we
can use the model fitted at time 1 to inform the model for time 2.</p>
<p><code>ptLasso</code> does not natively support this setting, but we
can use pretraining nonetheless – below is an example. We assume that
<span class="math inline">\(X\)</span> has changed between times 1 and
2. However, if <span class="math inline">\(X\)</span> is constant across
time, we can also treat this as a multitask problem – see the section
“Multitask learning or coaching” for an example.</p>
<p>To do pretraining, our plan is as follows:</p>
<ol style="list-style-type: decimal">
<li>fit a model for time 1 and extract its offset and support,</li>
<li>use the offset and support (the usual pretraining) to train a model
for time 2.</li>
</ol>
<p>We’ll start by simulating data – more details in the comments.</p>
<div class="sourceCode" id="cb97"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">600</span>; <span class="va">ntrain</span> <span class="op">=</span> <span class="fl">300</span>;</span>
<span><span class="va">p</span> <span class="op">=</span> <span class="fl">20</span></span>
<span></span>
<span><span class="co"># We assume that X at time 1 (x1) and X at time 2 (x2) are related:</span></span>
<span><span class="co"># to get X2, we modify X1.</span></span>
<span><span class="va">x1</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">*</span><span class="va">p</span><span class="op">)</span>, <span class="va">n</span>, <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">x2</span> <span class="op">=</span> <span class="va">x1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fl">0.2</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">*</span><span class="va">p</span><span class="op">)</span>, <span class="va">n</span>, <span class="va">p</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># The relationship between X and y at time 1 and 2 will be similarly related.</span></span>
<span><span class="co"># The coefficients at time 2 are a function of those at time 1.</span></span>
<span><span class="co"># Importantly, they share the same support.</span></span>
<span><span class="va">beta1</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">10</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">10</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">beta2</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">p</span>, <span class="fl">0.5</span>, <span class="fl">1</span><span class="op">)</span><span class="op">*</span><span class="va">beta1</span></span>
<span></span>
<span><span class="co"># Finally, we compute y.</span></span>
<span><span class="co"># y2 is a function of y1, x2 and beta2.</span></span>
<span><span class="va">y1</span> <span class="op">=</span> <span class="va">x1</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span><span class="va">y2</span> <span class="op">=</span> <span class="fl">0.5</span> <span class="op">*</span> <span class="va">y1</span> <span class="op">+</span> <span class="va">x2</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta2</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span></code></pre></div>
<p>Split into train and test, and define folds to use for cross
validation:</p>
<div class="sourceCode" id="cb98"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Split into train and test:</span></span>
<span><span class="va">x1test</span> <span class="op">=</span> <span class="va">x1</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span>, <span class="op">]</span></span>
<span><span class="va">x2test</span> <span class="op">=</span> <span class="va">x2</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span>, <span class="op">]</span></span>
<span><span class="va">y1test</span> <span class="op">=</span> <span class="va">y1</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">y2test</span> <span class="op">=</span> <span class="va">y2</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span><span class="va">x1</span> <span class="op">=</span> <span class="va">x1</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span>, <span class="op">]</span></span>
<span><span class="va">x2</span> <span class="op">=</span> <span class="va">x2</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span>, <span class="op">]</span></span>
<span><span class="va">y1</span> <span class="op">=</span> <span class="va">y1</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">]</span></span>
<span><span class="va">y2</span> <span class="op">=</span> <span class="va">y2</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># Define 10 training folds:</span></span>
<span><span class="va">nfolds</span> <span class="op">=</span> <span class="fl">10</span></span>
<span><span class="va">foldid</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">trunc</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">x1</span><span class="op">)</span><span class="op">/</span><span class="va">nfolds</span><span class="op">)</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">x1</span><span class="op">)</span><span class="op">]</span></span></code></pre></div>
<p>Now we have our simulated data and we are ready to train models. The
first step is to fit a model for time 1 and extract the cross-fitted
offset and support. Note that <code>cv.glmnet</code> will store
cross-fitted predictions if we use the argument
<code>keep = TRUE</code>.</p>
<div class="sourceCode" id="cb99"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">y1_fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x1</span>, <span class="va">y1</span>, keep<span class="op">=</span><span class="cn">TRUE</span>, foldid <span class="op">=</span> <span class="va">foldid</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Identify the support: coefficients which are nonzero:</span></span>
<span><span class="va">support</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">y1_fit</span>, s <span class="op">=</span> <span class="va">y1_fit</span><span class="op">$</span><span class="va">lambda.1se</span><span class="op">)</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span> <span class="op">!=</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Glmnet computed the cross-fitted predictions:</span></span>
<span><span class="va">offset</span> <span class="op">=</span> <span class="va">y1_fit</span><span class="op">$</span><span class="va">fit.preval</span><span class="op">[</span>, <span class="va">y1_fit</span><span class="op">$</span><span class="va">lambda</span> <span class="op">==</span> <span class="va">y1_fit</span><span class="op">$</span><span class="va">lambda.1se</span><span class="op">]</span></span></code></pre></div>
<p>The last step is to train a model for time 2 using the offset and
support from the previous model. As always with pretraining, there is a
hyperparameter <span class="math inline">\(\alpha\)</span> that
determines the influence of the time 1 model on the time 2 model; we can
choose this with cross validation. Here, we train models for a range of
values of <span class="math inline">\(\alpha\)</span> (0, 0.1, 0.2, …
1), and store the cross validated MSE – we will choose <span class="math inline">\(\alpha\)</span> corresponding to the model with
the lowest CV MSE.</p>
<div class="sourceCode" id="cb100"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cv.error</span> <span class="op">=</span> <span class="cn">NULL</span></span>
<span><span class="va">alphalist</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">11</span><span class="op">)</span></span>
<span></span>
<span><span class="kw">for</span><span class="op">(</span><span class="va">alpha</span> <span class="kw">in</span> <span class="va">alphalist</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="co"># Penalty factor:</span></span>
<span>  <span class="va">pf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="va">alpha</span>, <span class="va">p</span><span class="op">)</span></span>
<span>  <span class="va">pf</span><span class="op">[</span><span class="va">support</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1</span></span>
<span>  </span>
<span>  <span class="co"># Offset:</span></span>
<span>  <span class="va">offset.alpha</span> <span class="op">=</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">alpha</span><span class="op">)</span> <span class="op">*</span> <span class="va">offset</span></span>
<span>    </span>
<span>  <span class="co"># Model fitting:</span></span>
<span>  <span class="va">y2_fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x2</span>, <span class="va">y2</span>, </span>
<span>                     foldid <span class="op">=</span> <span class="va">foldid</span>,</span>
<span>                     offset <span class="op">=</span> <span class="va">offset.alpha</span>,</span>
<span>                     penalty.factor <span class="op">=</span> <span class="va">pf</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Use the CV MSE computed by cv.glmnet:</span></span>
<span>  <span class="va">cv.error</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">cv.error</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">min</a></span><span class="op">(</span><span class="va">y2_fit</span><span class="op">$</span><span class="va">cvm</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>Which <span class="math inline">\(\alpha\)</span> gave us the best
performance? Plotting the CV MSE across all <span class="math inline">\(\alpha\)</span>s we compared reveals that the best
<span class="math inline">\(\alpha = 0.5\)</span>.</p>
<div class="sourceCode" id="cb101"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">alphalist</span>, <span class="va">cv.error</span>, type <span class="op">=</span> <span class="st">"b"</span>,</span>
<span>     xlab <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html" class="external-link">expression</a></span><span class="op">(</span><span class="va">alpha</span><span class="op">)</span>,</span>
<span>     ylab <span class="op">=</span> <span class="st">"CV AUC"</span><span class="op">)</span></span>
<span><span class="va">best.alpha</span> <span class="op">=</span> <span class="va">alphalist</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html" class="external-link">which.min</a></span><span class="op">(</span><span class="va">cv.error</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="va">alphalist</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html" class="external-link">which.min</a></span><span class="op">(</span><span class="va">cv.error</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span></code></pre></div>
<p><img src="ptLasso_files/figure-html/unnamed-chunk-197-1.png" width="672"></p>
<div class="sourceCode" id="cb102"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Train a model using alpha = 0.5</span></span>
<span><span class="va">pf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="va">best.alpha</span>, <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">pf</span><span class="op">[</span><span class="va">support</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1</span></span>
<span></span>
<span><span class="va">offset.alpha</span> <span class="op">=</span> <span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">best.alpha</span><span class="op">)</span> <span class="op">*</span> <span class="va">offset</span></span>
<span></span>
<span><span class="va">y2_fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x2</span>, <span class="va">y2</span>, foldid <span class="op">=</span> <span class="va">foldid</span>,</span>
<span>                   offset <span class="op">=</span> <span class="va">offset.alpha</span>,</span>
<span>                   penalty.factor <span class="op">=</span> <span class="va">pf</span><span class="op">)</span></span></code></pre></div>
<p>Out of curiosity, let’s train an entirely separate model for time 2
(though we have done this already – this is the special case of
pretraining where <span class="math inline">\(\alpha = 1\)</span>). This
will give us a baseline performance measure.</p>
<div class="sourceCode" id="cb103"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">y2_fit_no_pretrain</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x2</span>, <span class="va">y2</span>, foldid <span class="op">=</span> <span class="va">foldid</span><span class="op">)</span></span>
<span></span>
<span><span class="va">testoffset</span> <span class="op">=</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">best.alpha</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">y1_fit</span>, <span class="va">x1test</span>, s<span class="op">=</span><span class="st">"lambda.1se"</span><span class="op">)</span></span>
<span><span class="va">pretrain_preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">y2_fit</span>, <span class="va">x2test</span>, newoffset <span class="op">=</span> <span class="va">testoffset</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Pretrain PSE:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">y2test</span> <span class="op">-</span> <span class="va">pretrain_preds</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>, <span class="fl">2</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Pretrain PSE: 1.35</span></span></code></pre></div>
<div class="sourceCode" id="cb104"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">individual_preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">y2_fit_no_pretrain</span>, <span class="va">x2test</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Individual PSE:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">y2test</span> <span class="op">-</span> <span class="va">individual_preds</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Individual PSE: 1.7</span></span></code></pre></div>
<p>Pretraining gives us a 20% lower PSE than just using individual
models. This is not surprising – we simulated data to favor pretraining.
Recall, however, that if the true models at times 1 and 2 are unrelated,
cross validation over the pretraining hyperparameter <span class="math inline">\(\alpha\)</span> will encourage us to choose the
individual model, and pretraining should not hurt our performance.</p>
</div>
<div class="section level2">
<h2 id="conditional-average-treatment-effect-estimation-glmnet-only">Conditional average treatment effect estimation (<code>glmnet</code>
only)<a class="anchor" aria-label="anchor" href="#conditional-average-treatment-effect-estimation-glmnet-only"></a>
</h2>
<div class="section level3">
<h3 id="background-cate-estimation-and-pretraining">Background: CATE estimation and pretraining<a class="anchor" aria-label="anchor" href="#background-cate-estimation-and-pretraining"></a>
</h3>
<p>In causal inference, we are often interested in predicting the
treatment effect for individual observations; this is called the
conditional average treatment effect (CATE). For example, before
prescribing a drug to a patient, we want to know whether the drug is
likely to work well <em>for that patient</em> - not just whether it
works well on average. One tool to model the CATE is the R-learner
(<span class="citation">Nie and Wager (2021)</span>), which minimizes
the R loss:</p>
<p><span class="math display">\[
\hat{L}_n\{\tau(\cdot)\}=\arg \min_\tau \frac{1}{n}\sum\Bigl[ (y_i-
m^*(x_i)) - (W_i-e^*(x_i))\tau(x_i) \Bigr]^2.
\]</span> Here, <span class="math inline">\(x_i\)</span> and <span class="math inline">\(y_i\)</span> are the covariates and outcome for
observation <span class="math inline">\(i\)</span>, <span class="math inline">\(e^*(x_i)\)</span> is the treatment propensity and
<span class="math inline">\(W_i\)</span> the treatment assignment, and
<span class="math inline">\(m^*(x_i)\)</span> is the conditional mean
outcome (<span class="math inline">\(E[y_i \mid x = x_i]\)</span>).
Then, <span class="math inline">\(\hat\tau\)</span> is the estimate of
the heterogeneous treatment effect function.</p>
<p>This is fitted in stages: first, the R-learner fits <span class="math inline">\(m^*\)</span> and <span class="math inline">\(e^*\)</span> to get <span class="math inline">\(\hat{m}^*\)</span> and <span class="math inline">\(\hat{e}^*\)</span>; then plugs in <span class="math inline">\(\hat{m}^*(x_i)\)</span> and <span class="math inline">\(\hat{e}^*(x_i)\)</span> to fit <span class="math inline">\(\tau\)</span>. A minor detail is that
cross-fitting (or prevalidation) is used in the first stage so that the
plugin value for e.g. <span class="math inline">\(\hat{m}^*(x_i)\)</span> comes from a model trained
without using <span class="math inline">\(x_i\)</span>.</p>
<p>When <span class="math inline">\(\tau\)</span> is a linear function,
then the second stage of fitting is straightforward. The values <span class="math inline">\(\hat{m}^*(x_i)\)</span> and <span class="math inline">\(\hat{e}^*(x_i)\)</span> are known, and we can use
linear regression to model <span class="math inline">\(y_i -
\hat{m}^*(x_i)\)</span> as a function of the weighted feature vector
<span class="math inline">\((W_i-\hat{e}^*(x_i)) x_i\)</span>. This is
what we will do in the following example.</p>
<p>How can pretraining be useful here? Well, we are separately fitting
models for <span class="math inline">\(m^*\)</span> (the conditional
mean) and <span class="math inline">\(\tau\)</span> (the heterogeneous
treatment effect), and these two functions are likely to share support:
it is sensible to assume that the features that modulate the mean
treatment effect also modulate the heterogeneous treatment effect. We
can use pretraining by (1) training a model for <span class="math inline">\(m^*\)</span> and (2) using the support from this
model to guide the fitting of <span class="math inline">\(\tau\)</span>.
Note that the offset is not used in this case; <span class="math inline">\(m^*\)</span> and <span class="math inline">\(\tau\)</span> are designed to predict different
outcomes.</p>
</div>
<div class="section level3">
<h3 id="a-simulated-example">A simulated example<a class="anchor" aria-label="anchor" href="#a-simulated-example"></a>
</h3>
<p>Here is an example. We will simplify the problem by assuming
treatment has been randomized – the true <span class="math inline">\(e^*(x_i) = 0.5\)</span> for all <span class="math inline">\(i\)</span>.</p>
<div class="sourceCode" id="cb105"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">600</span>; <span class="va">ntrain</span> <span class="op">=</span> <span class="fl">300</span></span>
<span><span class="va">p</span> <span class="op">=</span> <span class="fl">20</span></span>
<span>     </span>
<span><span class="va">x</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">*</span><span class="va">p</span><span class="op">)</span>, <span class="va">n</span>, <span class="va">p</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Treatment assignment</span></span>
<span><span class="va">w</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html" class="external-link">rbinom</a></span><span class="op">(</span><span class="va">n</span>, <span class="fl">1</span>, <span class="fl">0.5</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># m^*</span></span>
<span><span class="va">m.coefs</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">10</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">10</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">m</span> <span class="op">=</span> <span class="va">x</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">m.coefs</span></span>
<span></span>
<span><span class="co"># tau</span></span>
<span><span class="va">tau.coefs</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">p</span>, <span class="fl">0.5</span>, <span class="fl">1</span><span class="op">)</span><span class="op">*</span><span class="va">m.coefs</span> </span>
<span><span class="va">tau</span> <span class="op">=</span> <span class="fl">1.5</span><span class="op">*</span><span class="va">m</span> <span class="op">+</span> <span class="va">x</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span><span class="va">tau.coefs</span></span>
<span></span>
<span><span class="va">mu</span> <span class="op">=</span> <span class="va">m</span> <span class="op">+</span> <span class="va">w</span> <span class="op">*</span> <span class="va">tau</span></span>
<span><span class="va">y</span>  <span class="op">=</span> <span class="va">mu</span> <span class="op">+</span> <span class="fl">10</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Signal to noise ratio:"</span>, <span class="fu"><a href="https://rdrr.io/r/stats/cor.html" class="external-link">var</a></span><span class="op">(</span><span class="va">mu</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html" class="external-link">var</a></span><span class="op">(</span><span class="va">y</span><span class="op">-</span><span class="va">mu</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Signal to noise ratio: 2.301315</span></span></code></pre></div>
<div class="sourceCode" id="cb106"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># Split into train/test</span></span>
<span><span class="va">xtest</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span>, <span class="op">]</span></span>
<span><span class="va">tautest</span> <span class="op">=</span> <span class="va">tau</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span><span class="op">]</span> </span>
<span><span class="va">wtest</span> <span class="op">=</span> <span class="va">w</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span>, <span class="op">]</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">]</span> </span>
<span><span class="va">w</span> <span class="op">=</span> <span class="va">w</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># Define training folds</span></span>
<span><span class="va">nfolds</span> <span class="op">=</span> <span class="fl">10</span></span>
<span><span class="va">foldid</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">trunc</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">/</span><span class="va">nfolds</span><span class="op">)</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">]</span></span></code></pre></div>
<p>We begin model fitting, starting with our estimate of <span class="math inline">\(e^*\)</span> (the probability of receiving the
treatment). To fit <span class="math inline">\(\tau\)</span>, we will
also need to record the cross-fitted <span class="math inline">\(\hat{e}^*(x)\)</span>.</p>
<div class="sourceCode" id="cb107"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">e_fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">w</span>, foldid <span class="op">=</span> <span class="va">foldid</span>,</span>
<span>                  family<span class="op">=</span><span class="st">"binomial"</span>, type.measure<span class="op">=</span><span class="st">"deviance"</span>,</span>
<span>                  keep <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="va">e_hat</span> <span class="op">=</span> <span class="va">e_fit</span><span class="op">$</span><span class="va">fit.preval</span><span class="op">[</span>, <span class="va">e_fit</span><span class="op">$</span><span class="va">lambda</span> <span class="op">==</span> <span class="va">e_fit</span><span class="op">$</span><span class="va">lambda.1se</span><span class="op">]</span></span>
<span><span class="va">e_hat</span> <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="op">-</span><span class="va">e_hat</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>Now, stage 1 of pretraining: fit a model for <span class="math inline">\(m^*\)</span> and record the support. As before, we
also record the cross-fitted <span class="math inline">\(\hat{m}^*(x)\)</span>.</p>
<div class="sourceCode" id="cb108"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">m_fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, foldid <span class="op">=</span> <span class="va">foldid</span>, keep <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="va">m_hat</span> <span class="op">=</span> <span class="va">m_fit</span><span class="op">$</span><span class="va">fit.preval</span><span class="op">[</span>, <span class="va">m_fit</span><span class="op">$</span><span class="va">lambda</span> <span class="op">==</span> <span class="va">m_fit</span><span class="op">$</span><span class="va">lambda.1se</span><span class="op">]</span></span>
<span></span>
<span><span class="va">bhat</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">m_fit</span>, s <span class="op">=</span> <span class="va">m_fit</span><span class="op">$</span><span class="va">lambda.1se</span><span class="op">)</span></span>
<span><span class="va">support</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="va">bhat</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span> <span class="op">!=</span> <span class="fl">0</span><span class="op">)</span></span></code></pre></div>
<p>To fit <span class="math inline">\(\tau\)</span>, we will regress
<span class="math inline">\(\tilde{y} = y_i - \hat{m}^*(x_i)\)</span> on
<span class="math inline">\(\tilde{x} = (w_i - \hat{e}^*(x_i))
x_i\)</span>; we’ll define them here:</p>
<div class="sourceCode" id="cb109"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">y_tilde</span> <span class="op">=</span> <span class="va">y</span> <span class="op">-</span> <span class="va">m_hat</span></span>
<span><span class="va">x_tilde</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="va">w</span> <span class="op">-</span> <span class="va">e_hat</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">x</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>And now, pretraining for <span class="math inline">\(\tau\)</span>.
Loop over <span class="math inline">\(\alpha = 0, 0.1, \dots,
1\)</span>; for each <span class="math inline">\(\alpha\)</span>, fit a
model for <span class="math inline">\(\tau\)</span> using the penalty
factor defined by the support of <span class="math inline">\(\hat{m}\)</span> and <span class="math inline">\(\alpha\)</span>. We’ll keep track of our CV MSE at
each step so that we can choose the <span class="math inline">\(\alpha\)</span> that minimizes the MSE.</p>
<div class="sourceCode" id="cb110"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cv.error</span> <span class="op">=</span> <span class="cn">NULL</span></span>
<span><span class="va">alphalist</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">11</span><span class="op">)</span></span>
<span></span>
<span><span class="kw">for</span><span class="op">(</span><span class="va">alpha</span> <span class="kw">in</span> <span class="va">alphalist</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">pf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="va">alpha</span>, <span class="va">p</span><span class="op">)</span></span>
<span>  <span class="va">pf</span><span class="op">[</span><span class="va">support</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1</span></span>
<span>  <span class="va">pf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">pf</span><span class="op">)</span> <span class="co"># Don't penalize the intercept</span></span>
<span>  </span>
<span>  <span class="va">tau_fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x_tilde</span>, <span class="va">y_tilde</span>, </span>
<span>                      foldid <span class="op">=</span> <span class="va">foldid</span>,</span>
<span>                      penalty.factor <span class="op">=</span> <span class="va">pf</span>,</span>
<span>                      intercept <span class="op">=</span> <span class="cn">FALSE</span>, <span class="co"># already include in x_tilde</span></span>
<span>                      standardize <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span>  <span class="va">cv.error</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">cv.error</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">min</a></span><span class="op">(</span><span class="va">tau_fit</span><span class="op">$</span><span class="va">cvm</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">alphalist</span>, <span class="va">cv.error</span>, type <span class="op">=</span> <span class="st">"b"</span>,</span>
<span>     xlab <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html" class="external-link">expression</a></span><span class="op">(</span><span class="va">alpha</span><span class="op">)</span>, </span>
<span>     ylab <span class="op">=</span> <span class="st">"CV MSE"</span>, </span>
<span>     main <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/bquote.html" class="external-link">bquote</a></span><span class="op">(</span><span class="st">"CV mean squared error as a function of "</span> <span class="op">~</span> <span class="va">alpha</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="va">alphalist</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html" class="external-link">which.min</a></span><span class="op">(</span><span class="va">cv.error</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span></code></pre></div>
<p><img src="ptLasso_files/figure-html/unnamed-chunk-215-1.png" width="672"></p>
<p>In the plot above, the value at <span class="math inline">\(\alpha =
1\)</span> corresponds to the usual R learner, which makes no assumption
about a shared support between <span class="math inline">\(\tau\)</span>
and <span class="math inline">\(m^*\)</span>. Based on the plot, we
choose <span class="math inline">\(\alpha = 0.2\)</span> as our best
performing model:</p>
<div class="sourceCode" id="cb111"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">best.alpha</span> <span class="op">=</span> <span class="va">alphalist</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html" class="external-link">which.min</a></span><span class="op">(</span><span class="va">cv.error</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Chosen alpha:"</span>, <span class="va">best.alpha</span><span class="op">)</span></span>
<span><span class="co">#&gt; Chosen alpha: 0.2</span></span></code></pre></div>
<div class="sourceCode" id="cb112"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">pf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="va">best.alpha</span>, <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">pf</span><span class="op">[</span><span class="va">support</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1</span></span>
<span><span class="va">pf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">pf</span><span class="op">)</span></span>
<span><span class="va">tau_fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x_tilde</span>, <span class="va">y_tilde</span>, foldid <span class="op">=</span> <span class="va">foldid</span>,</span>
<span>                    penalty.factor <span class="op">=</span> <span class="va">pf</span>,</span>
<span>                    intercept <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>                    standardize <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<p>To concretely compare the pretrained R-learner with the usual
R-learner, we’ll train the usual R-learner here:</p>
<div class="sourceCode" id="cb113"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tau_rlearner</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x_tilde</span>, <span class="va">y_tilde</span>, foldid <span class="op">=</span> <span class="va">foldid</span>, </span>
<span>                         penalty.factor <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                         intercept <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>                         standardize <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<p>As anticipated, pretraining improves the prediction squared error
relative to the R learner – this is how we designed our simulation:</p>
<div class="sourceCode" id="cb114"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">rlearner_preds</span>   <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">tau_rlearner</span>, <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">xtest</span><span class="op">)</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"R-learner PSE: "</span>, </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">rlearner_preds</span> <span class="op">-</span> <span class="va">tautest</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; R-learner PSE:  45.85</span></span></code></pre></div>
<div class="sourceCode" id="cb115"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">pretrained_preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">tau_fit</span>, <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">xtest</span><span class="op">)</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Pretrained R-learner PSE: "</span>, </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">pretrained_preds</span> <span class="op">-</span> <span class="va">tautest</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Pretrained R-learner PSE:  37.63</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="what-if-the-pretraining-assumption-is-wrong">What if the pretraining assumption is wrong?<a class="anchor" aria-label="anchor" href="#what-if-the-pretraining-assumption-is-wrong"></a>
</h3>
<p>Here, we repeat everything from above, only now there is no overlap
in the support of <span class="math inline">\(m^*\)</span> and <span class="math inline">\(\tau\)</span>.</p>
<div class="sourceCode" id="cb116"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">######################################################</span></span>
<span><span class="co"># Simulate data</span></span>
<span><span class="co">######################################################</span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">*</span><span class="va">p</span><span class="op">)</span>, <span class="va">n</span>, <span class="va">p</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Treatment assignment</span></span>
<span><span class="va">w</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html" class="external-link">rbinom</a></span><span class="op">(</span><span class="va">n</span>, <span class="fl">1</span>, <span class="fl">0.5</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># m^*</span></span>
<span><span class="va">m.coefs</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">10</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">10</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">m</span> <span class="op">=</span> <span class="va">x</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">m.coefs</span></span>
<span></span>
<span><span class="co"># tau</span></span>
<span><span class="co"># Note these coefficients have no overlap with m.coefs!</span></span>
<span><span class="va">tau.coefs</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">10</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">20</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">tau</span> <span class="op">=</span> <span class="va">x</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span><span class="va">tau.coefs</span></span>
<span></span>
<span><span class="va">mu</span> <span class="op">=</span> <span class="va">m</span> <span class="op">+</span> <span class="va">w</span> <span class="op">*</span> <span class="va">tau</span></span>
<span><span class="va">y</span>  <span class="op">=</span> <span class="va">mu</span> <span class="op">+</span> <span class="fl">10</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Signal to noise ratio:"</span>, <span class="fu"><a href="https://rdrr.io/r/stats/cor.html" class="external-link">var</a></span><span class="op">(</span><span class="va">mu</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/stats/cor.html" class="external-link">var</a></span><span class="op">(</span><span class="va">y</span><span class="op">-</span><span class="va">mu</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Signal to noise ratio: 0.6938152</span></span></code></pre></div>
<div class="sourceCode" id="cb117"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># Split into train/test</span></span>
<span><span class="va">xtest</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span>, <span class="op">]</span></span>
<span><span class="va">tautest</span> <span class="op">=</span> <span class="va">tau</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span><span class="op">]</span> </span>
<span><span class="va">wtest</span> <span class="op">=</span> <span class="va">w</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span>, <span class="op">]</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">]</span> </span>
<span><span class="va">w</span> <span class="op">=</span> <span class="va">w</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">ntrain</span><span class="op">]</span></span>
<span></span>
<span><span class="co">######################################################</span></span>
<span><span class="co"># Model fitting: e^*</span></span>
<span><span class="co">######################################################</span></span>
<span><span class="va">e_fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">w</span>, foldid <span class="op">=</span> <span class="va">foldid</span>,</span>
<span>                  family<span class="op">=</span><span class="st">"binomial"</span>, type.measure<span class="op">=</span><span class="st">"deviance"</span>,</span>
<span>                  keep <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">e_hat</span> <span class="op">=</span> <span class="va">e_fit</span><span class="op">$</span><span class="va">fit.preval</span><span class="op">[</span>, <span class="va">e_fit</span><span class="op">$</span><span class="va">lambda</span> <span class="op">==</span> <span class="va">e_fit</span><span class="op">$</span><span class="va">lambda.1se</span><span class="op">]</span></span>
<span><span class="va">e_hat</span> <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="op">-</span><span class="va">e_hat</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co">######################################################</span></span>
<span><span class="co"># Model fitting: m^*</span></span>
<span><span class="co">######################################################</span></span>
<span><span class="va">m_fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, foldid <span class="op">=</span> <span class="va">foldid</span>, keep <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="va">m_hat</span> <span class="op">=</span> <span class="va">m_fit</span><span class="op">$</span><span class="va">fit.preval</span><span class="op">[</span>, <span class="va">m_fit</span><span class="op">$</span><span class="va">lambda</span> <span class="op">==</span> <span class="va">m_fit</span><span class="op">$</span><span class="va">lambda.1se</span><span class="op">]</span></span>
<span></span>
<span><span class="va">bhat</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">m_fit</span>, s <span class="op">=</span> <span class="va">m_fit</span><span class="op">$</span><span class="va">lambda.1se</span><span class="op">)</span></span>
<span><span class="va">support</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="va">bhat</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span> <span class="op">!=</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="co">######################################################</span></span>
<span><span class="co"># Pretraining: tau</span></span>
<span><span class="co">######################################################</span></span>
<span><span class="va">y_tilde</span> <span class="op">=</span> <span class="va">y</span> <span class="op">-</span> <span class="va">m_hat</span></span>
<span><span class="va">x_tilde</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="va">w</span> <span class="op">-</span> <span class="va">e_hat</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">x</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">cv.error</span> <span class="op">=</span> <span class="cn">NULL</span></span>
<span><span class="va">alphalist</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">11</span><span class="op">)</span></span>
<span></span>
<span><span class="kw">for</span><span class="op">(</span><span class="va">alpha</span> <span class="kw">in</span> <span class="va">alphalist</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">pf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="va">alpha</span>, <span class="va">p</span><span class="op">)</span></span>
<span>  <span class="va">pf</span><span class="op">[</span><span class="va">support</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1</span></span>
<span>  <span class="va">pf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">pf</span><span class="op">)</span> <span class="co"># Don't penalize the intercept</span></span>
<span>  </span>
<span>  <span class="va">tau_fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x_tilde</span>, <span class="va">y_tilde</span>, </span>
<span>                      foldid <span class="op">=</span> <span class="va">foldid</span>,</span>
<span>                      penalty.factor <span class="op">=</span> <span class="va">pf</span>,</span>
<span>                      intercept <span class="op">=</span> <span class="cn">FALSE</span>, <span class="co"># already include in x_tilde</span></span>
<span>                      standardize <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span>  <span class="va">cv.error</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">cv.error</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">min</a></span><span class="op">(</span><span class="va">tau_fit</span><span class="op">$</span><span class="va">cvm</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Our final model for tau:</span></span>
<span><span class="va">best.alpha</span> <span class="op">=</span> <span class="va">alphalist</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html" class="external-link">which.min</a></span><span class="op">(</span><span class="va">cv.error</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Chosen alpha:"</span>, <span class="va">best.alpha</span><span class="op">)</span></span>
<span><span class="co">#&gt; Chosen alpha: 1</span></span></code></pre></div>
<div class="sourceCode" id="cb118"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">pf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="va">best.alpha</span>, <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">pf</span><span class="op">[</span><span class="va">support</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1</span></span>
<span><span class="va">pf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">pf</span><span class="op">)</span></span>
<span><span class="va">tau_fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x_tilde</span>, <span class="va">y_tilde</span>, foldid <span class="op">=</span> <span class="va">foldid</span>,</span>
<span>                    penalty.factor <span class="op">=</span> <span class="va">pf</span>,</span>
<span>                    intercept <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>                    standardize <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span></span>
<span><span class="co">######################################################</span></span>
<span><span class="co"># Fit the usual R-learner:</span></span>
<span><span class="co">######################################################</span></span>
<span><span class="va">tau_rlearner</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x_tilde</span>, <span class="va">y_tilde</span>, foldid <span class="op">=</span> <span class="va">foldid</span>, </span>
<span>                         penalty.factor <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                         intercept <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>                         standardize <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span></span>
<span><span class="co">######################################################</span></span>
<span><span class="co"># Measure performance:</span></span>
<span><span class="co">######################################################</span></span>
<span><span class="va">rlearner_preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">tau_rlearner</span>, <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">xtest</span><span class="op">)</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"R-learner prediction squared error: "</span>, </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">rlearner_preds</span> <span class="op">-</span> <span class="va">tautest</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; R-learner prediction squared error:  31.11</span></span></code></pre></div>
<div class="sourceCode" id="cb119"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">pretrained_preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">tau_fit</span>, <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">xtest</span><span class="op">)</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Pretrained R-learner prediction squared error: "</span>, </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">pretrained_preds</span> <span class="op">-</span> <span class="va">tautest</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; Pretrained R-learner prediction squared error:  31.11</span></span></code></pre></div>
<p>Pretraining has not hurt our performance, even though the support of
<span class="math inline">\(m^*\)</span> and <span class="math inline">\(\tau\)</span> are not shared. Why? Recall that we
defined <span class="math inline">\(y =  m^*(x) + W * \tau(x) +
\epsilon\)</span>, so the relationship between <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span> is a function of the supports of both
<span class="math inline">\(m^*\)</span> and <span class="math inline">\(\tau\)</span>. In the first stage of pretraining,
we fitted <span class="math inline">\(m^*\)</span> using
<code>y ~ x</code> – so the support of <span class="math inline">\(m^*\)</span> <em>should</em> include the support
of <span class="math inline">\(\tau\)</span>. As a result, using
pretraining with the R-learner should not harm predictive
performance.</p>
</div>
</div>
<div class="section level2">
<h2 id="using-non-linear-bases-glmnet-only">Using non-linear bases (<code>glmnet</code> only)<a class="anchor" aria-label="anchor" href="#using-non-linear-bases-glmnet-only"></a>
</h2>
<p>Suppose we have a dataset with features <span class="math inline">\(X\)</span> and response <span class="math inline">\(y\)</span>, where the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(y\)</span> is a nonlinear function of the columns
of <span class="math inline">\(X\)</span>. Can we still use the lasso?
Yes! We can <em>pretrain</em> our linear model using
<code>xgboost</code> to obtain basis functions (features). Let’s walk
through an example.</p>
<div class="section level3">
<h3 id="example-1-xgboost-pretraining">Example 1: xgboost pretraining<a class="anchor" aria-label="anchor" href="#example-1-xgboost-pretraining"></a>
</h3>
<div class="sourceCode" id="cb120"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va"><a href="https://github.com/dmlc/xgboost" class="external-link">xgboost</a></span><span class="op">)</span></span>
<span><span class="co">#&gt; Loading required package: xgboost</span></span></code></pre></div>
<p>We start by simulating data (<span class="math inline">\(n =
1800\)</span>, <span class="math inline">\(p = 1000\)</span>) with a
continuous response. Our coefficients <span class="math inline">\(\beta\)</span> are sparse; the first 200 entries
will be drawn from a standard univariate normal, and the remainder are
<span class="math inline">\(0\)</span>. We define <span class="math inline">\(y\)</span> as <span class="math inline">\(y = 1(X
&gt; 0) \beta + \epsilon\)</span>, where <span class="math inline">\(\epsilon\)</span> is noise; we hope that
<code>xgboost</code> will learn the splits corresponding to <span class="math inline">\(X &gt; 0\)</span>.</p>
<div class="sourceCode" id="cb121"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">1800</span>; <span class="va">p</span> <span class="op">=</span> <span class="fl">1000</span>; <span class="va">noise</span> <span class="op">=</span> <span class="fl">5</span>;</span>
<span></span>
<span><span class="va">x</span>     <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, nrow<span class="op">=</span><span class="va">n</span>, ncol<span class="op">=</span><span class="va">p</span><span class="op">)</span></span>
<span><span class="va">xtest</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, nrow<span class="op">=</span><span class="va">n</span>, ncol<span class="op">=</span><span class="va">p</span><span class="op">)</span></span>
<span></span>
<span><span class="va">x.model</span>     <span class="op">=</span> <span class="fl">1</span><span class="op">*</span><span class="op">(</span><span class="va">x</span> <span class="op">&gt;</span> <span class="fl">0</span><span class="op">)</span>     </span>
<span><span class="va">xtest.model</span> <span class="op">=</span> <span class="fl">1</span><span class="op">*</span><span class="op">(</span><span class="va">xtest</span> <span class="op">&gt;</span> <span class="fl">0</span><span class="op">)</span> </span>
<span></span>
<span><span class="va">beta</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">200</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">200</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">y</span>     <span class="op">=</span> <span class="va">x.model</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta</span> <span class="op">+</span> <span class="va">noise</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span><span class="va">ytest</span> <span class="op">=</span> <span class="va">xtest.model</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta</span> <span class="op">+</span> <span class="va">noise</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span></span>
<span><span class="va">train.folds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span>, <span class="va">n</span><span class="op">/</span><span class="fl">10</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>Now, we run <code>xgboost</code> to get our basis functions:</p>
<div class="sourceCode" id="cb122"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">xgbfit</span>      <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/xgboost/man/xgb.train.html" class="external-link">xgboost</a></span><span class="op">(</span>data<span class="op">=</span><span class="va">x</span>, label<span class="op">=</span><span class="va">y</span>, nrounds<span class="op">=</span><span class="fl">200</span>, max_depth<span class="op">=</span><span class="fl">1</span>, verbose<span class="op">=</span><span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="va">x.boost</span>     <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">xgbfit</span>, <span class="va">x</span>, predleaf <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span></span>
<span><span class="va">xtest.boost</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">xgbfit</span>, <span class="va">xtest</span>, predleaf <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span></span></code></pre></div>
<p>And we are ready for model fitting with <code>cv.glmnet</code>. Our
two baselines are (1) a linear model that does not pretrain with
<code>xgboost</code>, and (2) <code>xgboost</code>. We find that
<code>glmnet</code> together with <code>xgboost</code> outperforms
<code>glmnet</code> alone and <code>xgboost</code> alone.</p>
<div class="sourceCode" id="cb123"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cvfit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x.boost</span>, <span class="va">y</span>, type.measure <span class="op">=</span> <span class="st">"mse"</span>, foldid <span class="op">=</span> <span class="va">train.folds</span><span class="op">)</span></span>
<span><span class="va">cvfit.noboost</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, type.measure <span class="op">=</span> <span class="st">"mse"</span>, foldid <span class="op">=</span> <span class="va">train.folds</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Lasso with xgboost pretraining PSE: "</span>, </span>
<span>    <span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="va">cvfit</span>, newx <span class="op">=</span> <span class="va">xtest.boost</span>, newy <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span><span class="op">$</span><span class="va">mse</span><span class="op">)</span></span>
<span><span class="co">#&gt; Lasso with xgboost pretraining PSE:  46.23225</span></span></code></pre></div>
<div class="sourceCode" id="cb124"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Lasso without xgboost pretraining PSE: "</span>, </span>
<span>    <span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="va">cvfit.noboost</span>, newx <span class="op">=</span> <span class="va">xtest</span>, newy <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span><span class="op">$</span><span class="va">mse</span><span class="op">)</span></span>
<span><span class="co">#&gt; Lasso without xgboost pretraining PSE:  60.68818</span></span></code></pre></div>
<div class="sourceCode" id="cb125"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"xgboost alone PSE: "</span>, </span>
<span>    <span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">xgbfit</span>, <span class="va">xtest</span><span class="op">)</span>, newy <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span><span class="op">$</span><span class="va">mse</span><span class="op">)</span></span>
<span><span class="co">#&gt; xgboost alone PSE:  49.47738</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="example-2-xgboost-pretraining-with-input-groups">Example 2: xgboost pretraining with input groups<a class="anchor" aria-label="anchor" href="#example-2-xgboost-pretraining-with-input-groups"></a>
</h3>
<p>Now, let’s repeat the above supposing our data have input groups. The
only difference here is that we will use <code>cv.ptLasso</code> for our
model instead of <code>cv.glmnet</code>, and we will use the group
indicators as a feature when fitting <code>xgboost</code>.</p>
<p>We start by simulating data with 3 groups (<span class="math inline">\(600\)</span> observations in each group) and a
continuous response. As before, we will simulate <span class="math inline">\(y\)</span> as <span class="math inline">\(y = 1(X
&gt; 0) \beta + \epsilon\)</span>, only now we have a different <span class="math inline">\(\beta\)</span> for each group. The coefficients
for the groups are in Table @ref(tab:nonlinear).</p>
<table class="table">
<caption>Coefficients for simulating data for use with xgboost
pretraining</caption>
<thead><tr class="header">
<th align="left"></th>
<th align="right">1-50</th>
<th align="right">51-100</th>
<th align="right">101-150</th>
<th align="right">151-200</th>
<th align="right">201-500</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">group 1</td>
<td align="right">2</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">group 2</td>
<td align="right">2</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">group 3</td>
<td align="right">2</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb126"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">1800</span>; <span class="va">p</span> <span class="op">=</span> <span class="fl">500</span>; <span class="va">k</span> <span class="op">=</span> <span class="fl">3</span>;</span>
<span><span class="va">noise</span> <span class="op">=</span> <span class="fl">5</span>;</span>
<span></span>
<span><span class="va">groups</span> <span class="op">=</span> <span class="va">groupstest</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sort.html" class="external-link">sort</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">k</span>, <span class="va">n</span><span class="op">/</span><span class="va">k</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">x</span>     <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, nrow<span class="op">=</span><span class="va">n</span>, ncol<span class="op">=</span><span class="va">p</span><span class="op">)</span></span>
<span><span class="va">xtest</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, nrow<span class="op">=</span><span class="va">n</span>, ncol<span class="op">=</span><span class="va">p</span><span class="op">)</span></span>
<span></span>
<span><span class="va">x.model</span>     <span class="op">=</span> <span class="fl">1</span><span class="op">*</span><span class="op">(</span><span class="va">x</span> <span class="op">&gt;</span> <span class="fl">0</span><span class="op">)</span>     </span>
<span><span class="va">xtest.model</span> <span class="op">=</span> <span class="fl">1</span><span class="op">*</span><span class="op">(</span><span class="va">xtest</span> <span class="op">&gt;</span> <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="va">common.beta</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">50</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">50</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">beta.1</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">50</span><span class="op">)</span>,  <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">50</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">100</span><span class="op">)</span><span class="op">)</span> </span>
<span><span class="va">beta.2</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">100</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">50</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">150</span><span class="op">)</span><span class="op">)</span> </span>
<span><span class="va">beta.3</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">150</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">50</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">-</span><span class="fl">200</span><span class="op">)</span><span class="op">)</span> </span>
<span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">x.model</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">common.beta</span> <span class="op">+</span> <span class="va">noise</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span><span class="va">y</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">1</span><span class="op">]</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="va">x.model</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">1</span>, <span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta.1</span></span>
<span><span class="va">y</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">2</span><span class="op">]</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">2</span><span class="op">]</span> <span class="op">+</span> <span class="va">x.model</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">2</span>, <span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta.2</span></span>
<span><span class="va">y</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">3</span><span class="op">]</span> <span class="op">=</span> <span class="va">y</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">3</span><span class="op">]</span> <span class="op">+</span> <span class="va">x.model</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">3</span>, <span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta.3</span></span>
<span></span>
<span><span class="va">ytest</span> <span class="op">=</span> <span class="va">xtest.model</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">common.beta</span> <span class="op">+</span> <span class="va">noise</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span><span class="va">ytest</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">1</span><span class="op">]</span> <span class="op">=</span> <span class="va">ytest</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="va">xtest.model</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">1</span>, <span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta.1</span></span>
<span><span class="va">ytest</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">2</span><span class="op">]</span> <span class="op">=</span> <span class="va">ytest</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">2</span><span class="op">]</span> <span class="op">+</span> <span class="va">xtest.model</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">2</span>, <span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta.2</span></span>
<span><span class="va">ytest</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">3</span><span class="op">]</span> <span class="op">=</span> <span class="va">ytest</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">3</span><span class="op">]</span> <span class="op">+</span> <span class="va">xtest.model</span><span class="op">[</span><span class="va">groups</span> <span class="op">==</span> <span class="fl">3</span>, <span class="op">]</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta.3</span></span></code></pre></div>
<p>Here are the dummy variables for our group indicators; we will use
them to fit and predict with <code>xgboost</code>.</p>
<div class="sourceCode" id="cb127"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">group.ids</span>     <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html" class="external-link">model.matrix</a></span><span class="op">(</span><span class="op">~</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">groups</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span> </span>
<span><span class="va">grouptest.ids</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html" class="external-link">model.matrix</a></span><span class="op">(</span><span class="op">~</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">groupstest</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span> </span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">colnames</a></span><span class="op">(</span><span class="va">grouptest.ids</span><span class="op">)</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">colnames</a></span><span class="op">(</span><span class="va">group.ids</span><span class="op">)</span></span></code></pre></div>
<p>Now, let’s train <code>xgboost</code> and <code>predict</code> to get
our new features. Note that we now use <code>max_depth = 2</code>: this
is intended to allow interactions between the group indicators and the
other features.</p>
<div class="sourceCode" id="cb128"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">xgbfit</span>      <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/xgboost/man/xgb.train.html" class="external-link">xgboost</a></span><span class="op">(</span>data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">group.ids</span><span class="op">)</span>, label<span class="op">=</span><span class="va">y</span>, </span>
<span>                      nrounds<span class="op">=</span><span class="fl">200</span>, max_depth<span class="op">=</span><span class="fl">2</span>, verbose<span class="op">=</span><span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="va">x.boost</span>     <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">xgbfit</span>, <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">group.ids</span><span class="op">)</span>, predleaf <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span></span>
<span><span class="va">xtest.boost</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">xgbfit</span>, <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">xtest</span>, <span class="va">grouptest.ids</span><span class="op">)</span>, predleaf <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">-</span> <span class="fl">1</span></span></code></pre></div>
<p>Finally, we are ready to fit two models trained with
<code>cv.ptLasso</code>: one uses the xgboost features and the other
does not. As before, we find that pretraining with xgboost improves
performance relative to (1) model fitting in the original feature space
and (2) xgboost alone.</p>
<div class="sourceCode" id="cb129"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cvfit</span> <span class="op">=</span> <span class="fu"><a href="../reference/cv.ptLasso.html">cv.ptLasso</a></span><span class="op">(</span><span class="va">x.boost</span>, <span class="va">y</span>, groups<span class="op">=</span><span class="va">groups</span>, type.measure <span class="op">=</span> <span class="st">"mse"</span><span class="op">)</span></span>
<span><span class="va">preds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">cvfit</span>, <span class="va">xtest.boost</span>, groups<span class="op">=</span><span class="va">groupstest</span>, alphatype <span class="op">=</span> <span class="st">"varying"</span><span class="op">)</span></span>
<span><span class="va">preds</span> <span class="op">=</span> <span class="va">preds</span><span class="op">$</span><span class="va">yhatpre</span></span>
<span></span>
<span><span class="va">cvfit.noboost</span> <span class="op">=</span> <span class="fu"><a href="../reference/cv.ptLasso.html">cv.ptLasso</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, groups<span class="op">=</span><span class="va">groups</span>, type.measure <span class="op">=</span> <span class="st">"mse"</span><span class="op">)</span></span>
<span><span class="va">preds.noboost</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">cvfit.noboost</span>, <span class="va">xtest</span>, groups<span class="op">=</span><span class="va">groupstest</span>, </span>
<span>                        alphatype <span class="op">=</span> <span class="st">"varying"</span><span class="op">)</span></span>
<span><span class="va">preds.noboost</span> <span class="op">=</span> <span class="va">preds.noboost</span><span class="op">$</span><span class="va">yhatpre</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"ptLasso with xgboost pretraining PSE: "</span>, </span>
<span>    <span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="va">preds</span>, newy <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span><span class="op">$</span><span class="va">mse</span><span class="op">)</span></span>
<span><span class="co">#&gt; ptLasso with xgboost pretraining PSE:  55.1535</span></span></code></pre></div>
<div class="sourceCode" id="cb130"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"ptLasso without xgboost pretraining PSE: "</span>, </span>
<span>    <span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="va">preds.noboost</span>, newy <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span><span class="op">$</span><span class="va">mse</span><span class="op">)</span></span>
<span><span class="co">#&gt; ptLasso without xgboost pretraining PSE:  66.37259</span></span></code></pre></div>
<div class="sourceCode" id="cb131"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"xgboost alone PSE: "</span>, </span>
<span>    <span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">xgbfit</span>, <span class="va">xtest</span><span class="op">)</span>, newy <span class="op">=</span> <span class="va">ytest</span><span class="op">)</span><span class="op">$</span><span class="va">mse</span><span class="op">)</span></span>
<span><span class="co">#&gt; xgboost alone PSE:  59.63781</span></span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="unsupervised-pretraining-glmnet-only">Unsupervised pretraining (<code>glmnet</code> only)<a class="anchor" aria-label="anchor" href="#unsupervised-pretraining-glmnet-only"></a>
</h2>
<p>Suppose we have a dataset with features <span class="math inline">\(X\)</span> and response <span class="math inline">\(y\)</span>. Suppose we also have a large set of
<em>unlabeled</em> data <span class="math inline">\(X^*\)</span>. Here,
we show how to <em>pretrain</em> a model using <span class="math inline">\(X^*\)</span>. The steps are:</p>
<ol style="list-style-type: decimal">
<li>Do sparse PCA using <span class="math inline">\(X^*\)</span>.
Identify the nonzero features in the first principal component
(PC).</li>
<li>Use <code>glmnet</code> (or <code>cv.glmnet</code>) to train model
using <span class="math inline">\(X\)</span> and <span class="math inline">\(y\)</span>. Define the penalty factor using the
support identified by sparse PCA. Unlike the usual pretraining, there is
no offset defined by sparse PCA.</li>
</ol>
<p>In step 1, we may choose to use the nonzero features from the first
<span class="math inline">\(k\)</span> PCs instead of just the first PC;
in the examples that follow, we use only the first PC for
simplicity.</p>
<p>To demonstrate unsupervised pretraining, we’ll use simulated data.
The covariates <span class="math inline">\(X\)</span> and <span class="math inline">\(X^*\)</span> are drawn from a multivariate normal
distribution where the first 10 features describe most of the variance,
and <span class="math inline">\(y\)</span> is defined as <span class="math inline">\(X \beta + \epsilon\)</span>, where only the first
10 coefficients in <span class="math inline">\(\beta\)</span> are
nonzero and <span class="math inline">\(\epsilon\)</span> is noise. In
this example, we have 10 times as much unlabeled data as labeled data;
this generally happens when labels are difficult to obtain.</p>
<div class="sourceCode" id="cb132"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va"><a href="http://www.stats.ox.ac.uk/pub/MASS4/" class="external-link">MASS</a></span><span class="op">)</span> <span class="co"># for mvrnorm</span></span>
<span><span class="co">#&gt; Loading required package: MASS</span></span></code></pre></div>
<div class="sourceCode" id="cb133"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span></span>
<span><span class="va">n</span> <span class="op">=</span> <span class="fl">100</span>; <span class="va">p</span> <span class="op">=</span> <span class="fl">150</span>; </span>
<span></span>
<span><span class="va">mu</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">sigma</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">p</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">*</span><span class="fl">2</span><span class="op">-</span><span class="fl">1</span>, ncol<span class="op">=</span><span class="va">p</span><span class="op">)</span> </span>
<span><span class="va">sigma</span><span class="op">[</span>, <span class="fl">11</span><span class="op">:</span><span class="va">p</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1e-2</span> <span class="co"># The first 10 features are the most important</span></span>
<span><span class="va">sigma</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="va">sigma</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">sigma</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/diag.html" class="external-link">diag</a></span><span class="op">(</span><span class="va">sigma</span><span class="op">)</span><span class="op">[</span><span class="fl">11</span><span class="op">:</span><span class="va">p</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1</span></span>
<span></span>
<span><span class="va">x</span>     <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/MASS/man/mvrnorm.html" class="external-link">mvrnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, mu <span class="op">=</span> <span class="va">mu</span>, Sigma <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span></span>
<span><span class="va">xtest</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/MASS/man/mvrnorm.html" class="external-link">mvrnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, mu <span class="op">=</span> <span class="va">mu</span>, Sigma <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span></span>
<span><span class="va">xstar</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/MASS/man/mvrnorm.html" class="external-link">mvrnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span> <span class="op">*</span> <span class="va">n</span>, mu <span class="op">=</span> <span class="va">mu</span>, Sigma <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span> <span class="co"># unlabeled</span></span>
<span></span>
<span><span class="va">noise</span> <span class="op">=</span> <span class="fl">3</span></span>
<span><span class="va">beta</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">10</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span> <span class="op">-</span> <span class="fl">10</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">y</span>     <span class="op">=</span> <span class="va">x</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta</span>     <span class="op">+</span> <span class="va">noise</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span><span class="va">ytest</span> <span class="op">=</span> <span class="va">xtest</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">beta</span> <span class="op">+</span> <span class="va">noise</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span></span>
<span><span class="va">train.folds</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span>, <span class="fl">10</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>Now, we do sparse PCA using <span class="math inline">\(X^*\)</span>
and we identify the features with nonzero loadings in the first PC. The
argument <span class="math inline">\(k = 1\)</span> means that we only
obtain the first PC.</p>
<div class="sourceCode" id="cb134"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va"><a href="https://github.com/erichson/spca" class="external-link">sparsepca</a></span><span class="op">)</span></span>
<span><span class="co">#&gt; Loading required package: sparsepca</span></span></code></pre></div>
<div class="sourceCode" id="cb135"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">pcs</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/sparsepca/man/spca.html" class="external-link">spca</a></span><span class="op">(</span><span class="va">xstar</span>, k <span class="op">=</span> <span class="fl">1</span>, verbose<span class="op">=</span><span class="cn">FALSE</span>, alpha<span class="op">=</span><span class="fl">1e-2</span>, beta<span class="op">=</span><span class="fl">1e-2</span><span class="op">)</span></span>
<span><span class="va">nonzero.loadings</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/which.html" class="external-link">which</a></span><span class="op">(</span><span class="va">pcs</span><span class="op">$</span><span class="va">loadings</span> <span class="op">!=</span> <span class="fl">0</span><span class="op">)</span></span></code></pre></div>
<p>We set ourselves up for success: because of how we simulated our
data, we know that the first 10 features are those that explain the
variance in <span class="math inline">\(X\)</span>. These are also the
features that define the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(y\)</span>. Let’s check that sparse PCA has found
the right features:</p>
<div class="sourceCode" id="cb136"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">nonzero.loadings</span></span>
<span><span class="co">#&gt; [1]  1  2  3  4  5  6  7  8 10</span></span></code></pre></div>
<p>Now, we are ready to model! We don’t need to call
<code>ptLasso</code> here. All we need to do is call
<code>cv.glmnet</code> across a grid of values of <span class="math inline">\(\alpha\)</span> with a different
<code>penalty.factor</code> for each call. Note that <code>offset</code>
is not used – sparse PCA identifies <em>which features</em> may
important, but it doesn’t suggest a value for the fitted
coefficients.</p>
<p>To do model selection, we want to know which value of <span class="math inline">\(\alpha\)</span> gave us the best CV error.
Fortunately, <code>cv.glmnet</code> will record the CV MSE for each
model in a vector called <code>cvm</code>; we just need to keep track of
the minimum error from each model.</p>
<div class="sourceCode" id="cb137"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">alphalist</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">11</span><span class="op">)</span></span>
<span></span>
<span><span class="va">cvm</span> <span class="op">=</span> <span class="cn">NULL</span></span>
<span><span class="kw">for</span><span class="op">(</span><span class="va">alpha</span> <span class="kw">in</span> <span class="va">alphalist</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="co"># Define the penalty factor:</span></span>
<span>  <span class="va">pf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="va">alpha</span>, <span class="va">p</span><span class="op">)</span></span>
<span>  <span class="va">pf</span><span class="op">[</span><span class="va">nonzero.loadings</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1</span></span>
<span>  </span>
<span>  <span class="co"># Train a model:</span></span>
<span>  <span class="va">model</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, family <span class="op">=</span> <span class="st">"gaussian"</span>, type.measure <span class="op">=</span> <span class="st">"mse"</span>,</span>
<span>                              penalty.factor <span class="op">=</span> <span class="va">pf</span>, </span>
<span>                              foldid <span class="op">=</span> <span class="va">train.folds</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># Record the minmum CV MSE for this model:</span></span>
<span>  <span class="va">cvm</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">cvm</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">min</a></span><span class="op">(</span><span class="va">model</span><span class="op">$</span><span class="va">cvm</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">best.alpha</span> <span class="op">=</span> <span class="va">alphalist</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html" class="external-link">which.min</a></span><span class="op">(</span><span class="va">cvm</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># Plot performance as a function of alpha</span></span>
<span><span class="co"># with a vertical line to show us the minimum mse:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">alphalist</span>, <span class="va">cvm</span>, </span>
<span>     xlab <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html" class="external-link">expression</a></span><span class="op">(</span><span class="va">alpha</span><span class="op">)</span>, </span>
<span>     ylab <span class="op">=</span> <span class="st">"Mean squared error (CV)"</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="va">best.alpha</span><span class="op">)</span></span></code></pre></div>
<p><img src="ptLasso_files/figure-html/unnamed-chunk-261-1.png" width="672"></p>
<p>So, using CV performance as a metric, we choose <span class="math inline">\(\alpha = 0.2\)</span>. Now, we train our final
model and predict and measure performance with our held-out data. We
find that pretraining gives us a boost in performance.</p>
<div class="sourceCode" id="cb138"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="va">best.alpha</span>, <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">pf</span><span class="op">[</span><span class="va">nonzero.loadings</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1</span></span>
<span></span>
<span><span class="va">selected.model</span> <span class="op">=</span>  <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, family <span class="op">=</span> <span class="st">"gaussian"</span>, type.measure <span class="op">=</span> <span class="st">"mse"</span>,</span>
<span>                              penalty.factor <span class="op">=</span> <span class="va">pf</span>, </span>
<span>                              foldid <span class="op">=</span> <span class="va">train.folds</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Prediction squared error with pretraining:</span></span>
<span><span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="va">selected.model</span>, <span class="va">xtest</span>, newy <span class="op">=</span> <span class="va">ytest</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span><span class="op">[</span><span class="st">"mse"</span><span class="op">]</span></span>
<span><span class="co">#&gt; $mse</span></span>
<span><span class="co">#&gt; lambda.min </span></span>
<span><span class="co">#&gt;   11.10926 </span></span>
<span><span class="co">#&gt; attr(,"measure")</span></span>
<span><span class="co">#&gt; [1] "Mean-Squared Error"</span></span></code></pre></div>
<div class="sourceCode" id="cb139"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="va">without.pretraining</span> <span class="op">=</span>  <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html" class="external-link">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, family <span class="op">=</span> <span class="st">"gaussian"</span>, type.measure <span class="op">=</span> <span class="st">"mse"</span>,</span>
<span>                                 foldid <span class="op">=</span> <span class="va">train.folds</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Prediction squared error without pretraining:</span></span>
<span><span class="fu"><a href="https://glmnet.stanford.edu/reference/assess.glmnet.html" class="external-link">assess.glmnet</a></span><span class="op">(</span><span class="va">without.pretraining</span>, <span class="va">xtest</span>, newy <span class="op">=</span> <span class="va">ytest</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span><span class="op">[</span><span class="st">"mse"</span><span class="op">]</span></span>
<span><span class="co">#&gt; $mse</span></span>
<span><span class="co">#&gt; lambda.min </span></span>
<span><span class="co">#&gt;   13.55434 </span></span>
<span><span class="co">#&gt; attr(,"measure")</span></span>
<span><span class="co">#&gt; [1] "Mean-Squared Error"</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-craig2024pretraining" class="csl-entry">
Craig, Erin, Mert Pilanci, Thomas Le Menestrel, Balasubramanian
Narasimhan, Manuel Rivas, Roozbeh Dehghannasiri, Julia Salzman, Jonathan
Taylor, and Robert Tibshirani. 2024. <span>“Pretraining and the
Lasso.”</span> <em>arXiv Preprint arXiv:2401.12911</em>.
</div>
<div id="ref-glmnet" class="csl-entry">
Friedman, Jerome, Robert Tibshirani, and Trevor Hastie. 2010.
<span>“Regularization Paths for Generalized Linear Models via Coordinate
Descent.”</span> <em>Journal of Statistical Software</em> 33 (1): 1–22.
<a href="https://doi.org/10.18637/jss.v033.i01" class="external-link">https://doi.org/10.18637/jss.v033.i01</a>.
</div>
<div id="ref-odrf" class="csl-entry">
Liu, Yu, and Yingcun Xia. 2022. <span>“<span>ODRF</span>: Consistency of
the Oblique Decision Tree and Its Random Forest.”</span> <em>arXiv
Preprint arXiv:2211.12653</em>.
</div>
<div id="ref-nie2021quasi" class="csl-entry">
Nie, Xinkun, and Stefan Wager. 2021. <span>“Quasi-Oracle Estimation of
Heterogeneous Treatment Effects.”</span> <em>Biometrika</em> 108 (2):
299–319.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by <a href="http://www.erincraig.me" class="external-link">Erin Craig</a>, <a href="http://statistics.stanford.edu/people/robert-tibshirani" class="external-link">Rob Tibshirani</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.9.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
